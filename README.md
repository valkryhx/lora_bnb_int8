# 使用lora+bitsandbytes_int8加速 数据集格式为alpaca  微调chatYuan-large-v2 模型(0.7B参数不爆显存)
# 该教程在colab免费的GPU算力（15G显存）上可以正常运行 对新手很友好
# 该笔记本代码包含各种踩坑注释 也是自己学习的总结
