{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/valkryhx/lora_bnb_int8/blob/main/trlx_sentiments_0416%E7%89%88_%E5%BC%84%E6%B8%85%E4%BA%86%E4%BD%9C%E7%94%A8%E6%9C%BA%E7%90%86.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jwhn4SLRdz0p"
      },
      "source": [
        "# Produce Movie Reviews with Positive Sentiment\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/CarperAI/trlx/blob/main/examples/notebooks/trlx_sentiments.ipynb)\n",
        "\n",
        "#### Optimize gpt2 to review movies positively based on a corpus of IMDB reviews with sentiment scores from DistilBert.\n",
        "\n",
        "Notebook by [@zswitten](https://github.com/zswitten)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/CarperAI/trlx/blob/main/examples/summarize_daily_cnn/t5_summarize_daily_cnn.py\n",
        "\n",
        "# 这是flan-t5-用来做summarize的例子  可见是可以用的\n",
        "\n",
        "# 见最下面"
      ],
      "metadata": {
        "id": "VVUVBR4kL6MQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[TODO]剩下要做的就是把peft弄进来"
      ],
      "metadata": {
        "id": "FUKNvJqbfOSI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[20230417学习经验]\n",
        "\n",
        "使用google的T5系列以及FLAN-T5系列模型\n",
        "在使用trlX框架训练时，训练过程会先tokenize samples=imdb['text']的每一条样本文字\n",
        "比如samples使用了imdb['text'][:20]那么tokenize操作20次\n",
        "但是目前感觉trlX实现的有问题\n",
        "会大量报warning\n",
        "Using bos_token, but it is not set yet.\n",
        "Using bos_token, but it is not set yet.\n",
        "Using bos_token, but it is not set yet.\n",
        "Using bos_token, but it is not set yet.\n",
        "看issue 讨论 开发者是修复了手动加入special token的bug 但是为何还是会上报 这就不知道了\n",
        "\n",
        "也就是说 如果样本是20000条 那么这个\n",
        "Using bos_token, but it is not set yet.\n",
        "Using bos_token, but it is not set yet.\n",
        "Using bos_token, but it is not set yet.\n",
        "Using bos_token, but it is not set yet.\n",
        "就会print 20000次 很尬 会造成缓冲区胀满\n",
        "\n",
        "# 但是实际上这些输出执行完毕后 还是能正常训练的！！！\n"
      ],
      "metadata": {
        "id": "owMpqN-kOFo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[20230416学习经验]\n",
        "\n",
        "原先是用POSITIVE值当作value\n",
        "这一版本我测试把metric_fn中用NEGATIVE值当作value\n",
        "\n",
        "这样metric_fn输出的logtis有两个位置，正向文字概率和负向情感文字概率，我们现在是把负向情感文字的概率当score\n",
        "\n",
        "那么除了把字典里面的key换成NEGATIVE之外\n",
        "还需要把\n",
        "\n",
        "trainer = trlx.train(\n",
        "    samples=imdb[\"text\"],  #输入文本\n",
        "    rewards=[1.0 - value  for value in imdb[\"label\"]],\n",
        "    . . .\n",
        "\n",
        "的rewards值用1做差 这样原先negative label=0  ，positive label=1\n",
        "\n",
        "现在 negative label=1  ，positive label=0 \n",
        "\n",
        "正好label又作为reward的奖励指引 所以意味着negative奖励为1 大于positive 奖励为0 \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Q4oU3DPyfSvj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "训练超参数调整可以直接改key的value 注意default_config['train']['total_steps']才是决定训练步数的\n",
        "\n",
        "default_config['train']['batch_size'] = 8\n",
        "\n",
        "default_config['train']['epochs'] = 10\n",
        "\n",
        "default_config['train']['total_steps'] = 2000"
      ],
      "metadata": {
        "id": "VhhfiP6Rg6t-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ykXFmnijfSY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCXUuMEMAtFz",
        "outputId": "4416281a-5c25-4a40-c910-e9287f9c40d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%pip install torch==2.0.0\n",
        "#%pip install -Uqq circuitsvis"
      ],
      "metadata": {
        "id": "Za9FLejACW0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %pip uninstall numpy\n",
        "# %pip install numpy==1.23.5\n",
        "# %pip install torch --extra-index-url https://download.pytorch.org/whl/cu116"
      ],
      "metadata": {
        "id": "0cogvnKYAvvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %pip install -Uqq git+https://github.com/neelnanda-io/TransformerLens\n",
        "#%pip install -Uqq circuitsvis"
      ],
      "metadata": {
        "id": "FlmGzK8E_VUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %pip uninstall numpy\n",
        "# %pip install numpy==1.23.5\n"
      ],
      "metadata": {
        "id": "DGakWZ4pDz9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %pip uninstall torch"
      ],
      "metadata": {
        "id": "vnoW25pnEq5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %pip install torch==1.13.1+cu116 --extra-index-url https://download.pytorch.org/whl/cu116"
      ],
      "metadata": {
        "id": "ghvqjL1OEprJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir -p /content/drive/MyDrive/trlx_0403"
      ],
      "metadata": {
        "id": "lO8lrZ_jA2-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/trlx_0403"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLViXDSzBKmi",
        "outputId": "d9abfcec-e344-4a57-ed4c-bc4a8eaed688"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/trlx_0403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKuuBx0teMb7"
      },
      "source": [
        "Execute the cells below to install [TRLX](https://github.com/CarperAI/trlx) for a colab environment."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install datasets loralib sentencepiece torchtyping opendelta transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9C8N34Z8GR1",
        "outputId": "618be038-d1ff-4b0d-b557-8e8eb9758d0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.11.0-py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.7/468.7 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting loralib\n",
            "  Downloading loralib-0.1.1-py3-none-any.whl (8.8 kB)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.98-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchtyping\n",
            "  Downloading torchtyping-0.1.4-py3-none-any.whl (17 kB)\n",
            "Collecting opendelta\n",
            "  Downloading opendelta-0.3.2-py3-none-any.whl (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.1/88.1 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets) (23.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (4.65.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.4.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.5.3)\n",
            "Collecting dill<0.3.7,>=0.3.0\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets) (1.22.4)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (6.0)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from torchtyping) (2.0.0+cu118)\n",
            "Collecting typeguard>=2.11.1\n",
            "  Downloading typeguard-3.0.2-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.9/dist-packages (from opendelta) (13.3.3)\n",
            "Collecting web.py\n",
            "  Downloading web.py-0.62.tar.gz (623 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m623.2/623.2 kB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from opendelta) (1.10.1)\n",
            "Collecting gitpython\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sklearn\n",
            "  Downloading sklearn-0.0.post4.tar.gz (3.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from opendelta) (4.4.2)\n",
            "Collecting delta-center-client==0.0.4\n",
            "  Downloading delta_center_client-0.0.4-py3-none-any.whl (8.5 kB)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Collecting oss2==2.15.0\n",
            "  Downloading oss2-2.15.0.tar.gz (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.4/226.4 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting crcmod>=1.7\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pycryptodome>=3.4.7\n",
            "  Downloading pycryptodome-3.17-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aliyun-python-sdk-kms>=2.4.1\n",
            "  Downloading aliyun_python_sdk_kms-2.16.0-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.4/67.4 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aliyun-python-sdk-core>=2.13.12\n",
            "  Downloading aliyun-python-sdk-core-2.13.36.tar.gz (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.5/440.5 kB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from oss2==2.15.0->delta-center-client==0.0.4->opendelta) (1.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->torchtyping) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->torchtyping) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->torchtyping) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->torchtyping) (2.0.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.7.0->torchtyping) (16.0.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.7.0->torchtyping) (3.25.2)\n",
            "Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.9/dist-packages (from typeguard>=2.11.1->torchtyping) (6.3.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.9/dist-packages (from rich->opendelta) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from rich->opendelta) (2.14.0)\n",
            "Collecting cheroot\n",
            "  Downloading cheroot-9.0.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.6/100.6 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=3.6->typeguard>=2.11.1->torchtyping) (3.15.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.9/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->opendelta) (0.1.2)\n",
            "Requirement already satisfied: more-itertools>=2.6 in /usr/local/lib/python3.9/dist-packages (from cheroot->web.py->opendelta) (9.1.0)\n",
            "Collecting jaraco.functools\n",
            "  Downloading jaraco.functools-3.6.0-py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.7.0->torchtyping) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.7.0->torchtyping) (1.3.0)\n",
            "Collecting jmespath<1.0.0,>=0.9.3\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: cryptography>=2.6.0 in /usr/local/lib/python3.9/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2==2.15.0->delta-center-client==0.0.4->opendelta) (40.0.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.9/dist-packages (from cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2==2.15.0->delta-center-client==0.0.4->opendelta) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.12->cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2==2.15.0->delta-center-client==0.0.4->opendelta) (2.21)\n",
            "Building wheels for collected packages: oss2, sklearn, web.py, aliyun-python-sdk-core, crcmod\n",
            "  Building wheel for oss2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for oss2: filename=oss2-2.15.0-py3-none-any.whl size=103449 sha256=ae87b5688791f13af6a224888cd7d1b9861355c6379ce46ae909c1e0343ca95d\n",
            "  Stored in directory: /root/.cache/pip/wheels/49/4e/74/90bd63fac3f168009ccd1087e62634827673ab4e0c72876f21\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post4-py3-none-any.whl size=2973 sha256=e347d08c960c5afe4f482940ac0873017a97660467b9e9faa562ad46f8e1dde6\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/b2/a9/590d15767d34955f20a9a033e8db973b79cb5672d95790c0a9\n",
            "  Building wheel for web.py (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for web.py: filename=web.py-0.62-py3-none-any.whl size=78567 sha256=0f3396fff7119212bd1e6e2022df5ffaf9fcbd506e0b6beedb42d7690c2d3cfa\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/ff/04/fabb5b4645583ec51fe5a96ed47cc0f39fa4d4b932ea9bca0b\n",
            "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for aliyun-python-sdk-core: filename=aliyun_python_sdk_core-2.13.36-py3-none-any.whl size=533194 sha256=345ef690c7a4b37f95f70f0c358508774a89227bb8bc0f9482ffe22652e339ad\n",
            "  Stored in directory: /root/.cache/pip/wheels/10/0a/92/f08c7b2c2cee2e47cffbb64fa291e5a30b24e77c726da41e31\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp39-cp39-linux_x86_64.whl size=36926 sha256=731acef3af17514fc0c1abac062f1e792c2224de9d8e7a51d83f272f60e1f397\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/6c/a6/ffdd136310039bf226f2707a9a8e6857be7d70a3fc061f6b36\n",
            "Successfully built oss2 sklearn web.py aliyun-python-sdk-core crcmod\n",
            "Installing collected packages: tokenizers, sklearn, sentencepiece, crcmod, yacs, xxhash, smmap, pycryptodome, multidict, loralib, jmespath, jaraco.functools, frozenlist, dill, async-timeout, yarl, typeguard, responses, multiprocess, huggingface-hub, gitdb, cheroot, aiosignal, web.py, transformers, gitpython, aliyun-python-sdk-core, aiohttp, aliyun-python-sdk-kms, oss2, datasets, delta-center-client, torchtyping, opendelta\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 aliyun-python-sdk-core-2.13.36 aliyun-python-sdk-kms-2.16.0 async-timeout-4.0.2 cheroot-9.0.0 crcmod-1.7 datasets-2.11.0 delta-center-client-0.0.4 dill-0.3.6 frozenlist-1.3.3 gitdb-4.0.10 gitpython-3.1.31 huggingface-hub-0.13.4 jaraco.functools-3.6.0 jmespath-0.10.0 loralib-0.1.1 multidict-6.0.4 multiprocess-0.70.14 opendelta-0.3.2 oss2-2.15.0 pycryptodome-3.17 responses-0.18.0 sentencepiece-0.1.98 sklearn-0.0.post4 smmap-5.0.0 tokenizers-0.13.3 torchtyping-0.1.4 transformers-4.28.1 typeguard-3.0.2 web.py-0.62 xxhash-3.2.0 yacs-0.1.8 yarl-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SY2PWyE7RFrV",
        "outputId": "c9b5652d-4b82-463a-bfd4-11d85c504f9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'trlx'...\n",
            "remote: Enumerating objects: 6526, done.\u001b[K\n",
            "remote: Counting objects: 100% (521/521), done.\u001b[K\n",
            "remote: Compressing objects: 100% (281/281), done.\u001b[K\n",
            "remote: Total 6526 (delta 335), reused 376 (delta 238), pack-reused 6005\u001b[K\n",
            "Receiving objects: 100% (6526/6526), 46.61 MiB | 13.02 MiB/s, done.\n",
            "Resolving deltas: 100% (4208/4208), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/CarperAI/trlx.git\n",
        "#!git config --global --add safe.directory /content/trlx && cd /content/trlx && pip install -e ."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "进入到trlx源码目录\n",
        "\n",
        "使用pip install -e . \n",
        "\n",
        "以开发模式安装当前目录下的whatever packages\n",
        "参考[https://www.reddit.com/r/learnpython/comments/ayx7za/how_does_pip_install_e_work_is_there_a_specific/]\n",
        "\"Use the program pip to install whatever package is in the current directory/folder in development mode\""
      ],
      "metadata": {
        "id": "6SllT0veKE3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/trlx_0403/trlx\n",
        "!pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOUTqpLxBWnb",
        "outputId": "826475d9-a18f-4d55-85fc-0f5ae51e9ee6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/trlx_0403/trlx\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/drive/MyDrive/trlx_0403/trlx\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ray@ https://ray-ci-artifact-branch-public.s3.amazonaws.com/42bb0357a6fb13e4994789c824f3623f32869ad8/tmp/artifacts/.whl/ray-3.0.0.dev0-cp39-cp39-manylinux2014_x86_64.whl\n",
            "  Downloading https://ray-ci-artifact-branch-public.s3.amazonaws.com/42bb0357a6fb13e4994789c824f3623f32869ad8/tmp/artifacts/.whl/ray-3.0.0.dev0-cp39-cp39-manylinux2014_x86_64.whl (58.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate>=0.17.1\n",
            "  Downloading accelerate-0.18.0-py3-none-any.whl (215 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.3/215.3 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting deepspeed>=0.8.1\n",
            "  Downloading deepspeed-0.9.0.tar.gz (764 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m764.8/764.8 kB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting wandb>=0.13.5\n",
            "  Downloading wandb-0.14.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cattrs>=22.2.0\n",
            "  Downloading cattrs-22.2.0-py3-none-any.whl (35 kB)\n",
            "Collecting tritonclient\n",
            "  Downloading tritonclient-2.32.0-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tabulate>=0.9.0\n",
            "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.9/dist-packages (from trlx==0.6.0) (13.3.3)\n",
            "Collecting einops>=0.4.1\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: datasets in /usr/local/lib/python3.9/dist-packages (from trlx==0.6.0) (2.11.0)\n",
            "Requirement already satisfied: torchtyping in /usr/local/lib/python3.9/dist-packages (from trlx==0.6.0) (0.1.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from trlx==0.6.0) (3.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from trlx==0.6.0) (4.65.0)\n",
            "Requirement already satisfied: attrs>=22.1.0 in /usr/local/lib/python3.9/dist-packages (from trlx==0.6.0) (22.2.0)\n",
            "Collecting numpy>=1.23.2\n",
            "  Downloading numpy-1.24.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers>=4.21.2 in /usr/local/lib/python3.9/dist-packages (from trlx==0.6.0) (4.28.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from accelerate>=0.17.1->trlx==0.6.0) (23.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from accelerate>=0.17.1->trlx==0.6.0) (5.9.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from accelerate>=0.17.1->trlx==0.6.0) (6.0)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from accelerate>=0.17.1->trlx==0.6.0) (2.0.0+cu118)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.9/dist-packages (from cattrs>=22.2.0->trlx==0.6.0) (1.1.1)\n",
            "Collecting hjson\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja\n",
            "  Downloading ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.0/146.0 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.9/dist-packages (from deepspeed>=0.8.1->trlx==0.6.0) (9.0.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.9/dist-packages (from deepspeed>=0.8.1->trlx==0.6.0) (1.10.7)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.21.2->trlx==0.6.0) (0.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers>=4.21.2->trlx==0.6.0) (3.11.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers>=4.21.2->trlx==0.6.0) (2.27.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.21.2->trlx==0.6.0) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.21.2->trlx==0.6.0) (0.13.3)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.19.1-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.9/dist-packages (from wandb>=0.13.5->trlx==0.6.0) (8.1.3)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from wandb>=0.13.5->trlx==0.6.0) (4.5.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.15.0 in /usr/local/lib/python3.9/dist-packages (from wandb>=0.13.5->trlx==0.6.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from wandb>=0.13.5->trlx==0.6.0) (67.6.1)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb>=0.13.5->trlx==0.6.0) (3.1.31)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.9/dist-packages (from wandb>=0.13.5->trlx==0.6.0) (1.4.4)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from datasets->trlx==0.6.0) (0.70.14)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from datasets->trlx==0.6.0) (0.18.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets->trlx==0.6.0) (3.8.4)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from datasets->trlx==0.6.0) (0.3.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from datasets->trlx==0.6.0) (3.2.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets->trlx==0.6.0) (9.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets->trlx==0.6.0) (1.5.3)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets->trlx==0.6.0) (2023.4.0)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.9/dist-packages (from ray@ https://ray-ci-artifact-branch-public.s3.amazonaws.com/42bb0357a6fb13e4994789c824f3623f32869ad8/tmp/artifacts/.whl/ray-3.0.0.dev0-cp39-cp39-manylinux2014_x86_64.whl->trlx==0.6.0) (1.3.3)\n",
            "Requirement already satisfied: grpcio>=1.32.0 in /usr/local/lib/python3.9/dist-packages (from ray@ https://ray-ci-artifact-branch-public.s3.amazonaws.com/42bb0357a6fb13e4994789c824f3623f32869ad8/tmp/artifacts/.whl/ray-3.0.0.dev0-cp39-cp39-manylinux2014_x86_64.whl->trlx==0.6.0) (1.53.0)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.9/dist-packages (from ray@ https://ray-ci-artifact-branch-public.s3.amazonaws.com/42bb0357a6fb13e4994789c824f3623f32869ad8/tmp/artifacts/.whl/ray-3.0.0.dev0-cp39-cp39-manylinux2014_x86_64.whl->trlx==0.6.0) (1.3.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.9/dist-packages (from ray@ https://ray-ci-artifact-branch-public.s3.amazonaws.com/42bb0357a6fb13e4994789c824f3623f32869ad8/tmp/artifacts/.whl/ray-3.0.0.dev0-cp39-cp39-manylinux2014_x86_64.whl->trlx==0.6.0) (4.3.3)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from ray@ https://ray-ci-artifact-branch-public.s3.amazonaws.com/42bb0357a6fb13e4994789c824f3623f32869ad8/tmp/artifacts/.whl/ray-3.0.0.dev0-cp39-cp39-manylinux2014_x86_64.whl->trlx==0.6.0) (1.0.5)\n",
            "Collecting virtualenv>=20.0.24\n",
            "  Downloading virtualenv-20.21.0-py3-none-any.whl (8.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m110.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from rich->trlx==0.6.0) (2.14.0)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.9/dist-packages (from rich->trlx==0.6.0) (2.2.0)\n",
            "Requirement already satisfied: typeguard>=2.11.1 in /usr/local/lib/python3.9/dist-packages (from torchtyping->trlx==0.6.0) (3.0.2)\n",
            "Collecting python-rapidjson>=0.9.1\n",
            "  Downloading python_rapidjson-1.10-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->trlx==0.6.0) (1.16.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->trlx==0.6.0) (1.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->trlx==0.6.0) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->trlx==0.6.0) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->trlx==0.6.0) (4.0.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->trlx==0.6.0) (4.0.10)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.9/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->trlx==0.6.0) (0.1.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers>=4.21.2->trlx==0.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers>=4.21.2->trlx==0.6.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers>=4.21.2->trlx==0.6.0) (2022.12.7)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.4.0->accelerate>=0.17.1->trlx==0.6.0) (1.11.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.4.0->accelerate>=0.17.1->trlx==0.6.0) (2.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.4.0->accelerate>=0.17.1->trlx==0.6.0) (3.1.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.4.0->accelerate>=0.17.1->trlx==0.6.0) (16.0.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.4.0->accelerate>=0.17.1->trlx==0.6.0) (3.25.2)\n",
            "Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.9/dist-packages (from typeguard>=2.11.1->torchtyping->trlx==0.6.0) (6.3.0)\n",
            "Collecting distlib<1,>=0.3.6\n",
            "  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.5/468.5 kB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs<4,>=2.4 in /usr/local/lib/python3.9/dist-packages (from virtualenv>=20.0.24->ray@ https://ray-ci-artifact-branch-public.s3.amazonaws.com/42bb0357a6fb13e4994789c824f3623f32869ad8/tmp/artifacts/.whl/ray-3.0.0.dev0-cp39-cp39-manylinux2014_x86_64.whl->trlx==0.6.0) (3.2.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema->ray@ https://ray-ci-artifact-branch-public.s3.amazonaws.com/42bb0357a6fb13e4994789c824f3623f32869ad8/tmp/artifacts/.whl/ray-3.0.0.dev0-cp39-cp39-manylinux2014_x86_64.whl->trlx==0.6.0) (0.19.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets->trlx==0.6.0) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets->trlx==0.6.0) (2.8.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.9/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->trlx==0.6.0) (5.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=3.6->typeguard>=2.11.1->torchtyping->trlx==0.6.0) (3.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.4.0->accelerate>=0.17.1->trlx==0.6.0) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.4.0->accelerate>=0.17.1->trlx==0.6.0) (1.3.0)\n",
            "Building wheels for collected packages: trlx, deepspeed, pathtools\n",
            "  Building editable for trlx (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for trlx: filename=trlx-0.6.0-0.editable-py3-none-any.whl size=6458 sha256=a6d427a15f0c45cb2f71123d972b31215751f87738e1bf61dea026b1ca05dc72\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-48il24eb/wheels/ed/ab/b3/e8448e0d64a441344ab0f3cb73359c98b01640aeada4fc1ec0\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.9.0-py3-none-any.whl size=797726 sha256=9325a5b1498265f686b8608e4881eaaa15289fd15b88cb455beee294b168a60b\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/bc/03/7c71f2235ee568d187c1114c2e5f1995c4dfff7a3f58d1b6c8\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=a4f85bec4b007788ea144aa797c2b7f00135fc7bf8a2a023bf9cb2213692a320\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/0a/67/ada2a22079218c75a88361c0782855cc72aebc4d18d0289d05\n",
            "Successfully built trlx deepspeed pathtools\n",
            "Installing collected packages: pathtools, ninja, hjson, distlib, virtualenv, tabulate, setproctitle, sentry-sdk, python-rapidjson, numpy, einops, docker-pycreds, cattrs, tritonclient, ray, wandb, deepspeed, accelerate, trlx\n",
            "  Attempting uninstall: tabulate\n",
            "    Found existing installation: tabulate 0.8.10\n",
            "    Uninstalling tabulate-0.8.10:\n",
            "      Successfully uninstalled tabulate-0.8.10\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.24.2 which is incompatible.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.18.0 cattrs-22.2.0 deepspeed-0.9.0 distlib-0.3.6 docker-pycreds-0.4.0 einops-0.6.0 hjson-3.1.0 ninja-1.11.1 numpy-1.24.2 pathtools-0.1.2 python-rapidjson-1.10 ray-3.0.0.dev0 sentry-sdk-1.19.1 setproctitle-1.3.2 tabulate-0.9.0 tritonclient-2.32.0 trlx-0.6.0 virtualenv-20.21.0 wandb-0.14.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy \n",
        "# numpy.__version__"
      ],
      "metadata": {
        "id": "49uCgILm0me6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3w8KNGigg9C",
        "outputId": "863026c9-322b-4299-8dc8-cf3fdb29449d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: scikit-learn 1.2.2\n",
            "Uninstalling scikit-learn-1.2.2:\n",
            "  Successfully uninstalled scikit-learn-1.2.2\n",
            "Found existing installation: jax 0.4.8\n",
            "Uninstalling jax-0.4.8:\n",
            "  Successfully uninstalled jax-0.4.8\n"
          ]
        }
      ],
      "source": [
        "# uninstall scikit_learn + jax to avoid numpy issues\n",
        "!pip uninstall -y scikit_learn jax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxgxiK3CVz9L",
        "outputId": "3e0d2095-5cdd-4603-adfa-69027d97d76d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/trlx_0403/trlx\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# run within repo\n",
        "os.chdir('/content/drive/MyDrive/trlx_0403/trlx')\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import wandb\n",
        "# wandb.init(mode=\"disabled\")"
      ],
      "metadata": {
        "id": "6Gcte7aWzRYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1aurCtZoBKkI"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "from datasets import load_dataset\n",
        "from transformers import pipeline,AutoTokenizer,AutoModelForCausalLM\n",
        "import pathlib\n",
        "from typing import Dict, List\n",
        "import trlx\n",
        "from trlx.data.default_configs import TRLConfig, default_ilql_config"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from trlx.data.configs import (\n",
        "    ModelConfig,\n",
        "    OptimizerConfig,\n",
        "    SchedulerConfig,\n",
        "    TokenizerConfig,\n",
        "    TrainConfig,\n",
        "    TRLConfig,\n",
        ")\n",
        "from trlx.models.modeling_ppo import PPOConfig\n",
        "from trlx.models.modeling_ilql import ILQLConfig"
      ],
      "metadata": {
        "id": "OrsR8OLsf4z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# default_config = default_ilql_config().to_dict()\n",
        "# print(type(default_config))\n",
        "# print(default_config)\n",
        "# default_config['method']\n"
      ],
      "metadata": {
        "id": "nD7VDqiRKDZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(default_config)"
      ],
      "metadata": {
        "id": "Lp0_bUcZkv8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# train=TrainConfig(\n",
        "#         seq_length=64,\n",
        "#         epochs=100,\n",
        "#         total_steps=1000,\n",
        "#         batch_size=1,\n",
        "#         checkpoint_interval=100,\n",
        "#         eval_interval=10,\n",
        "#         pipeline=\"PromptPipeline\",\n",
        "#         trainer=\"AccelerateILQLTrainer\",\n",
        "#         tracker=None, #default is wandb\n",
        "#     )\n",
        "# model=ModelConfig(\n",
        "#         model_path=\"google/flan-t5-small\",\n",
        "#         model_arch_type=\"seq2seq\",\n",
        "#         num_layers_unfrozen=2,\n",
        "#     )\n",
        "# tokenizer=TokenizerConfig(\n",
        "#         tokenizer_path=\"google/flan-t5-small\",\n",
        "#         truncation_side=\"right\",\n",
        "#     )\n",
        "# optimizer=OptimizerConfig(\n",
        "#         name=\"adamw\",\n",
        "#         kwargs={\n",
        "#             \"lr\": 1.0e-5,\n",
        "#             \"betas\": [0.9, 0.999],\n",
        "#             \"eps\": 1.0e-8,\n",
        "#             \"weight_decay\": 1.0e-6,\n",
        "#         },\n",
        "#     )\n",
        "# scheduler=SchedulerConfig(\n",
        "#         name=\"cosine_annealing\",\n",
        "#         kwargs={\n",
        "#             \"T_max\": 10000,\n",
        "#             \"eta_min\": 1.0e-6,\n",
        "#         },\n",
        "#     )\n",
        "   \n"
      ],
      "metadata": {
        "id": "l1ZGOPWfeB_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# default_config = default_ilql_config()\n",
        "# default_ilql_config().method"
      ],
      "metadata": {
        "id": "DOniohhmmdJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# default_config = default_ilql_config().to_dict()\n",
        "# default_config['train'] = train\n",
        "# default_config['model'] = model\n",
        "# default_config['tokenizer'] = tokenizer\n",
        "# default_config['optimizer'] = optimizer\n",
        "# default_config['scheduler'] = scheduler\n",
        "\n",
        "# #config = TRLConfig.update(default_config, {})\n",
        "# print(default_config)\n",
        "\n",
        "\n",
        "# print(config)"
      ],
      "metadata": {
        "id": "8QLgp8IXiEXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T67-KvxzBtkg"
      },
      "outputs": [],
      "source": [
        "# default_config =default_config.to_dict()\n",
        "# default_config['train']['tracker'] = None\n",
        "# default_config['train']['batch_size'] = 8\n",
        "# default_config['train']['epochs'] = 10\n",
        "# default_config['train']['total_steps'] = 2000\n",
        "# #我们换成t5-small 试试\n",
        "# #  t5:11B gpt2:1.5B t5-small:6000万\n",
        "# #注意t5 \n",
        "# default_config['model']['model_path'] = 'google/flan-t5-small'  #model_arch_type =se12seq\n",
        "# default_config['model']['model_arch_type'] = 'seq2seq'\n",
        "# default_config['model']['num_layers_unfrozen'] = 2\n",
        "# default_config[\"tokenizer\"][\"padding_side\"] = \"right\"\n",
        "# default_config[\"tokenizer\"][\"tokenizer_path\"] ='google/flan-t5-small' \n",
        "# #default_config[\"method\"][\"gen_kwargs\"]['bos_token'] = '<s>'\n",
        "# #default_config['train']['gradient_accumulation_steps']=2\n",
        "# config = TRLConfig.update(default_config, {})\n",
        "# print(config)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#os.environ['WANDB_SILENT']=\"true\""
      ],
      "metadata": {
        "id": "iqocgse_yluh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# google/flan-t5-large + ILQL, no LORA"
      ],
      "metadata": {
        "id": "64HMM6BuI1Bh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "用FLAN-T5试试 ，不用gpt2 ，注意config的定义方法"
      ],
      "metadata": {
        "id": "ez8K9n5g-Swv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = TRLConfig(\n",
        "    train=TrainConfig(\n",
        "        seq_length=256,\n",
        "        epochs=100,\n",
        "        total_steps=1000,\n",
        "        batch_size=8,\n",
        "        checkpoint_interval=100,\n",
        "        eval_interval=10,\n",
        "        pipeline=\"PromptPipeline\",\n",
        "        trainer=\"AccelerateILQLTrainer\",#\"AcceleratePPOTrainer\", #\n",
        "        tracker=None, #default is wandb\n",
        "    ),\n",
        "    model=ModelConfig(\n",
        "        model_path=\"google/flan-t5-large\",\n",
        "        model_arch_type=\"seq2seq\",\n",
        "        num_layers_unfrozen=2,\n",
        "    ),\n",
        "    tokenizer=TokenizerConfig(\n",
        "        tokenizer_path=\"google/flan-t5-large\",\n",
        "        truncation_side=\"right\",\n",
        "    ),\n",
        "    optimizer=OptimizerConfig(\n",
        "        name=\"adamw\",\n",
        "        kwargs={\n",
        "            \"lr\": 1.0e-5,\n",
        "            \"betas\": [0.9, 0.999],\n",
        "            \"eps\": 1.0e-8,\n",
        "            \"weight_decay\": 1.0e-6,\n",
        "        },\n",
        "    ),\n",
        "    scheduler=SchedulerConfig(\n",
        "        name=\"cosine_annealing\",\n",
        "        kwargs={\n",
        "            \"T_max\": 10000,\n",
        "            \"eta_min\": 1.0e-6,\n",
        "        },\n",
        "    ),\n",
        "    method=ILQLConfig(name='ilqlconfig', \n",
        "               tau=0.7, \n",
        "               gamma=0.99, \n",
        "               cql_scale=0.1, \n",
        "               awac_scale=1, alpha=0.001, \n",
        "               beta=0, \n",
        "               steps_for_target_q_sync=5, \n",
        "               two_qs =True,\n",
        "               gen_kwargs={'max_new_tokens': 56, \n",
        "                    'top_k': 20, \n",
        "                    'beta': 1,\n",
        "                     'temperature': 1.0}\n",
        "        ),\n",
        "    # method =ILQLConfig(\n",
        "        \n",
        "    #     name =\"ILQLConfig\",\n",
        "    #     tau =  0.7,\n",
        "    #     gamma = 0.99,\n",
        "    #     cql_scale = 0.1,\n",
        "    #     awac_scale =  1,\n",
        "    #     alpha =  0.001,\n",
        "    #     beta =  0,\n",
        "    #     steps_for_target_q_sync =  5,\n",
        "    #     two_qs = True,\n",
        "    #     gen_kwargs={\n",
        "            \n",
        "    #         \"max_new_tokens\": 56,\n",
        "    #         \"top_k\": 20,\n",
        "    #         \"beta\": 1,\n",
        "    #         \"temperature\": 1.0\n",
        "    #     }\n",
        "    # ),\n",
        ")"
      ],
      "metadata": {
        "id": "_kZ6zG15G54u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#这里解释一下 get_positive_score(scores) 的作用方式\n",
        "scores = [\n",
        "    { \"SENTIMENT\":\"POSITIVE\", \"score\": 0.8},\n",
        "   { \"SENTIMENT\":\"NEGETIVE\", \"score\": 0.2},\n",
        "    #{ \"SENTIMENT\":\"NEUTRAL\", \"score\": 0.1},\n",
        "]\n",
        "# Apply the map() and dict() functions to extract the value associated with the \"POSITIVE\" key\n",
        "'''\n",
        "这里map函数的用法: map(func ,list[或者其他iterable比如tuple，dict])\n",
        "func这里的入参是list中的元素而不是list本身\n",
        "func这里具体的实现是一个lambda函数 函数的入参x是list中的一个字典结构元素，比如{ \"SENTIMENT\":\"POSITIVE\", \"score\": 0.8}\n",
        "lambda函数将这个字典结构（本身是{k1:v1 , k2:v2}）转换成元组，因为只提取了每个x.values(),所以元组中的值只包含v1和v2\n",
        "即各个tuple组成了一个list 为 [('POSITIVE',0.8),(\"NEGATIVE\",-0.4)]\n",
        "然后又使用dict函数将该list转为字典{'POSITIVE':0.8,\"NEGATIVE\":-0.4}\n",
        "可以测试这段代码就明白\n",
        ">>> a=[(1,2),(3,4)]\n",
        ">>> a\n",
        "[(1, 2), (3, 4)]\n",
        ">>> dict(a)\n",
        "{1: 2, 3: 4}\n",
        "最后只取字典中\"POSITIVE\"对应的值作为最终的评分\n",
        "\n",
        "结合下面代码\n",
        "trainer = trlx.train(\n",
        "    samples=imdb[\"text\"], \n",
        "    rewards=imdb[\"label\"],\n",
        "    ....\n",
        "来看 这个rewards=imdb['label']的取值只有0和1 ，0代表负面，1代表正面，这个reward的定义方式就是鼓励输出正面，因为这样奖励值大（1>0）\n",
        "正好又能代表奖励，即输出负面文字奖励值低（为0），输出正面文字奖励值高（1）\n",
        "而positive_score = dict(map(lambda x: tuple(x.values()), scores))[\"POSITIVE\"]这个值是由distiBERT模型评价transfoermer模型输出文字的得分\n",
        "其实这个得分就是归一化的分布概率，就是softmax最后输出的那个玩意 想起来没，就是logits，所以加起来是1。这里只不过用到了带温度的softmax，本质一样都是logits。\n",
        "这个得分要越高越好，而这正是ILQL或者PPO算法通过得分positive score值返过去调整transformer模型参数来实现的。\n",
        "'''\n",
        "\n",
        "positive_score = dict(map(lambda x: tuple(x.values()), scores))[\"POSITIVE\"]\n",
        "\n",
        "#每个x是{ \"SENTIMENT\":\"POSITIVE\", \"score\": 0.8} x.values()是两个值，tuple之后是(\"POSITIVE\",0.8),dict就是{\"POSITIVE\":0.8}\n",
        "#把所有的x都考虑上 dict最后就是{\"POSITIVE\":0.8  ,\"NEGATIVE\":-0.4 ,\"NEUTRAL\":0.2}\n",
        "print(dict(map(lambda x: tuple(x.values()), scores)))\n",
        "# Print the value associated with the \"POSITIVE\" key 这步就是取出其中的POSITIVE对应的值当作奖励值\n",
        "print(positive_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8pRPiLUCqrz",
        "outputId": "87f70352-84b9-4452-8e78-498729b29aa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'POSITIVE': 0.8, 'NEGETIVE': 0.2}\n",
            "0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "hq8GFfs7TMg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4m0dbDrTqo5",
        "outputId": "f732e4e4-61de-4862-a0e8-4fa9322339c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201,
          "referenced_widgets": [
            "686000c9e36f41149539cb1775f1add9",
            "5cfe39c4f840474c8fb4496d71e1fa29",
            "0a368e2e9d864678920ee5e14aa552f2",
            "4d65713bfbbf403c8a6bf033a0d695cc",
            "7bd0a22547fd434b9153571cdb7d4cbc",
            "ee2e9084efc94a57aa3b58555ab55402",
            "db57a69093484d0f87e7aac9139a6254",
            "8d75ca1cd8574673baac42cf288c0166",
            "d7618e562fe54de68ff9bd867bb543a9",
            "46ffc586d453485e8eb430b19e19142f",
            "d97eb077de4146fdb3f874de12f8bc19",
            "eed05ffd5d3f49e7a1a9dc3759e4f8d3",
            "e8615fe3a2524084a39edb1c48134f71",
            "6217bf69887e40c9b0a99338b5a2c175",
            "ad74cfdebaf440ba8b38c13c4083e8a9",
            "ac33b6d7a3d048e5833f8f017f3d32bf",
            "c23b04f65aca40b79c58685a793c36a9",
            "0df4ac0568024bffa565a6354bcbbec4",
            "4e09959706804306b65ffa0e82a1c916",
            "b53c38a9d464426fb4352dcfa6c9e9f3",
            "82db8ff5b53d46529375ba75a1a1ccd9",
            "267b561006e64303820b42d9887fba20",
            "df2dd0f0a48646c08739fefe71d8543f",
            "30c0f2fdfaa94cde8bde05bd37255ac2",
            "5dbfd72eba194bf482d6fe013a66e9f4",
            "aab84284c1f64e4c8eaad37092df6f8c",
            "368411e5d5e3417db588160f35a3ca1a",
            "60fd0072868849c987339ecff8d46a62",
            "676253a401a14334ac6076b94dfff2b2",
            "3c1051146ae14a3fa88ba336129ca6f9",
            "b5dd4dc841d74e3f8376aac762285782",
            "b87ee69e5d7c4fb5bc2be407751733fe",
            "6129506551e54065b5811feef887345f",
            "723d5dda640e4e17a1b74759a8ee7c1f",
            "afcd7336514e4a96894279dc0b93e0c1",
            "7b19739190e4433283d728e8b955dc88",
            "681934a1030a48c49bc3ee127d6cd681",
            "a5c2a95f727b4ee0b1b93e37f4988fca",
            "0523f9a09c41433fa36752a0b9f51d43",
            "4667efa7efae4620b35136f329dcab05",
            "024c2f461151416693b4e2526c4f7206",
            "31e96aee7c73466d9ff38d2af2e74bfc",
            "4b4d6adbf3e44c7ca76bfc2d86a55d4f",
            "9c6f621299264000976411252b22dfea",
            "9ec39fb9b0394ff29aca9363ca623dfd",
            "1d68810bb3664b32a4f7e57c7d045f12",
            "dd28d1a21d014490a00e5973a08af576",
            "64d9b28a7884414d89cf32e20d879265",
            "fa5889e60b1c491a90fe248db7fa2f08",
            "7f47e0cf2ea74bba965bde5f353b41b2",
            "ffaad0a085024bc4bd9fdbb1d30caf3c",
            "95e74c34605b4f3d84844529208e92b0",
            "27e1de79a8ce4c9ca4cf7636c0d372b2",
            "02433cf760cc40ddab668ed696cf3b5c",
            "0e18eb913d364d69ae2ba709543b9455",
            "0b0f6796c33c4e86b0649c645c2ba339",
            "d82530b59187404a85d971e667ca60a8",
            "010b0d1f14404e1cbee05fc25c4f8ac0",
            "8e1097309c6d469396bf470d9eef4b58",
            "ae83af989bdf466b9531ee642b4f057c",
            "a3f41fbf522c4a75b2f759312cecbe63",
            "f3da7c2995394c7eb02c8c76048cd5d3",
            "47f500f3f1f74e82a4d1818c19e3f326",
            "e99b8fbc9d5e40548de5c89fdeaaa44d",
            "8ca87b59b6904065a79561ee6223cc58",
            "0727e12c05644de29a62091189651d7a",
            "3c1f241807404c4cbc52d1314368d6e0",
            "d07fbfa75ca048fda1fdea732ae813af",
            "1e095b5ddc1b43978b3af58ee29bb85f",
            "308eb890117c431a8b5d25d30b32695e",
            "f6a864c4949a4ef7a90315db85a7954f",
            "6f5a525e118448798b4982b760c8fb59",
            "762b2446ca8d4b0ea0b80185aea555cd",
            "46cb0a520aa54c5ebb47bc8a2dea40e6",
            "4d14bab2342c4c588a0de26905b80827",
            "e77593fa03cc4430832ffc6d5f6c5e26",
            "8cfbda2a0d8a4f5fa25265ac3303f9ed"
          ]
        },
        "id": "jPFazHi1B6xR",
        "outputId": "dc82762b-de33-489c-f507-501d5b4e6eb0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/4.31k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "686000c9e36f41149539cb1775f1add9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading metadata:   0%|          | 0.00/2.17k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eed05ffd5d3f49e7a1a9dc3759e4f8d3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/7.59k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df2dd0f0a48646c08739fefe71d8543f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset imdb/plain_text to /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/84.1M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "723d5dda640e4e17a1b74759a8ee7c1f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ec39fb9b0394ff29aca9363ca623dfd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b0f6796c33c4e86b0649c645c2ba339"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c1f241807404c4cbc52d1314368d6e0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset imdb downloaded and prepared to /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0. Subsequent calls will reuse this data.\n"
          ]
        }
      ],
      "source": [
        "def get_positive_score(scores):\n",
        "    \"Extract value associated with a positive sentiment from pipeline's output\"\n",
        "    return dict(map(lambda x: tuple(x.values()), scores))[\"NEGATIVE\"]#[\"POSITIVE\"]  #return的是一个float\n",
        "\n",
        "#pipeline huggingface提供的一种使用模型的快捷方式 参考[https://huggingface.co/docs/transformers/main_classes/pipelines]\n",
        "'''#例子\n",
        "pipe = pipeline(model=\"roberta-large-mnli\")\n",
        "pipe(\"This restaurant is awesome\")\n",
        "[{'label': 'NEUTRAL', 'score': 0.7313136458396912}]\n",
        "'''\n",
        "sentiment_fn = pipeline(\n",
        "     \n",
        "    \"sentiment-analysis\",\n",
        "    \"lvwerra/distilbert-imdb\",\n",
        "    top_k=2, #只输出POSTIVE和NEGETIVE两类的归一化概率logits\n",
        "    truncation=True,\n",
        "    batch_size=6,\n",
        "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")#0,\n",
        ")\n",
        "\n",
        "def sentiment_fn_trick_test_20230416(samples):\n",
        "   lens =len(samples)\n",
        "   return [[{'label': 'NEGATIVE', 'score': 0.76}, {'label': 'POSITIVE', 'score': 0.24}] for _ in range(lens)]\n",
        "'''\n",
        "说明一下metric_fn的作用\n",
        "samples=[影评1，影评2]\n",
        "sentiment_fn(samples)会对每个影评做一个正负情感分类，参考distilbert-imdb例子[https://huggingface.co/lvwerra/distilbert-imdb]\n",
        "sentiment_fn(samples) 是一个list= [{'label': 'NEGATIVE', 'score': 0.76}, {'label': 'POSITIVE', 'score': 0.24}]\n",
        "而map(get_positive_score, sentiment_fn(samples)) 将这个list中的每个dict转化成一个得分值score，再list一下，成为[影评1得分，影评2得分]的score_list\n",
        "最后return {'sentiments':score_list} 我觉得这个字典的key是任意写的\n",
        "'''\n",
        "\n",
        "def metric_fn(samples: List[str], **kwargs) -> Dict[str, List[float]]:\n",
        "    sentiments = list(map(get_positive_score, sentiment_fn(samples)))\n",
        "    return {\"sentiments\": sentiments}\n",
        "\n",
        "imdb = load_dataset(\"imdb\", split=\"train+test\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%cd /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0"
      ],
      "metadata": {
        "id": "fKXpUaIVmljZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%ls"
      ],
      "metadata": {
        "id": "Iy_wfwHGmoEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#原始的imdb可能结构就是个jsonl 有50000行，每行形如{'text':XXX , 'label':0 or 1}\n",
        "#然后被转成了datasets.arrow_dataset.Dataset 结构，形如{'text':[t1,t2,t3,...] ,'label':[0,1,0,...] }\n",
        "#这跟之前我尝试自定义的结构是一致的"
      ],
      "metadata": {
        "id": "7Ug5kG0usRsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#这是一种定义数据的方式 类似csv 每个key都把所有的值存成list 这个a里面是嵌套的json\n",
        "import json\n",
        "q=[1,2]\n",
        "p=[11,22]\n",
        "a={'data_filed':{'q':q ,'p':p}}\n",
        "with open('a','w') as f:\n",
        "  json.dump(a,f)  #需要序列化 是直接把整个obj序列化到文件\n",
        "#load时 由于a是嵌套json 所以需要加入filed=XX指明哪个字段\n",
        "a_load = load_dataset(\"json\", data_files=\"a\",field='data_filed')\n",
        "print(a_load)\n",
        "print(a_load['train']['q'])\n",
        "print(a_load['train'][:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369,
          "referenced_widgets": [
            "4b57316c3f524bc9b11c26e62b7e9436",
            "d6e47d5dac75448e897936d58e82989b",
            "37c49557f6ee4d13bd5d5a13c7bed603",
            "5981f16e2f08400bb43f60d3a546f08a",
            "34e8fe507e204ccab37e422a0b8b83d2",
            "19d615fa592045fbb0c34bf785165a9b",
            "7155fea914614aa8a731fef4306abbeb",
            "598f0a69ac8f4bdaac8fcb3a8957a0cb",
            "3b5cfbd7f6624b609d82187586affd94",
            "cde93d9d95cb42d2a0abde616e2f6809",
            "c02269065b9d4308a137b3cc5f45a2f9",
            "c3b1177cc33a48908119c0a6679e5e83",
            "a502d7021f874d90bd21f204452e239a",
            "3e90fd39786b483c98fd7b72380fc4ef",
            "7a6cb42745fd4985b9e76c8539de7114",
            "7797b71dc7a9495c8b0f89d55a7088d1",
            "a96a3bcfd0234687898b4410cdecd60b",
            "63d992abcc65415aa574afeeccfffd85",
            "5f89cc0bf8ee45dfbe30ae8c4ee45ed1",
            "1a2393fb5a6d44e59d7c9c0e338d5a40",
            "d9232b0b00264fee913f6b72e09e795f",
            "6007c6a18ea449d4a2bff9018aab8e65",
            "666c3a69fd9f4cc480745717a2413da9",
            "6ad1b4dbdefa4e79b6e5e46d7883c83b",
            "e37a77e30f1b4e43ac23b2861af99580",
            "1e20a124c925428ca1ecde672f7f0573",
            "edd95c00a18144a19a16df1ee74284c1",
            "a7a8dcb86d534c6dbca77d8bafd55061",
            "bee96bf3f25749bebee2b73a9511624e",
            "1a1201e1d3a94955a8125df54d7b2e68",
            "e6b230deff0042adbb5e78dffb74b1bc",
            "c34bdc0accb0427b8c1a224936a6d8d9",
            "f72c6c8fe376407382176e4e49a137b1",
            "2f7cd6e3a0014c188699afca6379d56f",
            "c253e1af3349494b8b2d7dff7895ff12",
            "32613f45e07f444dbc18fb5e1e7ef706",
            "3c0a8755a136461ebdd1089cd52fd78c",
            "912fc9be8de84e5ea3dee6290a949833",
            "788f74fae6aa47feb80aba504fd9ca00",
            "e90b8b434c7e4d8d8f2c1f1d5300b4c4",
            "1e7feab0147748b49bc2e03b3cace377",
            "f786bb2548934b7fa71026497e692b58",
            "d3b0c193bb8b4b9fa8be2ce7d4491cfb",
            "0a469bb7383a453f9432e145ae241433"
          ]
        },
        "id": "XvUhLVm0tamk",
        "outputId": "bc5b02c1-6268-4542-eb5d-5737280b1d2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-5f101f42f7729c1f/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b57316c3f524bc9b11c26e62b7e9436"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c3b1177cc33a48908119c0a6679e5e83"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "666c3a69fd9f4cc480745717a2413da9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-5f101f42f7729c1f/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f7cd6e3a0014c188699afca6379d56f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['q', 'p'],\n",
            "        num_rows: 2\n",
            "    })\n",
            "})\n",
            "[1, 2]\n",
            "{'q': [1, 2], 'p': [11, 22]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#这是另一种定义数据的方式 json或者叫jsonline 每行定义一个 1个key存1个值 不是a那样的嵌套json\n",
        "import json\n",
        "mydata = [\n",
        "    {'q':1 ,'p':11} , \n",
        "    {'q':2 ,'p':22}\n",
        "]\n",
        "\n",
        "with open('b','w') as f:\n",
        "  for item in mydata:\n",
        "    #需要序列化 是把每一个dict对象序列化再写入文件\n",
        "    json_line = json.dumps(item, ensure_ascii=False)\n",
        "    f.write(json_line + \"\\n\")\n",
        "\n",
        "\n",
        "b_load = load_dataset(\"json\", data_files=\"b\")\n",
        "print(b_load)\n",
        "print(b_load['train']['q'])\n",
        "print(b_load['train'][:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369,
          "referenced_widgets": [
            "9c1175f25f4f40d0a66659a69df21dbb",
            "700737966620420da9ae2909da2bbbce",
            "c27f83328b0b459a902c337ea747adcd",
            "d1b8ad7bc16c4edd99ce7232e1c0c626",
            "7d8c41ce2da24c4b921c1cebdd935fac",
            "315582a357814c39b720c62100c5ef2a",
            "5da2e45ceee4417eaa1cd2b953de6b58",
            "c5e5ec5ac76e4ec39a10aa3df96cdf9c",
            "22e3a233cdc847e382a9c26a3df23d48",
            "955fcb214f164ac0a3bb9ebac0db3119",
            "4644b13ae1e241e092d85a92ae7b20ca",
            "d11ebcd9ea934d858774e4b8f75e1d5e",
            "e524c38d7adb4a53aae86b968ebf8fbe",
            "6920d631feb1423fb34c4e19fd338ebc",
            "a02b6ab9baef4145ab8d1c0e05d4c739",
            "dca5ae6677b54571bc32f96f44167975",
            "329410de24df47d09a94601c912a4a96",
            "34efcd63e62140ceb909a515a170db38",
            "cdc91fb0aac8467383631a43280592c3",
            "af7214134dce4992a939fac5be347115",
            "152f647052ee46e3bc5bc0c1b61690ee",
            "66f86cb7a1b44dd08d2d25b7ad239f36",
            "ceb499487c1d4a8fbe59925154e10357",
            "182129f2e50a44a5aa5bd261d98f887e",
            "07f6c9d203454780b7cb4ebee4ef4c01",
            "d95c67a60abe4208ba38a5469e68c153",
            "d734d61d27d54c45b83454b3d410d481",
            "fc749e44b1394345ab399d4c0a72cdc3",
            "b648cb89bd3c447686adec5aaa635617",
            "a1ce8ba66790459fa9b663160a97d99d",
            "0ec80017d693485c8fd0fd11898f584d",
            "a86532955e0144018b7e370dcc7851ac",
            "dae2faed7bcf4000904b25389db651a6",
            "c2b7aaaf062c43d1a8b9835ac5e2e87d",
            "ae9906b88c77459f880e00f7978bcb17",
            "d4dbefe0775f485d8f7f14db78e3947a",
            "311584c003064ed792ec4c1a6a2eb21a",
            "22e8c564a1d04a3b9c381467252fe0e3",
            "fce87225291f4b5fbb8b03a31183d6d5",
            "4fb7d0cfc40f4b5e890d8d673e72d95d",
            "6a40ce5aa1414fa7adff6b7f5e0147c6",
            "16413fe2e8534221a3f48a20d465c245",
            "9bfb9835efb246cab867edd63c298280",
            "4b96ec03168d4b1583ea56277f462d4a"
          ]
        },
        "id": "IMdVb9YUwp3N",
        "outputId": "c0eb7e7c-18d5-4ff8-8705-4368ff283fc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-847c29d6df4d15bb/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9c1175f25f4f40d0a66659a69df21dbb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d11ebcd9ea934d858774e4b8f75e1d5e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ceb499487c1d4a8fbe59925154e10357"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-847c29d6df4d15bb/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c2b7aaaf062c43d1a8b9835ac5e2e87d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['q', 'p'],\n",
            "        num_rows: 2\n",
            "    })\n",
            "})\n",
            "[1, 2]\n",
            "{'q': [1, 2], 'p': [11, 22]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#测试一下\n",
        "print(type(imdb))\n",
        "#这种datasets.arrow_dataset.Dataset 类型的数据\n",
        "#可以按照key取值\n",
        "print(imdb['label'][:2])\n",
        "print(imdb['text'][:2])\n",
        "#也可以把所有的key对应的value list同时取相同的长度或者具体某一条sample\n",
        "print(imdb[:2]) #这是嵌套json {'text':[t1,t2] , 'label':[l1,l2]}\n",
        "print(imdb[2])  #这是jsonl结构 ｛'text':xXXX, 'label':YYY｝"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dy2rISr4liry",
        "outputId": "bdee1ee5-a82a-41a3-d421-bf511197c845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'datasets.arrow_dataset.Dataset'>\n",
            "[0, 0]\n",
            "['I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.', '\"I Am Curious: Yellow\" is a risible and pretentious steaming pile. It doesn\\'t matter what one\\'s political views are because this film can hardly be taken seriously on any level. As for the claim that frontal male nudity is an automatic NC-17, that isn\\'t true. I\\'ve seen R-rated films with male nudity. Granted, they only offer some fleeting views, but where are the R-rated films with gaping vulvas and flapping labia? Nowhere, because they don\\'t exist. The same goes for those crappy cable shows: schlongs swinging in the breeze but not a clitoris in sight. And those pretentious indie movies like The Brown Bunny, in which we\\'re treated to the site of Vincent Gallo\\'s throbbing johnson, but not a trace of pink visible on Chloe Sevigny. Before crying (or implying) \"double-standard\" in matters of nudity, the mentally obtuse should take into account one unavoidably obvious anatomical difference between men and women: there are no genitals on display when actresses appears nude, and the same cannot be said for a man. In fact, you generally won\\'t see female genitals in an American film in anything short of porn or explicit erotica. This alleged double-standard is less a double standard than an admittedly depressing ability to come to terms culturally with the insides of women\\'s bodies.']\n",
            "{'text': ['I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.', '\"I Am Curious: Yellow\" is a risible and pretentious steaming pile. It doesn\\'t matter what one\\'s political views are because this film can hardly be taken seriously on any level. As for the claim that frontal male nudity is an automatic NC-17, that isn\\'t true. I\\'ve seen R-rated films with male nudity. Granted, they only offer some fleeting views, but where are the R-rated films with gaping vulvas and flapping labia? Nowhere, because they don\\'t exist. The same goes for those crappy cable shows: schlongs swinging in the breeze but not a clitoris in sight. And those pretentious indie movies like The Brown Bunny, in which we\\'re treated to the site of Vincent Gallo\\'s throbbing johnson, but not a trace of pink visible on Chloe Sevigny. Before crying (or implying) \"double-standard\" in matters of nudity, the mentally obtuse should take into account one unavoidably obvious anatomical difference between men and women: there are no genitals on display when actresses appears nude, and the same cannot be said for a man. In fact, you generally won\\'t see female genitals in an American film in anything short of porn or explicit erotica. This alleged double-standard is less a double standard than an admittedly depressing ability to come to terms culturally with the insides of women\\'s bodies.'], 'label': [0, 0]}\n",
            "{'text': \"If only to avoid making this type of film in the future. This film is interesting as an experiment but tells no cogent story.<br /><br />One might feel virtuous for sitting thru it because it touches on so many IMPORTANT issues but it does so without any discernable motive. The viewer comes away with no new perspectives (unless one comes up with one while one's mind wanders, as it will invariably do during this pointless film).<br /><br />One might better spend one's time staring out a window at a tree growing.<br /><br />\", 'label': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "说明一下metric_fn的作用\n",
        "samples=[影评1，影评2]\n",
        "sentiment_fn(samples)会对每个影评做一个正负情感分类，参考distilbert-imdb例子[https://huggingface.co/lvwerra/distilbert-imdb]\n",
        "sentiment_fn(samples) 是一个嵌套list 与上面举例一致 除了key值不同但是这个不影响 因为我们只要values \n",
        "sentiment_fn(samples)结果形如 \n",
        "[\n",
        "  [{'label': 'NEGATIVE', 'score': 0.7600291967391968}, {'label': 'POSITIVE', 'score': 0.23997080326080322}],\n",
        "  [{'label': 'NEGATIVE', 'score': 0.9923253059387207}, {'label': 'POSITIVE', 'score': 0.00767475226894021}],\n",
        "  [{'label': 'NEGATIVE', 'score': 0.9928519129753113}, {'label': 'POSITIVE', 'score': 0.007148080505430698}]\n",
        "]\n",
        "而map(get_positive_score, sentiment_fn(samples)) 将这个list中的内部list转化成一个得分值score，再list一下，成为[影评1得分，影评2得分]的score_list\n",
        "最后return {'sentiments':score_list} 我觉得这个字典的key是任意写的\n",
        "'''\n",
        "#注意是imdb['text']不是imdb,因为imdb包含text和label两个key 这里只能输入text对应的list\n",
        "small_samples = imdb[:3][\"text\"]\n",
        "print(sentiment_fn(small_samples))\n",
        "#get_postive_score（函数定义内部就是map方式作用）的输入是一个内部[{'label': 'NEGATIVE', 'score': 0.7600291967391968}, {'label': 'POSITIVE', 'score': 0.23997080326080322}]\n",
        "#得到一个得分0.23997080326080322\n",
        "#map(get_postive_score, XXX) 就是把XXX中每个list转化为一个得分，外面加上list形成列表\n",
        "print(list(map(get_positive_score, sentiment_fn(small_samples))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVMmRECXofuj",
        "outputId": "1b9b9c42-2a3e-44a8-b2b9-01ff8aa4cd27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[{'label': 'NEGATIVE', 'score': 0.7600291967391968}, {'label': 'POSITIVE', 'score': 0.23997080326080322}], [{'label': 'NEGATIVE', 'score': 0.9923253059387207}, {'label': 'POSITIVE', 'score': 0.00767475226894021}], [{'label': 'NEGATIVE', 'score': 0.9928519129753113}, {'label': 'POSITIVE', 'score': 0.007148080505430698}]]\n",
            "[0.7600291967391968, 0.9923253059387207, 0.9928519129753113]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#先看看训练的内容是什么\n",
        "print(f\"len_of_training_samples={len(imdb)}\")\n",
        "print(imdb[10000])\n",
        "count =0\n",
        "\n",
        "#label=0 negetive\n",
        "#label=1 positive\n",
        "\n",
        "for item in imdb:\n",
        "  if item['label'] ==0 :  #0表示负面影评 我们这里只是看一下 后面要用的实际是label=1的正面影评\n",
        "    print(item['text'])\n",
        "    print(item['label'])\n",
        "    count +=1\n",
        "  if count ==10:break"
      ],
      "metadata": {
        "id": "Bc9K5sbDF9m9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c55510d7-0e9c-40f9-8a73-5a5484750ef2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len_of_training_samples=50000\n",
            "{'text': \"Someone actually gave this movie 2 stars. There's a very high chance they need immediate professional help as anyone who doesn't spend 30 seconds to see if you can award no stars is quite literally scary.<br /><br />This film is ... well ... I guess it's pretty much some kind of attempt at a horrible porn / snuff movie with no porn or no real horrible bits (apart from the acting, plot, story, sets, dialogue and sound). I wrongly assumed it was about zombies. <br /><br />Watching it is actually quite scary in fairness; you're terrified someone will come over and you'll never be able to describe what it is and they'll go away thinking you're a freak that watches home-made amateur torture videos or something along those lines. <br /><br />I'm so taken aback I'm writing this review on my mobile so I don't forget to attempt to bring the rating down further than the current 1.6 to save others from the same horrible fate that I just suffered. <br /><br />I worst film I've ever seen and I can say (with hand on heart) it will never, never be topped.\", 'label': 0}\n",
            "I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it's not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn't have much of a plot.\n",
            "0\n",
            "\"I Am Curious: Yellow\" is a risible and pretentious steaming pile. It doesn't matter what one's political views are because this film can hardly be taken seriously on any level. As for the claim that frontal male nudity is an automatic NC-17, that isn't true. I've seen R-rated films with male nudity. Granted, they only offer some fleeting views, but where are the R-rated films with gaping vulvas and flapping labia? Nowhere, because they don't exist. The same goes for those crappy cable shows: schlongs swinging in the breeze but not a clitoris in sight. And those pretentious indie movies like The Brown Bunny, in which we're treated to the site of Vincent Gallo's throbbing johnson, but not a trace of pink visible on Chloe Sevigny. Before crying (or implying) \"double-standard\" in matters of nudity, the mentally obtuse should take into account one unavoidably obvious anatomical difference between men and women: there are no genitals on display when actresses appears nude, and the same cannot be said for a man. In fact, you generally won't see female genitals in an American film in anything short of porn or explicit erotica. This alleged double-standard is less a double standard than an admittedly depressing ability to come to terms culturally with the insides of women's bodies.\n",
            "0\n",
            "If only to avoid making this type of film in the future. This film is interesting as an experiment but tells no cogent story.<br /><br />One might feel virtuous for sitting thru it because it touches on so many IMPORTANT issues but it does so without any discernable motive. The viewer comes away with no new perspectives (unless one comes up with one while one's mind wanders, as it will invariably do during this pointless film).<br /><br />One might better spend one's time staring out a window at a tree growing.<br /><br />\n",
            "0\n",
            "This film was probably inspired by Godard's Masculin, féminin and I urge you to see that film instead.<br /><br />The film has two strong elements and those are, (1) the realistic acting (2) the impressive, undeservedly good, photo. Apart from that, what strikes me most is the endless stream of silliness. Lena Nyman has to be most annoying actress in the world. She acts so stupid and with all the nudity in this film,...it's unattractive. Comparing to Godard's film, intellectuality has been replaced with stupidity. Without going too far on this subject, I would say that follows from the difference in ideals between the French and the Swedish society.<br /><br />A movie of its time, and place. 2/10.\n",
            "0\n",
            "Oh, brother...after hearing about this ridiculous film for umpteen years all I can think of is that old Peggy Lee song..<br /><br />\"Is that all there is??\" ...I was just an early teen when this smoked fish hit the U.S. I was too young to get in the theater (although I did manage to sneak into \"Goodbye Columbus\"). Then a screening at a local film museum beckoned - Finally I could see this film, except now I was as old as my parents were when they schlepped to see it!!<br /><br />The ONLY reason this film was not condemned to the anonymous sands of time was because of the obscenity case sparked by its U.S. release. MILLIONS of people flocked to this stinker, thinking they were going to see a sex film...Instead, they got lots of closeups of gnarly, repulsive Swedes, on-street interviews in bland shopping malls, asinie political pretension...and feeble who-cares simulated sex scenes with saggy, pale actors.<br /><br />Cultural icon, holy grail, historic artifact..whatever this thing was, shred it, burn it, then stuff the ashes in a lead box!<br /><br />Elite esthetes still scrape to find value in its boring pseudo revolutionary political spewings..But if it weren't for the censorship scandal, it would have been ignored, then forgotten.<br /><br />Instead, the \"I Am Blank, Blank\" rhythymed title was repeated endlessly for years as a titilation for porno films (I am Curious, Lavender - for gay films, I Am Curious, Black - for blaxploitation films, etc..) and every ten years or so the thing rises from the dead, to be viewed by a new generation of suckers who want to see that \"naughty sex film\" that \"revolutionized the film industry\"...<br /><br />Yeesh, avoid like the plague..Or if you MUST see it - rent the video and fast forward to the \"dirty\" parts, just to get it over with.<br /><br />\n",
            "0\n",
            "I would put this at the top of my list of films in the category of unwatchable trash! There are films that are bad, but the worst kind are the ones that are unwatchable but you are suppose to like them because they are supposed to be good for you! The sex sequences, so shocking in its day, couldn't even arouse a rabbit. The so called controversial politics is strictly high school sophomore amateur night Marxism. The film is self-consciously arty in the worst sense of the term. The photography is in a harsh grainy black and white. Some scenes are out of focus or taken from the wrong angle. Even the sound is bad! And some people call this art?<br /><br />\n",
            "0\n",
            "Whoever wrote the screenplay for this movie obviously never consulted any books about Lucille Ball, especially her autobiography. I've never seen so many mistakes in a biopic, ranging from her early years in Celoron and Jamestown to her later years with Desi. I could write a whole list of factual errors, but it would go on for pages. In all, I believe that Lucille Ball is one of those inimitable people who simply cannot be portrayed by anyone other than themselves. If I were Lucie Arnaz and Desi, Jr., I would be irate at how many mistakes were made in this film. The filmmakers tried hard, but the movie seems awfully sloppy to me.\n",
            "0\n",
            "When I first saw a glimpse of this movie, I quickly noticed the actress who was playing the role of Lucille Ball. Rachel York's portrayal of Lucy is absolutely awful. Lucille Ball was an astounding comedian with incredible talent. To think about a legend like Lucille Ball being portrayed the way she was in the movie is horrendous. I cannot believe out of all the actresses in the world who could play a much better Lucy, the producers decided to get Rachel York. She might be a good actress in other roles but to play the role of Lucille Ball is tough. It is pretty hard to find someone who could resemble Lucille Ball, but they could at least find someone a bit similar in looks and talent. If you noticed York's portrayal of Lucy in episodes of I Love Lucy like the chocolate factory or vitavetavegamin, nothing is similar in any way-her expression, voice, or movement.<br /><br />To top it all off, Danny Pino playing Desi Arnaz is horrible. Pino does not qualify to play as Ricky. He's small and skinny, his accent is unreal, and once again, his acting is unbelievable. Although Fred and Ethel were not similar either, they were not as bad as the characters of Lucy and Ricky.<br /><br />Overall, extremely horrible casting and the story is badly told. If people want to understand the real life situation of Lucille Ball, I suggest watching A&E Biography of Lucy and Desi, read the book from Lucille Ball herself, or PBS' American Masters: Finding Lucy. If you want to see a docudrama, \"Before the Laughter\" would be a better choice. The casting of Lucille Ball and Desi Arnaz in \"Before the Laughter\" is much better compared to this. At least, a similar aspect is shown rather than nothing.\n",
            "0\n",
            "Who are these \"They\"- the actors? the filmmakers? Certainly couldn't be the audience- this is among the most air-puffed productions in existence. It's the kind of movie that looks like it was a lot of fun to shoot TOO much fun, nobody is getting any actual work done, and that almost always makes for a movie that's no fun to watch.<br /><br />Ritter dons glasses so as to hammer home his character's status as a sort of doppleganger of the bespectacled Bogdanovich; the scenes with the breezy Ms. Stratten are sweet, but have an embarrassing, look-guys-I'm-dating-the-prom-queen feel to them. Ben Gazzara sports his usual cat's-got-canary grin in a futile attempt to elevate the meager plot, which requires him to pursue Audrey Hepburn with all the interest of a narcoleptic at an insomnia clinic. In the meantime, the budding couple's respective children (nepotism alert: Bogdanovich's daughters) spew cute and pick up some fairly disturbing pointers on 'love' while observing their parents. (Ms. Hepburn, drawing on her dignity, manages to rise above the proceedings- but she has the monumental challenge of playing herself, ostensibly.) Everybody looks great, but so what? It's a movie and we can expect that much, if that's what you're looking for you'd be better off picking up a copy of Vogue.<br /><br />Oh- and it has to be mentioned that Colleen Camp thoroughly annoys, even apart from her singing, which, while competent, is wholly unconvincing... the country and western numbers are woefully mismatched with the standards on the soundtrack. Surely this is NOT what Gershwin (who wrote the song from which the movie's title is derived) had in mind; his stage musicals of the 20's may have been slight, but at least they were long on charm. \"They All Laughed\" tries to coast on its good intentions, but nobody- least of all Peter Bogdanovich - has the good sense to put on the brakes.<br /><br />Due in no small part to the tragic death of Dorothy Stratten, this movie has a special place in the heart of Mr. Bogdanovich- he even bought it back from its producers, then distributed it on his own and went bankrupt when it didn't prove popular. His rise and fall is among the more sympathetic and tragic of Hollywood stories, so there's no joy in criticizing the film... there _is_ real emotional investment in Ms. Stratten's scenes. But \"Laughed\" is a faint echo of \"The Last Picture Show\", \"Paper Moon\" or \"What's Up, Doc\"- following \"Daisy Miller\" and \"At Long Last Love\", it was a thundering confirmation of the phase from which P.B. has never emerged.<br /><br />All in all, though, the movie is harmless, only a waste of rental. I want to watch people having a good time, I'll go to the park on a sunny day. For filmic expressions of joy and love, I'll stick to Ernest Lubitsch and Jaques Demy...\n",
            "0\n",
            "This is said to be a personal film for Peter Bogdonavitch. He based it on his life but changed things around to fit the characters, who are detectives. These detectives date beautiful models and have no problem getting them. Sounds more like a millionaire playboy filmmaker than a detective, doesn't it? This entire movie was written by Peter, and it shows how out of touch with real people he was. You're supposed to write what you know, and he did that, indeed. And leaves the audience bored and confused, and jealous, for that matter. This is a curio for people who want to see Dorothy Stratten, who was murdered right after filming. But Patti Hanson, who would, in real life, marry Keith Richards, was also a model, like Stratten, but is a lot better and has a more ample part. In fact, Stratten's part seemed forced; added. She doesn't have a lot to do with the story, which is pretty convoluted to begin with. All in all, every character in this film is somebody that very few people can relate with, unless you're millionaire from Manhattan with beautiful supermodels at your beckon call. For the rest of us, it's an irritating snore fest. That's what happens when you're out of touch. You entertain your few friends with inside jokes, and bore all the rest.\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#显存太小 减少训练样本\n",
        "#train_num=20000"
      ],
      "metadata": {
        "id": "G5Gw8tlfF2D-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#参考 https://www.kaggle.com/code/shiyan00221/ppo-aidev-2023\n",
        "#   build_dataset_test 方法中tokenize(sample)函数加入了add_special_tokens=True \n",
        "#   然后把所有的sample处理成input_ids 又反过来处理成文字形式 这多此一举的行为肯定有道理\n",
        "#add_special_tokens=False or True 都试过了 没用 还是报 bos_toekn is used but not set\n",
        "tokenizer = AutoTokenizer.from_pretrained(config.model.model_path)\n",
        "def tokenize(sample):\n",
        "    sample[\"input_ids\"] = tokenizer.encode(sample[\"text\"], add_special_tokens=False)\n",
        "    sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n",
        "    return sample"
      ],
      "metadata": {
        "id": "57dj0bWFQdMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "参考dataset的各种预处理 对列的变换\n",
        "\n",
        "https://huggingface.co/docs/datasets/process"
      ],
      "metadata": {
        "id": "JyuyTusGbO9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#不用执行 只是看看remove_colunms函数的用法\n",
        "imdb = load_dataset(\"imdb\", split=\"train+test\")\n",
        "print(imdb) #此时imdb有2列 text和label\n",
        "imdb_2 = imdb.remove_columns(['label']) # 可以用这个方法去掉不需要的\n",
        "print(imdb_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43BoR6skXkPj",
        "outputId": "78e04140-65dc-4f96-e913-77996a170abc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset imdb (/root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['text', 'label'],\n",
            "    num_rows: 50000\n",
            "})\n",
            "Dataset({\n",
            "    features: ['text'],\n",
            "    num_rows: 50000\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#不用执行\n",
        "#没啥用 还是会大量报Using bos_token, but it is not set yet.\n",
        "#Using bos_token, but it is not set yet.\n",
        "#Using bos_token, but it is not set yet.\n",
        "ds = imdb\n",
        "ds = ds.map(tokenize, batched=False)\n",
        "ds.set_format(type='torch')\n",
        "ds = ds.remove_columns(['text','input_ids'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "e1281eed63ef4fcc9f997a029d6b734c",
            "1383cb7539a647e2bfc62f6c6932d831",
            "bc64af65441143b780970728e1431360",
            "ca0f73d8f2c2494fa66852694d9e7144",
            "c2472924d7f34b20b460b6c57d343ce2",
            "c72eeecc36be4c10a903bd28f51c37d2",
            "fe754088114245ecb6fff201d7971e4b",
            "f5b594779a9145459ed4d84c8cce4080",
            "cdaf7cf64b2246f0aad6d79194b7356e",
            "dfdb0585348b44b2b7d1b787b250ff87",
            "42d6855379de4edea2c97fd1f0438e15"
          ]
        },
        "id": "LiYsktwqVubp",
        "outputId": "210b06f7-95dc-4126-f3d2-407340d00942"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e1281eed63ef4fcc9f997a029d6b734c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnDNDnkSYmTs",
        "outputId": "14e99a30-ceb1-4ca6-8e98-88bf29d66687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['label', 'query'],\n",
            "    num_rows: 50000\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d632cce31730445a8c9ccf5d5c02225b",
            "926547d1646941718f5f09e319ffe964",
            "efa62eb2bac144b89c3eebc37e77fc9c",
            "a47b8a20659e469b8613252045f542e6",
            "e9848f1b6e42454593ba8aea7bfe6534",
            "8448416d0d46447da98b8011ea39c1db",
            "4678015f68434d39a8f7efa3339a2b2e",
            "5f1ebd16ef0949e9b02eb9499df909f3",
            "f3743a3e9f7e486782f53cae47f0cbe7",
            "f2eaabfbe2694897934e5d82fad4b861",
            "e8f64c10a87742729bd5b953c729492b"
          ]
        },
        "id": "JaxmtRxECPXA",
        "outputId": "b7b13db9-d2cf-43d9-a854-1a9ccf8686c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[RANK 0] Initializing model: google/flan-t5-large\n",
            "[RANK 0] Collecting rollouts\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (576 > 512). Running this sequence through the model will result in indexing errors\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "[RANK 0] Logging sample example\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                                                  Sample Example                                                   \u001b[0m\n",
              "┏━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mPrompt\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mResponse                                                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mReward    \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
              "│ </s>   │ I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that      │ tensor(1.) │\n",
              "│        │ surrounded it when it was first released in 1967. I also heard that at first it was       │            │\n",
              "│        │ seized by U.S. customs if it ever tried to enter this country, therefore being a fan of   │            │\n",
              "│        │ films considered \"controversial\" I really had to see this for myself.<unk> br /><unk> br  │            │\n",
              "│        │ />The plot is centered around a young Swedish drama student named Lena who wants to learn │            │\n",
              "│        │ everything she can about life. In particular she wants to focus her attentions to making  │            │\n",
              "│        │ some sort of documentary on what the average Swede thought about certain political issues │            │\n",
              "│        │ such as the Vietnam War and race issues in the United States. In between asking           │            │\n",
              "│        │ politicians and ordinary denizens of Stockholm about their opinions on politics, she has  │            │\n",
              "│        │ sex with her drama teacher, classmates, and married men.<unk> br /><unk> br />What kills  │            │\n",
              "│        │ me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic.      │            │\n",
              "│        │ Really, the sex and nudity scenes are few and far between, even then it's not shot like   │            │\n",
              "└────────┴───────────────────────────────────────────────────────────────────────────────────────────┴────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                  Sample Example                                                   </span>\n",
              "┏━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Prompt </span>┃<span style=\"font-weight: bold\"> Response                                                                                  </span>┃<span style=\"font-weight: bold\"> Reward     </span>┃\n",
              "┡━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
              "│ &lt;/s&gt;   │ I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that      │ tensor(1.) │\n",
              "│        │ surrounded it when it was first released in 1967. I also heard that at first it was       │            │\n",
              "│        │ seized by U.S. customs if it ever tried to enter this country, therefore being a fan of   │            │\n",
              "│        │ films considered \"controversial\" I really had to see this for myself.&lt;unk&gt; br /&gt;&lt;unk&gt; br  │            │\n",
              "│        │ /&gt;The plot is centered around a young Swedish drama student named Lena who wants to learn │            │\n",
              "│        │ everything she can about life. In particular she wants to focus her attentions to making  │            │\n",
              "│        │ some sort of documentary on what the average Swede thought about certain political issues │            │\n",
              "│        │ such as the Vietnam War and race issues in the United States. In between asking           │            │\n",
              "│        │ politicians and ordinary denizens of Stockholm about their opinions on politics, she has  │            │\n",
              "│        │ sex with her drama teacher, classmates, and married men.&lt;unk&gt; br /&gt;&lt;unk&gt; br /&gt;What kills  │            │\n",
              "│        │ me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic.      │            │\n",
              "│        │ Really, the sex and nudity scenes are few and far between, even then it's not shot like   │            │\n",
              "└────────┴───────────────────────────────────────────────────────────────────────────────────────────┴────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[RANK 0] Logging experience string statistics\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m        Experience String Stats (mean ∈ [min, max])        \u001b[0m\n",
              "┏━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mPrompt Length\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Length     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mSample Length     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ 1.00 ∈ [1, 1] │ 216.04 ∈ [51, 255] │ 217.04 ∈ [52, 256] │\n",
              "└───────────────┴────────────────────┴────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">        Experience String Stats (mean ∈ [min, max])        </span>\n",
              "┏━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Prompt Length </span>┃<span style=\"font-weight: bold\"> Output Length      </span>┃<span style=\"font-weight: bold\"> Sample Length      </span>┃\n",
              "┡━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ 1.00 ∈ [1, 1] │ 216.04 ∈ [51, 255] │ 217.04 ∈ [52, 256] │\n",
              "└───────────────┴────────────────────┴────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[RANK 0] Starting training\n",
            "[RANK 0] Evaluating model\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[generation sweep 0/1 | eval batch 0/1]:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d632cce31730445a8c9ccf5d5c02225b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92m<cell line: 6>\u001b[0m:\u001b[94m6\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/content/drive/MyDrive/trlx_0403/trlx/trlx/\u001b[0m\u001b[1;33mtrlx.py\u001b[0m:\u001b[94m124\u001b[0m in \u001b[92mtrain\u001b[0m                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m121 \u001b[0m\u001b[2m│   \u001b[0meval_pipeline = get_pipeline(config.train.pipeline)(eval_prompts, max_prompt_length,   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m122 \u001b[0m\u001b[2m│   \u001b[0mtrainer.add_eval_pipeline(eval_pipeline)                                               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m123 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m124 \u001b[2m│   \u001b[0mtrainer.learn()                                                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m125 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m trainer                                                                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m126 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/content/drive/MyDrive/trlx_0403/trlx/trlx/trainer/\u001b[0m\u001b[1;33maccelerate_base_trainer.py\u001b[0m:\u001b[94m504\u001b[0m in \u001b[92mlearn\u001b[0m       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m501 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0mstate = json.load(f)                                               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m502 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.iter_count = state[\u001b[33m\"\u001b[0m\u001b[33miter_count\u001b[0m\u001b[33m\"\u001b[0m]                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m503 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m504 \u001b[2m│   │   │   \u001b[0mresults = \u001b[96mself\u001b[0m.evaluate()                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m505 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.accelerator.log(results, step=\u001b[96mself\u001b[0m.iter_count)                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m506 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m507 \u001b[0m\u001b[2m│   │   \u001b[0mtbar = logging.tqdm(                                                               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/content/drive/MyDrive/trlx_0403/trlx/trlx/trainer/\u001b[0m\u001b[1;33maccelerate_base_trainer.py\u001b[0m:\u001b[94m349\u001b[0m in \u001b[92mevaluate\u001b[0m    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m346 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0mprompts[\u001b[33m\"\u001b[0m\u001b[33minput_ids\u001b[0m\u001b[33m\"\u001b[0m], prompts[\u001b[33m\"\u001b[0m\u001b[33mattention_mask\u001b[0m\u001b[33m\"\u001b[0m], **{gen_sweep_ar   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m347 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m)                                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m348 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m349 \u001b[2m│   │   │   │   │   \u001b[0msamples = \u001b[96mself\u001b[0m.generate_eval(prompts[\u001b[33m\"\u001b[0m\u001b[33minput_ids\u001b[0m\u001b[33m\"\u001b[0m], prompts[\u001b[33m\"\u001b[0m\u001b[33mattentio\u001b[0m   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m350 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m351 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# TODO(reciprocated): this should be moved into `decode`\u001b[0m                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m352 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# but that needs to be synced with indexing in `make_experience`\u001b[0m           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/content/drive/MyDrive/trlx_0403/trlx/trlx/trainer/\u001b[0m\u001b[1;33maccelerate_base_trainer.py\u001b[0m:\u001b[94m263\u001b[0m in             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[92mgenerate_eval\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m260 \u001b[0m\u001b[2m│   │   \u001b[0mkwargs = \u001b[96mdict\u001b[0m(\u001b[96mself\u001b[0m.generate_kwargs, **kwargs)                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m261 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m262 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m torch.no_grad():                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m263 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.accelerator.unwrap_model(\u001b[96mself\u001b[0m.model).generate(                     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m264 \u001b[0m\u001b[2m│   │   │   │   \u001b[0minput_ids=input_ids, attention_mask=attention_mask, **kwargs               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m265 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m266 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/content/drive/MyDrive/trlx_0403/trlx/trlx/models/\u001b[0m\u001b[1;33mmodeling_ilql.py\u001b[0m:\u001b[94m461\u001b[0m in \u001b[92mgenerate\u001b[0m               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m458 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m459 \u001b[0m\u001b[2m│   │   \u001b[0mfinished = torch.zeros(input_ids.shape[\u001b[94m0\u001b[0m], \u001b[94m1\u001b[0m, dtype=torch.long, device=input_ids   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m460 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m _ \u001b[95min\u001b[0m \u001b[96mrange\u001b[0m(max_new_tokens):                                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m461 \u001b[2m│   │   │   \u001b[0mout = \u001b[96mself\u001b[0m.forward(                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m462 \u001b[0m\u001b[2m│   │   │   │   \u001b[0minput_ids=input_ids,                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m463 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mattention_mask=attention_mask,                                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m464 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mdecoder_input_ids=decoder_input_ids[:, -\u001b[94m1\u001b[0m].unsqueeze(-\u001b[94m1\u001b[0m),                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/content/drive/MyDrive/trlx_0403/trlx/trlx/models/\u001b[0m\u001b[1;33mmodeling_ilql.py\u001b[0m:\u001b[94m422\u001b[0m in \u001b[92mforward\u001b[0m                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m419 \u001b[0m\u001b[2m│   │   \u001b[0mhs = out.decoder_hidden_states[-\u001b[94m1\u001b[0m]                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m420 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m421 \u001b[0m\u001b[2m│   │   \u001b[0mlogits = \u001b[96mself\u001b[0m.base_model.lm_head(hs)                                               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m422 \u001b[2m│   │   \u001b[0mqs, target_qs, vs = \u001b[96mself\u001b[0m.ilql_heads(hs, states_ixs=states_ixs, actions_ixs=actio   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m423 \u001b[0m\u001b[2m│   │   \u001b[0mencoder_outputs = (out.encoder_last_hidden_state, out.encoder_hidden_states, out   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m424 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m logits, qs, target_qs, vs, out.past_key_values, encoder_outputs             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m425 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/content/drive/MyDrive/trlx_0403/trlx/trlx/models/\u001b[0m\u001b[1;33mmodeling_ilql.py\u001b[0m:\u001b[94m176\u001b[0m in \u001b[92mforward\u001b[0m                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m173 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m174 \u001b[0m\u001b[2m│   │   │   \u001b[0mstates_hs = actions_hs = hs                                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m175 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m176 \u001b[2m│   │   \u001b[0mqs = \u001b[96mtuple\u001b[0m(q_head(actions_hs) \u001b[94mfor\u001b[0m q_head \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.q_heads)                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m177 \u001b[0m\u001b[2m│   │   \u001b[0mtarget_qs = \u001b[96mtuple\u001b[0m(q_head(actions_hs) \u001b[94mfor\u001b[0m q_head \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.target_q_heads)            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m178 \u001b[0m\u001b[2m│   │   \u001b[0mvs = \u001b[96mself\u001b[0m.v_head(states_hs)                                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m179 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/content/drive/MyDrive/trlx_0403/trlx/trlx/models/\u001b[0m\u001b[1;33mmodeling_ilql.py\u001b[0m:\u001b[94m176\u001b[0m in \u001b[92m<genexpr>\u001b[0m              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m173 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m174 \u001b[0m\u001b[2m│   │   │   \u001b[0mstates_hs = actions_hs = hs                                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m175 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m176 \u001b[2m│   │   \u001b[0mqs = \u001b[96mtuple\u001b[0m(q_head(actions_hs) \u001b[94mfor\u001b[0m q_head \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.q_heads)                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m177 \u001b[0m\u001b[2m│   │   \u001b[0mtarget_qs = \u001b[96mtuple\u001b[0m(q_head(actions_hs) \u001b[94mfor\u001b[0m q_head \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.target_q_heads)            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m178 \u001b[0m\u001b[2m│   │   \u001b[0mvs = \u001b[96mself\u001b[0m.v_head(states_hs)                                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m179 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mcontainer.py\u001b[0m:\u001b[94m217\u001b[0m in \u001b[92mforward\u001b[0m              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m214 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# with Any as TorchScript expects a more precise type\u001b[0m                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m215 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m):                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m216 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m module \u001b[95min\u001b[0m \u001b[96mself\u001b[0m:                                                                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m217 \u001b[2m│   │   │   \u001b[0m\u001b[96minput\u001b[0m = module(\u001b[96minput\u001b[0m)                                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m218 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96minput\u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m219 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m220 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mappend\u001b[0m(\u001b[96mself\u001b[0m, module: Module) -> \u001b[33m'\u001b[0m\u001b[33mSequential\u001b[0m\u001b[33m'\u001b[0m:                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mlinear.py\u001b[0m:\u001b[94m114\u001b[0m in \u001b[92mforward\u001b[0m                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m111 \u001b[0m\u001b[2m│   │   │   \u001b[0minit.uniform_(\u001b[96mself\u001b[0m.bias, -bound, bound)                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m: Tensor) -> Tensor:                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m114 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m F.linear(\u001b[96minput\u001b[0m, \u001b[96mself\u001b[0m.weight, \u001b[96mself\u001b[0m.bias)                                     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m115 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mextra_repr\u001b[0m(\u001b[96mself\u001b[0m) -> \u001b[96mstr\u001b[0m:                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m117 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[33m'\u001b[0m\u001b[33min_features=\u001b[0m\u001b[33m{}\u001b[0m\u001b[33m, out_features=\u001b[0m\u001b[33m{}\u001b[0m\u001b[33m, bias=\u001b[0m\u001b[33m{}\u001b[0m\u001b[33m'\u001b[0m.format(                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 6&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">6</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/content/drive/MyDrive/trlx_0403/trlx/trlx/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trlx.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">124</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train</span>                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121 │   </span>eval_pipeline = get_pipeline(config.train.pipeline)(eval_prompts, max_prompt_length,   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">122 │   </span>trainer.add_eval_pipeline(eval_pipeline)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">123 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>124 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>trainer.learn()                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">125 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> trainer                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">126 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/content/drive/MyDrive/trlx_0403/trlx/trlx/trainer/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">accelerate_base_trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">504</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">learn</span>       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">501 │   │   │   │   │   │   </span>state = json.load(f)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">502 │   │   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.iter_count = state[<span style=\"color: #808000; text-decoration-color: #808000\">\"iter_count\"</span>]                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">503 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>504 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>results = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.evaluate()                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">505 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.accelerator.log(results, step=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.iter_count)                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">506 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">507 │   │   </span>tbar = logging.tqdm(                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/content/drive/MyDrive/trlx_0403/trlx/trlx/trainer/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">accelerate_base_trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">349</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">evaluate</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">346 │   │   │   │   │   │   </span>prompts[<span style=\"color: #808000; text-decoration-color: #808000\">\"input_ids\"</span>], prompts[<span style=\"color: #808000; text-decoration-color: #808000\">\"attention_mask\"</span>], **{gen_sweep_ar   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">347 │   │   │   │   │   </span>)                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">348 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>349 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>samples = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.generate_eval(prompts[<span style=\"color: #808000; text-decoration-color: #808000\">\"input_ids\"</span>], prompts[<span style=\"color: #808000; text-decoration-color: #808000\">\"attentio</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">350 │   │   │   │   </span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">351 │   │   │   │   # TODO(reciprocated): this should be moved into `decode`</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">352 │   │   │   │   # but that needs to be synced with indexing in `make_experience`</span>           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/content/drive/MyDrive/trlx_0403/trlx/trlx/trainer/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">accelerate_base_trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">263</span> in             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">generate_eval</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">260 │   │   </span>kwargs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">dict</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.generate_kwargs, **kwargs)                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">261 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">262 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.no_grad():                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>263 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.accelerator.unwrap_model(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.model).generate(                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">264 │   │   │   │   </span>input_ids=input_ids, attention_mask=attention_mask, **kwargs               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">265 │   │   │   </span>)                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">266 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/content/drive/MyDrive/trlx_0403/trlx/trlx/models/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_ilql.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">461</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">generate</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">458 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">459 │   │   </span>finished = torch.zeros(input_ids.shape[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>], <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, dtype=torch.long, device=input_ids   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">460 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> _ <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">range</span>(max_new_tokens):                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>461 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>out = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.forward(                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">462 │   │   │   │   </span>input_ids=input_ids,                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">463 │   │   │   │   </span>attention_mask=attention_mask,                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">464 │   │   │   │   </span>decoder_input_ids=decoder_input_ids[:, -<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>].unsqueeze(-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>),                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/content/drive/MyDrive/trlx_0403/trlx/trlx/models/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_ilql.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">422</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">419 │   │   </span>hs = out.decoder_hidden_states[-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>]                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">420 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">421 │   │   </span>logits = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.base_model.lm_head(hs)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>422 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>qs, target_qs, vs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.ilql_heads(hs, states_ixs=states_ixs, actions_ixs=actio   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">423 │   │   </span>encoder_outputs = (out.encoder_last_hidden_state, out.encoder_hidden_states, out   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">424 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> logits, qs, target_qs, vs, out.past_key_values, encoder_outputs             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">425 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.9/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/content/drive/MyDrive/trlx_0403/trlx/trlx/models/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_ilql.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">176</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">173 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">174 │   │   │   </span>states_hs = actions_hs = hs                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">175 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>176 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>qs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">tuple</span>(q_head(actions_hs) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> q_head <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.q_heads)                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">177 │   │   </span>target_qs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">tuple</span>(q_head(actions_hs) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> q_head <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.target_q_heads)            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">178 │   │   </span>vs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.v_head(states_hs)                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">179 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/content/drive/MyDrive/trlx_0403/trlx/trlx/models/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_ilql.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">176</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;genexpr&gt;</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">173 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">174 │   │   │   </span>states_hs = actions_hs = hs                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">175 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>176 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>qs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">tuple</span>(q_head(actions_hs) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> q_head <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.q_heads)                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">177 │   │   </span>target_qs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">tuple</span>(q_head(actions_hs) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> q_head <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.target_q_heads)            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">178 │   │   </span>vs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.v_head(states_hs)                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">179 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.9/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.9/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">container.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">217</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">214 │   # with Any as TorchScript expects a more precise type</span>                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">215 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>):                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">216 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> module <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>:                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>217 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span> = module(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>)                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">218 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">219 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">220 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">append</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, module: Module) -&gt; <span style=\"color: #808000; text-decoration-color: #808000\">'Sequential'</span>:                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.9/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.9/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">linear.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">114</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">111 │   │   │   </span>init.uniform_(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.bias, -bound, bound)                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">112 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">113 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>: Tensor) -&gt; Tensor:                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>114 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> F.linear(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.weight, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.bias)                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">115 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">116 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">extra_repr</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>) -&gt; <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>:                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">117 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #808000; text-decoration-color: #808000\">'in_features={}, out_features={}, bias={}'</span>.format(                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#trainer中的eval_prompts是用于在训练过程中验证效果的样本\n",
        "#看看用这些提示输入，模型返回的句子是怎么样的 ，理论上输出会根据这些提示输出正面评价的output\n",
        "#Evaluation #11 metrics/sentiments: 0.528 这个值是句子的正面分类得分 由上面metric_fn的定义而来\n",
        "\n",
        "\n",
        "trainer = trlx.train(\n",
        "    \n",
        "    #prompts=prompts,\n",
        "    #eval_prompts=val_prompts,\n",
        "    #reward_fn=metric_fn,\n",
        "    #config=config,\n",
        "    samples=imdb[\"text\"][:20000] ,#ds['query'][:200], #imdb[\"text\"][:20000],  #输入文本\n",
        "    #注意这个rewards和scores函数对应 做减法就是scores函数取NEGATIVE的值\n",
        "    #rewards=[ 1.0 - value  for value in ds[\"label\"][:200]],\n",
        "    rewards=[ 1.0 - value  for value in imdb[\"label\"][:20000]]\n",
        "    #,  #被标注的label=0 ，1 代表负面或者正面，既然是reward那么越高越高 所以这是引导输出1即正面文字\n",
        "    eval_prompts=[  #训练过程中的验证 验证时会看到输出根据训练的进行在逐步改变成正面文字\n",
        "        \"I don't know much about Hungarian underground\",\n",
        "        \"What made this movie so distinctly\",\n",
        "        \"Like the sandwich I just bought at the grocery store,\",\n",
        "        \"I cannot believe how much this movie made me want to\"\n",
        "    ] *1, #* 20,\n",
        "    metric_fn=metric_fn, #这个metric_fn会把上面的samples作为输入\n",
        "    config=config,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "上面是磁盘满了导致的"
      ],
      "metadata": {
        "id": "RDl_iQt3N3Hr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "官网\n"
      ],
      "metadata": {
        "id": "6kcunTrLPaNi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://huggingface.co/blog/rlhf\n",
        "\n",
        "https://wandb.ai/carperai/summarize_RLHF/reports/Implementing-RLHF-Learning-to-Summarize-with-trlX--VmlldzozMzAwODM2\n",
        "\n",
        "https://blog.eleuther.ai/trlx-exploratory-analysis/\n",
        "\n",
        "模型训练完成后存储 网上说有两种方式\n",
        "Important: Once the model is trained, you will need to save it in a particular way before you can load it into TransformerLens. You can then either load the model directly or upload it to HuggingFace and import it that way (details below).\n",
        "\n",
        "Weights&Bais官网说是\n",
        "trainer.save('/path/to/output/folder/')\n",
        "\n",
        "下面是另外的说法来自https://blog.eleuther.ai/trlx-exploratory-analysis/\n",
        "trainer.model.base_model.save_pretrained(\"base_model/\")"
      ],
      "metadata": {
        "id": "GzaYBYYIOlIN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l--lSYICuuE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGL7Uk8mCTPO",
        "outputId": "c92e0323-938c-4356-a5e0-9871b7106962"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One thing you should know about When Sally Met Harry is that her name is the first thing you hear in a TV movie about \"The Man In The White Suit.\" I've seen all of the films so far and it's not a bad film for sure. It does have some of the best writing and acting ever in\n"
          ]
        }
      ],
      "source": [
        "# output\n",
        "input_str = 'One thing you should know about When Sally Met Harry is that'\n",
        "trainer_output = trainer.generate_eval(\n",
        "    **trainer.tokenizer(input_str, return_tensors='pt'))[0]\n",
        "print(trainer.tokenizer.decode(trainer_output))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trlx \n",
        "trl\n",
        "gpt2：1.y\n",
        "flan-t5 5-6y"
      ],
      "metadata": {
        "id": "VT5CMz1cu85a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 20230417 引入LORA:  google/flan-t5-large + lora\n"
      ],
      "metadata": {
        "id": "z4xcKSbeu5-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = TRLConfig(\n",
        "    train=TrainConfig(\n",
        "        seq_length=256, \n",
        "        #真正的train step = max(epochs , total_steps) \n",
        "        #参见/content/drive/MyDrive/trlx_0403/trlx/configs/test_config.yml 的定义\n",
        "        epochs=100,\n",
        "        total_steps=5000,\n",
        "        batch_size=8,\n",
        "        checkpoint_interval=5000, #训练中每checkpoint_interval次就保存一次 但是colab只有15G 所以我们最后再保存\n",
        "        eval_interval=500,\n",
        "        pipeline=\"PromptPipeline\",\n",
        "        trainer=\"AccelerateILQLTrainer\",#\"AcceleratePPOTrainer\", #\n",
        "        tracker=None, #default is wandb\n",
        "    ),\n",
        "    model=ModelConfig(\n",
        "        model_path='google/flan-t5-large',#'google/flan-t5-large',#\"gpt2\",\n",
        "        model_arch_type=\"seq2seq\",      #causal for gpt2\n",
        "        num_layers_unfrozen=2,\n",
        "        #load_in_8bit =True,  not supoort yet\n",
        "        # LORA here \n",
        "        delta_kwargs={\n",
        "                \"delta_type\": \"lora\", \n",
        "                #gpt2不适用这个\"modified_modules\": \"attention\",\n",
        "                'modified_modules':'attention', # all\n",
        "                \"lora_r\": 8, \n",
        "                \"lora_alpha\": 32, \n",
        "                \"lora_dropout\": 0.05,\n",
        "                #\"task_type\":\"CAUSAL_LM\",  not supoort yet\n",
        "                },\n",
        "                 \n",
        "    ),\n",
        "    tokenizer=TokenizerConfig(\n",
        "        tokenizer_path='google/flan-t5-large',#'google/flan-t5-large',#\"gpt2\",\n",
        "        truncation_side=\"right\",\n",
        "    ),\n",
        "    optimizer=OptimizerConfig(\n",
        "        name=\"adamw\",\n",
        "        kwargs={\n",
        "            \"lr\": 1.0e-5,\n",
        "            \"betas\": [0.9, 0.999],\n",
        "            \"eps\": 1.0e-8,\n",
        "            \"weight_decay\": 1.0e-6,\n",
        "        },\n",
        "    ),\n",
        "    scheduler=SchedulerConfig(\n",
        "        name=\"cosine_annealing\",\n",
        "        kwargs={\n",
        "            \"T_max\": 10000,\n",
        "            \"eta_min\": 1.0e-6,\n",
        "        },\n",
        "    ),\n",
        "    method=ILQLConfig(name='ilqlconfig', \n",
        "               tau=0.7, \n",
        "               gamma=0.99, \n",
        "               cql_scale=0.1, \n",
        "               awac_scale=1, alpha=0.001, \n",
        "               beta=0, \n",
        "               steps_for_target_q_sync=5, \n",
        "               two_qs =True,\n",
        "               gen_kwargs={'max_new_tokens': 56, \n",
        "                    'top_k': 20, \n",
        "                    'beta': 1,\n",
        "                     'temperature': 1.0}\n",
        "        ),\n",
        "    # method =ILQLConfig(\n",
        "        \n",
        "    #     name =\"ILQLConfig\",\n",
        "    #     tau =  0.7,\n",
        "    #     gamma = 0.99,\n",
        "    #     cql_scale = 0.1,\n",
        "    #     awac_scale =  1,\n",
        "    #     alpha =  0.001,\n",
        "    #     beta =  0,\n",
        "    #     steps_for_target_q_sync =  5,\n",
        "    #     two_qs = True,\n",
        "    #     gen_kwargs={\n",
        "            \n",
        "    #         \"max_new_tokens\": 56,\n",
        "    #         \"top_k\": 20,\n",
        "    #         \"beta\": 1,\n",
        "    #         \"temperature\": 1.0\n",
        "    #     }\n",
        "    # ),\n",
        ")"
      ],
      "metadata": {
        "id": "NJceg-09u9w1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 试试LoRA更多 不做UNfrozen限制  并且lora:attention换成Lora:all"
      ],
      "metadata": {
        "id": "sxBCLNBcNXF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lora:atten 注意力层 * 24\n",
        "low rank matrice:rank\n",
        "model.bin +lora_adapter.bin: output"
      ],
      "metadata": {
        "id": "dQQMZh5bxyfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = TRLConfig(\n",
        "    train=TrainConfig(\n",
        "        seq_length=256, \n",
        "        #真正的train step = max(epochs , total_steps) \n",
        "        #参见/content/drive/MyDrive/trlx_0403/trlx/configs/test_config.yml 的定义\n",
        "        epochs=100,\n",
        "        total_steps=5000,\n",
        "        batch_size=8,\n",
        "        checkpoint_interval=5000, #训练中每checkpoint_interval次就保存一次 但是colab只有15G 所以我们最后再保存\n",
        "        eval_interval=500,\n",
        "        pipeline=\"PromptPipeline\",\n",
        "        trainer=\"AccelerateILQLTrainer\",#\"AcceleratePPOTrainer\", #\n",
        "        tracker=None, #default is wandb\n",
        "    ),\n",
        "    model=ModelConfig(\n",
        "        model_path='google/flan-t5-large',#'google/flan-t5-large',#\"gpt2\",\n",
        "        model_arch_type=\"seq2seq\",      #causal for gpt2\n",
        "        #num_layers_unfrozen=2,\n",
        "        #load_in_8bit =True,  not supoort yet\n",
        "        #LORA here \n",
        "        delta_kwargs={\n",
        "                \"delta_type\": \"lora\", \n",
        "                #gpt2不适用这个\"modified_modules\": \"attention\",\n",
        "                'modified_modules':\"all\",#'attention', # all\n",
        "                \"lora_r\": 8, \n",
        "                \"lora_alpha\": 32, \n",
        "                \"lora_dropout\": 0.05,\n",
        "                #\"task_type\":\"CAUSAL_LM\",  not supoort yet\n",
        "                },\n",
        "                 \n",
        "    ),\n",
        "    tokenizer=TokenizerConfig(\n",
        "        tokenizer_path='google/flan-t5-large',#'google/flan-t5-large',#\"gpt2\",\n",
        "        truncation_side=\"right\",\n",
        "    ),\n",
        "    optimizer=OptimizerConfig(\n",
        "        name=\"adamw\",\n",
        "        kwargs={\n",
        "            \"lr\": 1.0e-5,\n",
        "            \"betas\": [0.9, 0.999],\n",
        "            \"eps\": 1.0e-8,\n",
        "            \"weight_decay\": 1.0e-6,\n",
        "        },\n",
        "    ),\n",
        "    scheduler=SchedulerConfig(\n",
        "        name=\"cosine_annealing\",\n",
        "        kwargs={\n",
        "            \"T_max\": 10000,\n",
        "            \"eta_min\": 1.0e-6,\n",
        "        },\n",
        "    ),\n",
        "    method=ILQLConfig(name='ilqlconfig', \n",
        "               tau=0.7, \n",
        "               gamma=0.99, \n",
        "               cql_scale=0.1, \n",
        "               awac_scale=1, alpha=0.001, \n",
        "               beta=0, \n",
        "               steps_for_target_q_sync=5, \n",
        "               two_qs =True,\n",
        "               gen_kwargs={'max_new_tokens': 56, \n",
        "                    'top_k': 20, \n",
        "                    'beta': 1,\n",
        "                     'temperature': 1.0}\n",
        "        ),\n",
        "    # method =ILQLConfig(\n",
        "        \n",
        "    #     name =\"ILQLConfig\",\n",
        "    #     tau =  0.7,\n",
        "    #     gamma = 0.99,\n",
        "    #     cql_scale = 0.1,\n",
        "    #     awac_scale =  1,\n",
        "    #     alpha =  0.001,\n",
        "    #     beta =  0,\n",
        "    #     steps_for_target_q_sync =  5,\n",
        "    #     two_qs = True,\n",
        "    #     gen_kwargs={\n",
        "            \n",
        "    #         \"max_new_tokens\": 56,\n",
        "    #         \"top_k\": 20,\n",
        "    #         \"beta\": 1,\n",
        "    #         \"temperature\": 1.0\n",
        "    #     }\n",
        "    # ),\n",
        ")"
      ],
      "metadata": {
        "id": "eTQDRqC8L9HA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "TbySQBV93dD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "dyfHbGQYfVcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_positive_score(scores):\n",
        "    \"Extract value associated with a positive sentiment from pipeline's output\"\n",
        "    return dict(map(lambda x: tuple(x.values()), scores))[\"NEGATIVE\"]#[\"POSITIVE\"]  #return的是一个float\n",
        "\n",
        "#pipeline huggingface提供的一种使用模型的快捷方式 参考[https://huggingface.co/docs/transformers/main_classes/pipelines]\n",
        "'''#例子\n",
        "pipe = pipeline(model=\"roberta-large-mnli\")\n",
        "pipe(\"This restaurant is awesome\")\n",
        "[{'label': 'NEUTRAL', 'score': 0.7313136458396912}]\n",
        "'''\n",
        "sentiment_fn = pipeline( #RM hf\n",
        "     \n",
        "    \"sentiment-analysis\",\n",
        "    \"lvwerra/distilbert-imdb\",\n",
        "    top_k=2, #只输出POSTIVE和NEGETIVE两类的归一化概率logits\n",
        "    truncation=True,\n",
        "    batch_size=8,\n",
        "    #device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")#0,\n",
        ")\n",
        "\n",
        "def sentiment_fn_trick_test_20230416(samples):\n",
        "   lens =len(samples)\n",
        "   return [[{'label': 'NEGATIVE', 'score': 0.76}, {'label': 'POSITIVE', 'score': 0.24}] for _ in range(lens)]\n",
        "'''\n",
        "说明一下metric_fn的作用\n",
        "samples=[影评1，影评2]\n",
        "sentiment_fn(samples)会对每个影评做一个正负情感分类，参考distilbert-imdb例子[https://huggingface.co/lvwerra/distilbert-imdb]\n",
        "sentiment_fn(samples) 是一个list= [{'label': 'NEGATIVE', 'score': 0.76}, {'label': 'POSITIVE', 'score': 0.24}]\n",
        "而map(get_positive_score, sentiment_fn(samples)) 将这个list中的每个dict转化成一个得分值score，再list一下，成为[影评1得分，影评2得分]的score_list\n",
        "最后return {'sentiments':score_list} 我觉得这个字典的key是任意写的\n",
        "'''\n",
        "\n",
        "def metric_fn(samples: List[str], **kwargs) -> Dict[str, List[float]]:\n",
        "    sentiments = list(map(get_positive_score, sentiment_fn(samples)))\n",
        "    return {\"sentiments\": sentiments}\n",
        "\n",
        "imdb = load_dataset(\"imdb\", split=\"train+test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dHmTP65yj2c",
        "outputId": "189f9ffd-48b7-45f5-8278-275d7fc5a465"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset imdb (/root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#构建一个较小的数据集 以jsonl的形式\n",
        "imdb_positive_500 = []\n",
        "len_pos =0\n",
        "imdb_negative_500 = []\n",
        "len_neg =0\n",
        "for i in range(len(imdb)):\n",
        "  label = imdb[i]['label']\n",
        "  if label == 1 and len_pos<500:\n",
        "    pos_review = imdb[i]['text']\n",
        "    imdb_positive_500.append({'text':pos_review , 'label':label})\n",
        "    len_pos += 1\n",
        "  if label == 0 and len_neg<500:\n",
        "    neg_review = imdb[i]['text']\n",
        "    imdb_negative_500.append({'text':neg_review , 'label':label})\n",
        "    len_neg += 1"
      ],
      "metadata": {
        "id": "nc19nDkYgYeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#imdb_negative_500"
      ],
      "metadata": {
        "id": "6fx9Z6Iqh0VO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "imdb_1k = imdb_positive_500 + imdb_negative_500\n",
        "\n",
        "\n",
        "random.shuffle(imdb_1k) #随机打乱\n",
        "len(imdb_1k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEBvxR63iMa_",
        "outputId": "78c89057-caa7-4a2b-f3b4-cbeee67da9bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open('/content/drive/MyDrive/trlx_0403/imdb_1k.json','w') as f:\n",
        "  for item in imdb_1k :\n",
        "    f.write(json.dumps(item))\n",
        "    f.write('\\n')\n",
        "print('json write done')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqz7gVBuikph",
        "outputId": "87fb4a38-ab8d-48cd-ea5f-09eb0d01d3a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "json write done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "#带上split='train' 这样导入后就没有train这一层 结构更简单 不然要用#imdb_1k_ds['train']['text'][:4] 多一层参数\n",
        "imdb_1k_ds = load_dataset(\"json\", data_files=\"/content/drive/MyDrive/trlx_0403/imdb_1k.json\",split=\"train\")\n",
        "\n",
        "print(imdb_1k_ds)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205,
          "referenced_widgets": [
            "84596edc3cd14511942d5d87623d8964",
            "612e77cc2fd74bb081b1f45b73a00684",
            "feee40745e6f46dfa5a1d1a106da2625",
            "7ab11506bcd7477882eb5f65425a14cd",
            "689d8ebe9a09443d83bd1e8c1c79b4df",
            "5ed881d07ea94ea3afd5d6ededb2a7a1",
            "ae0cd0a7b34543c98f2598871149970d",
            "7031676d638b4945b79311643c5b9911",
            "a4129066c6cb4c9aa61becd3d8fe2225",
            "359bd2a427bc44aa8e94d67782638dd5",
            "ea4f40c12dc449458e933069628277ac",
            "ca0692f20fde4edabb7e95199434b853",
            "316197278593419ca5d075081a11881d",
            "eb747b371533441a8e815e997d354b43",
            "e95513b8628f410f8441592ca88a3f7e",
            "3c7718c4a35d4901b17a5b3cb746fd48",
            "c847dbbc9c3c4c568beff8cc2672b8e9",
            "77b578bf53364abeaf7d3f53f1b69254",
            "56fe6d386eb24683bacee87d51574263",
            "9ca711f2b9e24027aca28279a63a12e0",
            "ae33439e69a540db85cc56f8b56bd9af",
            "463a30c137e94d64953b726d465d44c3",
            "6350deeec6744b9cb48669c865c893aa",
            "0ed800fde3b744a89bfb13c665b4cd9a",
            "f86b0643d7ca410fb0d72b620938bd22",
            "ea30485cc0b54f329f252f57f3471c0e",
            "222e5e8cb1014e2b96c95c7027190f0f",
            "c84b2ecf94a846959ef070728d740450",
            "e333d942fa354303bad9f0e0cccc7b7d",
            "ff1a37dff9f24ca09c159fced82b9c92",
            "e6115b3e94bf418daeddaeaa2f320fed",
            "77d4468931d348d7a97a46569bedeff9",
            "0b89140d21434f9a8bf25497db0a9e11"
          ]
        },
        "id": "ZWR5MX4ikleR",
        "outputId": "d9a2fce9-3bb1-41b1-f23d-6542841468bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-66411290daf6a649/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "84596edc3cd14511942d5d87623d8964"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca0692f20fde4edabb7e95199434b853"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6350deeec6744b9cb48669c865c893aa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-66411290daf6a649/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e. Subsequent calls will reuse this data.\n",
            "Dataset({\n",
            "    features: ['text', 'label'],\n",
            "    num_rows: 1000\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#imdb\n",
        "#imdb_1k_ds \n",
        "#目前接口一致"
      ],
      "metadata": {
        "id": "1q_zx1j2o_V4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HTmdsoAVo0fI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print([  1.0 -value  for value in imdb_1k_ds[\"label\"]][0])\n",
        "print(imdb_1k_ds[\"text\"][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFK3dFh4oSMJ",
        "outputId": "3c9e0289-e291-4ea3-e9ff-cc833432aab6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "Who are these \"They\"- the actors? the filmmakers? Certainly couldn't be the audience- this is among the most air-puffed productions in existence. It's the kind of movie that looks like it was a lot of fun to shoot TOO much fun, nobody is getting any actual work done, and that almost always makes for a movie that's no fun to watch.<br /><br />Ritter dons glasses so as to hammer home his character's status as a sort of doppleganger of the bespectacled Bogdanovich; the scenes with the breezy Ms. Stratten are sweet, but have an embarrassing, look-guys-I'm-dating-the-prom-queen feel to them. Ben Gazzara sports his usual cat's-got-canary grin in a futile attempt to elevate the meager plot, which requires him to pursue Audrey Hepburn with all the interest of a narcoleptic at an insomnia clinic. In the meantime, the budding couple's respective children (nepotism alert: Bogdanovich's daughters) spew cute and pick up some fairly disturbing pointers on 'love' while observing their parents. (Ms. Hepburn, drawing on her dignity, manages to rise above the proceedings- but she has the monumental challenge of playing herself, ostensibly.) Everybody looks great, but so what? It's a movie and we can expect that much, if that's what you're looking for you'd be better off picking up a copy of Vogue.<br /><br />Oh- and it has to be mentioned that Colleen Camp thoroughly annoys, even apart from her singing, which, while competent, is wholly unconvincing... the country and western numbers are woefully mismatched with the standards on the soundtrack. Surely this is NOT what Gershwin (who wrote the song from which the movie's title is derived) had in mind; his stage musicals of the 20's may have been slight, but at least they were long on charm. \"They All Laughed\" tries to coast on its good intentions, but nobody- least of all Peter Bogdanovich - has the good sense to put on the brakes.<br /><br />Due in no small part to the tragic death of Dorothy Stratten, this movie has a special place in the heart of Mr. Bogdanovich- he even bought it back from its producers, then distributed it on his own and went bankrupt when it didn't prove popular. His rise and fall is among the more sympathetic and tragic of Hollywood stories, so there's no joy in criticizing the film... there _is_ real emotional investment in Ms. Stratten's scenes. But \"Laughed\" is a faint echo of \"The Last Picture Show\", \"Paper Moon\" or \"What's Up, Doc\"- following \"Daisy Miller\" and \"At Long Last Love\", it was a thundering confirmation of the phase from which P.B. has never emerged.<br /><br />All in all, though, the movie is harmless, only a waste of rental. I want to watch people having a good time, I'll go to the park on a sunny day. For filmic expressions of joy and love, I'll stick to Ernest Lubitsch and Jaques Demy...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3145728/786295808 = 0.40%     Lora：atten\n",
        "\n",
        "5357568/788507648 = 0.68%     Lora：all\n",
        "\n",
        "明天减小batch size测试\n"
      ],
      "metadata": {
        "id": "qlsWx_MdOUOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MLP=FCN"
      ],
      "metadata": {
        "id": "pW8kbjVrwh4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#trainer中的eval_prompts是用于在训练过程中验证效果的样本\n",
        "#看看用这些提示输入，模型返回的句子是怎么样的 ，理论上输出会根据这些提示输出正面评价的output\n",
        "#Evaluation #11 metrics/sentiments: 0.528 这个值是句子的正面分类得分 由上面metric_fn的定义而来\n",
        "\n",
        "\n",
        "trainer = trlx.train(\n",
        "    \n",
        "    #prompts=prompts,\n",
        "    #eval_prompts=val_prompts,\n",
        "    #reward_fn=metric_fn,\n",
        "    #config=config,\n",
        "    samples=imdb_1k_ds['text'],#imdb[\"text\"][:1000] ,#ds['query'][:200], #imdb[\"text\"][:20000],  #输入文本\n",
        "    #注意这个rewards和scores函数对应 做减法就是scores函数取NEGATIVE的值\n",
        "    #rewards=[ 1.0 - value  for value in ds[\"label\"][:200]],\n",
        "    rewards=[  1.0 -value  for value in imdb_1k_ds[\"label\"]],#[  1.0 -value  for value in imdb[\"label\"][:1000]],\n",
        "    #,  #被标注的label=0 ，1 代表负面或者正面，既然是reward那么越高越高 所以这是引导输出1即正面文字\n",
        "    eval_prompts = [\n",
        "        \"What made this movie so\",\n",
        "        \"This is the movie I will \",\n",
        "        \"This movie is such a \",\n",
        "        \"I didn't expect this movie was\",\n",
        "    ] * 8,\n",
        "    metric_fn=metric_fn, #这个metric_fn会把上面的samples作为输入\n",
        "    config=config,\n",
        ")"
      ],
      "metadata": {
        "id": "Ud9vln-CyVIy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "71a7bfcb3ce644a28e10639c3439d0a2",
            "5101ef58855247f8852249b65fe419ab",
            "c2829b1716b04ec888d1789d0169244b",
            "b8e28f81e06a4722bad654e6dc91c8b7",
            "1c3d156217964da8b1c193e2ea4ff0a9",
            "f0d5adebcb9d4a8cb761b1a00a6540a8",
            "aad3ea00d81b46ce9e2a1c9f2eba4bb1",
            "4135780cc16a4db59b2e879a0b5b9abf",
            "7c4cbb256b7a47e491cc3ad212e31b5d",
            "e8e8fe1819c44c6aad31130f1899834b",
            "8e3bee401e4f4337960a28eab1d4e274",
            "febec210c0fd4dfa8d2d32efa4c1a5b1",
            "456b3399506349888b11ae157cf7372e",
            "3529f88bef074ced8ac46547e3f685a1",
            "d25b4c66e9f74e97b768e59cf2d929c0",
            "10982521d3104a50abbf2ecb1effba51",
            "0791aabad7f049c2bd24a78ba8d56cff",
            "4e2303dc9fab4a699c0b9877dd756307",
            "ab656885af4440f7b719c90391d9f7ef",
            "f43b7bb62a7746b3b2a49f88fd2660b5",
            "a4a6780e506a4e6081e9d4172250d388",
            "c1b8d87574434858865a6a6189985861"
          ]
        },
        "outputId": "2c8afd06-4f74-4abe-fa5d-81d02473156a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[RANK 0] Initializing model: google/flan-t5-large\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[37mroot\u001b[0m\n",
              "├── \u001b[31mshared\u001b[0m\u001b[32m(Embedding),\u001b[0m\u001b[31mlm_head\u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[38;2;0;70;100mweight:[32128, 1024]\u001b[0m\n",
              "├── \u001b[37mencoder \u001b[0m\u001b[32m(T5Stack)\u001b[0m\n",
              "│   ├── \u001b[37membed_tokens \u001b[0m\u001b[32m(Embedding) \u001b[0m\u001b[38;2;0;70;100mweight:[32128, 1024]\u001b[0m\n",
              "│   ├── \u001b[37mblock \u001b[0m\u001b[32m(ModuleList)\u001b[0m\n",
              "│   │   ├── \u001b[37m0 \u001b[0m\u001b[32m(T5Block)\u001b[0m\n",
              "│   │   │   └── \u001b[37mlayer \u001b[0m\u001b[32m(ModuleList)\u001b[0m\n",
              "│   │   │       ├── \u001b[37m0 \u001b[0m\u001b[32m(T5LayerSelfAttention)\u001b[0m\n",
              "│   │   │       │   ├── \u001b[37mSelfAttention \u001b[0m\u001b[32m(T5Attention)\u001b[0m\n",
              "│   │   │       │   │   ├── \u001b[31mq,k,v,o\u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[38;2;0;70;100mweight:[1024, 1024]\u001b[0m\n",
              "│   │   │       │   │   └── \u001b[37mrelative_attention_bias \u001b[0m\u001b[32m(Embedding) \u001b[0m\u001b[38;2;0;70;100mweight:[32, 16]\u001b[0m\n",
              "│   │   │       │   └── \u001b[37mlayer_norm \u001b[0m\u001b[32m(T5LayerNorm) \u001b[0m\u001b[38;2;0;70;100mweight:[1024]\u001b[0m\n",
              "│   │   │       └── \u001b[37m1 \u001b[0m\u001b[32m(T5LayerFF)\u001b[0m\n",
              "│   │   │           ├── \u001b[37mDenseReluDense \u001b[0m\u001b[32m(T5DenseGatedActDense)\u001b[0m\n",
              "│   │   │           │   ├── \u001b[31mwi_0,wi_1\u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[38;2;0;70;100mweight:[2816, 1024]\u001b[0m\n",
              "│   │   │           │   └── \u001b[37mwo \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[38;2;0;70;100mweight:[1024, 2816]\u001b[0m\n",
              "│   │   │           └── \u001b[37mlayer_norm \u001b[0m\u001b[32m(T5LayerNorm) \u001b[0m\u001b[38;2;0;70;100mweight:[1024]\u001b[0m\n",
              "│   │   └── \u001b[31m1-23\u001b[0m\u001b[32m(T5Block)\u001b[0m\n",
              "│   │       └── \u001b[37mlayer \u001b[0m\u001b[32m(ModuleList)\u001b[0m\n",
              "│   │           ├── \u001b[37m0 \u001b[0m\u001b[32m(T5LayerSelfAttention)\u001b[0m\n",
              "│   │           │   ├── \u001b[37mSelfAttention \u001b[0m\u001b[32m(T5Attention)\u001b[0m\n",
              "│   │           │   │   └── \u001b[31mq,k,v,o\u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[38;2;0;70;100mweight:[1024, 1024]\u001b[0m\n",
              "│   │           │   └── \u001b[37mlayer_norm \u001b[0m\u001b[32m(T5LayerNorm) \u001b[0m\u001b[38;2;0;70;100mweight:[1024]\u001b[0m\n",
              "│   │           └── \u001b[37m1 \u001b[0m\u001b[32m(T5LayerFF)\u001b[0m\n",
              "│   │               ├── \u001b[37mDenseReluDense \u001b[0m\u001b[32m(T5DenseGatedActDense)\u001b[0m\n",
              "│   │               │   ├── \u001b[31mwi_0,wi_1\u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[38;2;0;70;100mweight:[2816, 1024]\u001b[0m\n",
              "│   │               │   └── \u001b[37mwo \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[38;2;0;70;100mweight:[1024, 2816]\u001b[0m\n",
              "│   │               └── \u001b[37mlayer_norm \u001b[0m\u001b[32m(T5LayerNorm) \u001b[0m\u001b[38;2;0;70;100mweight:[1024]\u001b[0m\n",
              "│   └── \u001b[37mfinal_layer_norm \u001b[0m\u001b[32m(T5LayerNorm) \u001b[0m\u001b[38;2;0;70;100mweight:[1024]\u001b[0m\n",
              "└── \u001b[37mdecoder \u001b[0m\u001b[32m(T5Stack)\u001b[0m\n",
              "    ├── \u001b[37membed_tokens \u001b[0m\u001b[32m(Embedding) \u001b[0m\u001b[38;2;0;70;100mweight:[32128, 1024]\u001b[0m\n",
              "    ├── \u001b[37mblock \u001b[0m\u001b[32m(ModuleList)\u001b[0m\n",
              "    │   ├── \u001b[37m0 \u001b[0m\u001b[32m(T5Block)\u001b[0m\n",
              "    │   │   └── \u001b[37mlayer \u001b[0m\u001b[32m(ModuleList)\u001b[0m\n",
              "    │   │       ├── \u001b[37m0 \u001b[0m\u001b[32m(T5LayerSelfAttention)\u001b[0m\n",
              "    │   │       │   ├── \u001b[37mSelfAttention \u001b[0m\u001b[32m(T5Attention)\u001b[0m\n",
              "    │   │       │   │   ├── \u001b[31mq,k,v,o\u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[38;2;0;70;100mweight:[1024, 1024]\u001b[0m\n",
              "    │   │       │   │   │   └── \u001b[37mlora \u001b[0m\u001b[32m(LowRankLinear) \u001b[0m\u001b[38;2;175;0;255mlora_A:[8, 1024] \u001b[0m\u001b[38;2;175;0;255mlora_B:[1024, 8]\u001b[0m\n",
              "    │   │       │   │   └── \u001b[37mrelative_attention_bias \u001b[0m\u001b[32m(Embedding) \u001b[0m\u001b[38;2;0;70;100mweight:[32, 16]\u001b[0m\n",
              "    │   │       │   └── \u001b[37mlayer_norm \u001b[0m\u001b[32m(T5LayerNorm) \u001b[0m\u001b[38;2;0;70;100mweight:[1024]\u001b[0m\n",
              "    │   │       ├── \u001b[37m1 \u001b[0m\u001b[32m(T5LayerCrossAttention)\u001b[0m\n",
              "    │   │       │   ├── \u001b[37mEncDecAttention \u001b[0m\u001b[32m(T5Attention)\u001b[0m\n",
              "    │   │       │   │   └── \u001b[31mq,k,v,o\u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[38;2;0;70;100mweight:[1024, 1024]\u001b[0m\n",
              "    │   │       │   │       └── \u001b[37mlora \u001b[0m\u001b[32m(LowRankLinear) \u001b[0m\u001b[38;2;175;0;255mlora_A:[8, 1024] \u001b[0m\u001b[38;2;175;0;255mlora_B:[1024, 8]\u001b[0m\n",
              "    │   │       │   └── \u001b[37mlayer_norm \u001b[0m\u001b[32m(T5LayerNorm) \u001b[0m\u001b[38;2;0;70;100mweight:[1024]\u001b[0m\n",
              "    │   │       └── \u001b[37m2 \u001b[0m\u001b[32m(T5LayerFF)\u001b[0m\n",
              "    │   │           ├── \u001b[37mDenseReluDense \u001b[0m\u001b[32m(T5DenseGatedActDense)\u001b[0m\n",
              "    │   │           │   ├── \u001b[31mwi_0,wi_1\u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[38;2;0;70;100mweight:[2816, 1024]\u001b[0m\n",
              "    │   │           │   │   └── \u001b[37mlora \u001b[0m\u001b[32m(LowRankLinear) \u001b[0m\u001b[38;2;175;0;255mlora_A:[8, 1024] \u001b[0m\u001b[38;2;175;0;255mlora_B:[2816, 8]\u001b[0m\n",
              "    │   │           │   └── \u001b[37mwo \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[38;2;0;70;100mweight:[1024, 2816]\u001b[0m\n",
              "    │   │           │       └── \u001b[37mlora \u001b[0m\u001b[32m(LowRankLinear) \u001b[0m\u001b[38;2;175;0;255mlora_A:[8, 2816] \u001b[0m\u001b[38;2;175;0;255mlora_B:[1024, 8]\u001b[0m\n",
              "    │   │           └── \u001b[37mlayer_norm \u001b[0m\u001b[32m(T5LayerNorm) \u001b[0m\u001b[38;2;0;70;100mweight:[1024]\u001b[0m\n",
              "    │   └── \u001b[31m1-23\u001b[0m\u001b[32m(T5Block)\u001b[0m\n",
              "    │       └── \u001b[37mlayer \u001b[0m\u001b[32m(ModuleList)\u001b[0m\n",
              "    │           ├── \u001b[37m0 \u001b[0m\u001b[32m(T5LayerSelfAttention)\u001b[0m\n",
              "    │           │   ├── \u001b[37mSelfAttention \u001b[0m\u001b[32m(T5Attention)\u001b[0m\n",
              "    │           │   │   └── \u001b[31mq,k,v,o\u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[38;2;0;70;100mweight:[1024, 1024]\u001b[0m\n",
              "    │           │   │       └── \u001b[37mlora \u001b[0m\u001b[32m(LowRankLinear) \u001b[0m\u001b[38;2;175;0;255mlora_A:[8, 1024] \u001b[0m\u001b[38;2;175;0;255mlora_B:[1024, 8]\u001b[0m\n",
              "    │           │   └── \u001b[37mlayer_norm \u001b[0m\u001b[32m(T5LayerNorm) \u001b[0m\u001b[38;2;0;70;100mweight:[1024]\u001b[0m\n",
              "    │           ├── \u001b[37m1 \u001b[0m\u001b[32m(T5LayerCrossAttention)\u001b[0m\n",
              "    │           │   ├── \u001b[37mEncDecAttention \u001b[0m\u001b[32m(T5Attention)\u001b[0m\n",
              "    │           │   │   └── \u001b[31mq,k,v,o\u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[38;2;0;70;100mweight:[1024, 1024]\u001b[0m\n",
              "    │           │   │       └── \u001b[37mlora \u001b[0m\u001b[32m(LowRankLinear) \u001b[0m\u001b[38;2;175;0;255mlora_A:[8, 1024] \u001b[0m\u001b[38;2;175;0;255mlora_B:[1024, 8]\u001b[0m\n",
              "    │           │   └── \u001b[37mlayer_norm \u001b[0m\u001b[32m(T5LayerNorm) \u001b[0m\u001b[38;2;0;70;100mweight:[1024]\u001b[0m\n",
              "    │           └── \u001b[37m2 \u001b[0m\u001b[32m(T5LayerFF)\u001b[0m\n",
              "    │               ├── \u001b[37mDenseReluDense \u001b[0m\u001b[32m(T5DenseGatedActDense)\u001b[0m\n",
              "    │               │   ├── \u001b[31mwi_0,wi_1\u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[38;2;0;70;100mweight:[2816, 1024]\u001b[0m\n",
              "    │               │   │   └── \u001b[37mlora \u001b[0m\u001b[32m(LowRankLinear) \u001b[0m\u001b[38;2;175;0;255mlora_A:[8, 1024] \u001b[0m\u001b[38;2;175;0;255mlora_B:[2816, 8]\u001b[0m\n",
              "    │               │   └── \u001b[37mwo \u001b[0m\u001b[32m(Linear) \u001b[0m\u001b[38;2;0;70;100mweight:[1024, 2816]\u001b[0m\n",
              "    │               │       └── \u001b[37mlora \u001b[0m\u001b[32m(LowRankLinear) \u001b[0m\u001b[38;2;175;0;255mlora_A:[8, 2816] \u001b[0m\u001b[38;2;175;0;255mlora_B:[1024, 8]\u001b[0m\n",
              "    │               └── \u001b[37mlayer_norm \u001b[0m\u001b[32m(T5LayerNorm) \u001b[0m\u001b[38;2;0;70;100mweight:[1024]\u001b[0m\n",
              "    └── \u001b[37mfinal_layer_norm \u001b[0m\u001b[32m(T5LayerNorm) \u001b[0m\u001b[38;2;0;70;100mweight:[1024]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">root</span>\n",
              "├── <span style=\"color: #800000; text-decoration-color: #800000\">shared</span><span style=\"color: #008000; text-decoration-color: #008000\">(Embedding),</span><span style=\"color: #800000; text-decoration-color: #800000\">lm_head</span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[32128, 1024]</span>\n",
              "├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">encoder </span><span style=\"color: #008000; text-decoration-color: #008000\">(T5Stack)</span>\n",
              "│   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">embed_tokens </span><span style=\"color: #008000; text-decoration-color: #008000\">(Embedding) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[32128, 1024]</span>\n",
              "│   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">block </span><span style=\"color: #008000; text-decoration-color: #008000\">(ModuleList)</span>\n",
              "│   │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0 </span><span style=\"color: #008000; text-decoration-color: #008000\">(T5Block)</span>\n",
              "│   │   │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">layer </span><span style=\"color: #008000; text-decoration-color: #008000\">(ModuleList)</span>\n",
              "│   │   │       ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0 </span><span style=\"color: #008000; text-decoration-color: #008000\">(T5LayerSelfAttention)</span>\n",
              "│   │   │       │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">SelfAttention </span><span style=\"color: #008000; text-decoration-color: #008000\">(T5Attention)</span>\n",
              "│   │   │       │   │   ├── <span style=\"color: #800000; text-decoration-color: #800000\">q,k,v,o</span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[1024, 1024]</span>\n",
              "│   │   │       │   │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">relative_attention_bias </span><span style=\"color: #008000; text-decoration-color: #008000\">(Embedding) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[32, 16]</span>\n",
              "│   │   │       │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">layer_norm </span><span style=\"color: #008000; text-decoration-color: #008000\">(T5LayerNorm) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[1024]</span>\n",
              "│   │   │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">1 </span><span style=\"color: #008000; text-decoration-color: #008000\">(T5LayerFF)</span>\n",
              "│   │   │           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">DenseReluDense </span><span style=\"color: #008000; text-decoration-color: #008000\">(T5DenseGatedActDense)</span>\n",
              "│   │   │           │   ├── <span style=\"color: #800000; text-decoration-color: #800000\">wi_0,wi_1</span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[2816, 1024]</span>\n",
              "│   │   │           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">wo </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[1024, 2816]</span>\n",
              "│   │   │           └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">layer_norm </span><span style=\"color: #008000; text-decoration-color: #008000\">(T5LayerNorm) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[1024]</span>\n",
              "│   │   └── <span style=\"color: #800000; text-decoration-color: #800000\">1-23</span><span style=\"color: #008000; text-decoration-color: #008000\">(T5Block)</span>\n",
              "│   │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">layer </span><span style=\"color: #008000; text-decoration-color: #008000\">(ModuleList)</span>\n",
              "│   │           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0 </span><span style=\"color: #008000; text-decoration-color: #008000\">(T5LayerSelfAttention)</span>\n",
              "│   │           │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">SelfAttention </span><span style=\"color: #008000; text-decoration-color: #008000\">(T5Attention)</span>\n",
              "│   │           │   │   └── <span style=\"color: #800000; text-decoration-color: #800000\">q,k,v,o</span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[1024, 1024]</span>\n",
              "│   │           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">layer_norm </span><span style=\"color: #008000; text-decoration-color: #008000\">(T5LayerNorm) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[1024]</span>\n",
              "│   │           └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">1 </span><span style=\"color: #008000; text-decoration-color: #008000\">(T5LayerFF)</span>\n",
              "│   │               ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">DenseReluDense </span><span style=\"color: #008000; text-decoration-color: #008000\">(T5DenseGatedActDense)</span>\n",
              "│   │               │   ├── <span style=\"color: #800000; text-decoration-color: #800000\">wi_0,wi_1</span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[2816, 1024]</span>\n",
              "│   │               │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">wo </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[1024, 2816]</span>\n",
              "│   │               └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">layer_norm </span><span style=\"color: #008000; text-decoration-color: #008000\">(T5LayerNorm) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[1024]</span>\n",
              "│   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">final_layer_norm </span><span style=\"color: #008000; text-decoration-color: #008000\">(T5LayerNorm) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[1024]</span>\n",
              "└── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">decoder </span><span style=\"color: #008000; text-decoration-color: #008000\">(T5Stack)</span>\n",
              "    ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">embed_tokens </span><span style=\"color: #008000; text-decoration-color: #008000\">(Embedding) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[32128, 1024]</span>\n",
              "    ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">block </span><span style=\"color: #008000; text-decoration-color: #008000\">(ModuleList)</span>\n",
              "    │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0 </span><span style=\"color: #008000; text-decoration-color: #008000\">(T5Block)</span>\n",
              "    │   │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">layer </span><span style=\"color: #008000; text-decoration-color: #008000\">(ModuleList)</span>\n",
              "    │   │       ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0 </span><span style=\"color: #008000; text-decoration-color: #008000\">(T5LayerSelfAttention)</span>\n",
              "    │   │       │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">SelfAttention </span><span style=\"color: #008000; text-decoration-color: #008000\">(T5Attention)</span>\n",
              "    │   │       │   │   ├── <span style=\"color: #800000; text-decoration-color: #800000\">q,k,v,o</span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[1024, 1024]</span>\n",
              "    │   │       │   │   │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">lora </span><span style=\"color: #008000; text-decoration-color: #008000\">(LowRankLinear) </span><span style=\"color: #af00ff; text-decoration-color: #af00ff\">lora_A:[8, 1024] lora_B:[1024, 8]</span>\n",
              "    │   │       │   │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">relative_attention_bias </span><span style=\"color: #008000; text-decoration-color: #008000\">(Embedding) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[32, 16]</span>\n",
              "    │   │       │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">layer_norm </span><span style=\"color: #008000; text-decoration-color: #008000\">(T5LayerNorm) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[1024]</span>\n",
              "    │   │       ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">1 </span><span style=\"color: #008000; text-decoration-color: #008000\">(T5LayerCrossAttention)</span>\n",
              "    │   │       │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">EncDecAttention </span><span style=\"color: #008000; text-decoration-color: #008000\">(T5Attention)</span>\n",
              "    │   │       │   │   └── <span style=\"color: #800000; text-decoration-color: #800000\">q,k,v,o</span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[1024, 1024]</span>\n",
              "    │   │       │   │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">lora </span><span style=\"color: #008000; text-decoration-color: #008000\">(LowRankLinear) </span><span style=\"color: #af00ff; text-decoration-color: #af00ff\">lora_A:[8, 1024] lora_B:[1024, 8]</span>\n",
              "    │   │       │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">layer_norm </span><span style=\"color: #008000; text-decoration-color: #008000\">(T5LayerNorm) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[1024]</span>\n",
              "    │   │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">2 </span><span style=\"color: #008000; text-decoration-color: #008000\">(T5LayerFF)</span>\n",
              "    │   │           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">DenseReluDense </span><span style=\"color: #008000; text-decoration-color: #008000\">(T5DenseGatedActDense)</span>\n",
              "    │   │           │   ├── <span style=\"color: #800000; text-decoration-color: #800000\">wi_0,wi_1</span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[2816, 1024]</span>\n",
              "    │   │           │   │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">lora </span><span style=\"color: #008000; text-decoration-color: #008000\">(LowRankLinear) </span><span style=\"color: #af00ff; text-decoration-color: #af00ff\">lora_A:[8, 1024] lora_B:[2816, 8]</span>\n",
              "    │   │           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">wo </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[1024, 2816]</span>\n",
              "    │   │           │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">lora </span><span style=\"color: #008000; text-decoration-color: #008000\">(LowRankLinear) </span><span style=\"color: #af00ff; text-decoration-color: #af00ff\">lora_A:[8, 2816] lora_B:[1024, 8]</span>\n",
              "    │   │           └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">layer_norm </span><span style=\"color: #008000; text-decoration-color: #008000\">(T5LayerNorm) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[1024]</span>\n",
              "    │   └── <span style=\"color: #800000; text-decoration-color: #800000\">1-23</span><span style=\"color: #008000; text-decoration-color: #008000\">(T5Block)</span>\n",
              "    │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">layer </span><span style=\"color: #008000; text-decoration-color: #008000\">(ModuleList)</span>\n",
              "    │           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0 </span><span style=\"color: #008000; text-decoration-color: #008000\">(T5LayerSelfAttention)</span>\n",
              "    │           │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">SelfAttention </span><span style=\"color: #008000; text-decoration-color: #008000\">(T5Attention)</span>\n",
              "    │           │   │   └── <span style=\"color: #800000; text-decoration-color: #800000\">q,k,v,o</span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[1024, 1024]</span>\n",
              "    │           │   │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">lora </span><span style=\"color: #008000; text-decoration-color: #008000\">(LowRankLinear) </span><span style=\"color: #af00ff; text-decoration-color: #af00ff\">lora_A:[8, 1024] lora_B:[1024, 8]</span>\n",
              "    │           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">layer_norm </span><span style=\"color: #008000; text-decoration-color: #008000\">(T5LayerNorm) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[1024]</span>\n",
              "    │           ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">1 </span><span style=\"color: #008000; text-decoration-color: #008000\">(T5LayerCrossAttention)</span>\n",
              "    │           │   ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">EncDecAttention </span><span style=\"color: #008000; text-decoration-color: #008000\">(T5Attention)</span>\n",
              "    │           │   │   └── <span style=\"color: #800000; text-decoration-color: #800000\">q,k,v,o</span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[1024, 1024]</span>\n",
              "    │           │   │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">lora </span><span style=\"color: #008000; text-decoration-color: #008000\">(LowRankLinear) </span><span style=\"color: #af00ff; text-decoration-color: #af00ff\">lora_A:[8, 1024] lora_B:[1024, 8]</span>\n",
              "    │           │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">layer_norm </span><span style=\"color: #008000; text-decoration-color: #008000\">(T5LayerNorm) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[1024]</span>\n",
              "    │           └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">2 </span><span style=\"color: #008000; text-decoration-color: #008000\">(T5LayerFF)</span>\n",
              "    │               ├── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">DenseReluDense </span><span style=\"color: #008000; text-decoration-color: #008000\">(T5DenseGatedActDense)</span>\n",
              "    │               │   ├── <span style=\"color: #800000; text-decoration-color: #800000\">wi_0,wi_1</span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[2816, 1024]</span>\n",
              "    │               │   │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">lora </span><span style=\"color: #008000; text-decoration-color: #008000\">(LowRankLinear) </span><span style=\"color: #af00ff; text-decoration-color: #af00ff\">lora_A:[8, 1024] lora_B:[2816, 8]</span>\n",
              "    │               │   └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">wo </span><span style=\"color: #008000; text-decoration-color: #008000\">(Linear) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[1024, 2816]</span>\n",
              "    │               │       └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">lora </span><span style=\"color: #008000; text-decoration-color: #008000\">(LowRankLinear) </span><span style=\"color: #af00ff; text-decoration-color: #af00ff\">lora_A:[8, 2816] lora_B:[1024, 8]</span>\n",
              "    │               └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">layer_norm </span><span style=\"color: #008000; text-decoration-color: #008000\">(T5LayerNorm) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[1024]</span>\n",
              "    └── <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">final_layer_norm </span><span style=\"color: #008000; text-decoration-color: #008000\">(T5LayerNorm) </span><span style=\"color: #004664; text-decoration-color: #004664\">weight:[1024]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[INFO|(OpenDelta)basemodel:696]2023-04-18 16:37:14,171 >> Trainable Ratio: 5357568/788507648=0.679457%\n",
            "[INFO|(OpenDelta)basemodel:698]2023-04-18 16:37:14,173 >> Delta Parameter Ratio: 5357568/788507648=0.679457%\n",
            "[INFO|(OpenDelta)basemodel:700]2023-04-18 16:37:14,176 >> Static Memory 0.00 GB, Max Memory 0.00 GB\n",
            "[RANK 0] Collecting rollouts\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (608 > 512). Running this sequence through the model will result in indexing errors\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n",
            "[RANK 0] Logging sample example\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                                                  Sample Example                                                   \u001b[0m\n",
              "┏━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mPrompt\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mResponse                                                                                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mReward\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
              "│ </s>   │ When Tsui Hark experiments, nothing and no one can withstand him. Legend of Zu is possibly    │ 0.0    │\n",
              "│        │ 6Hours condensed into 1h40. One does not understand all, but like at \"2001 A Space Odyssey\"   │        │\n",
              "│        │ you also don't have to, but one feels the power of the film to every second, every picture.   │        │\n",
              "│        │ An extraordinary vision of the future of the 7th art and the one of the most pioneering,      │        │\n",
              "│        │ astounding, rejoicing in the recent years. VITAL severe MASTERPIECE! It's absolutely perfect  │        │\n",
              "│        │ as it is.<unk>br /><unk>br />When Tsui Hark experiments, nothing and no one can withstand     │        │\n",
              "│        │ him. Legend of Zu is possibly 6Hours condensed into 1h40. One does not understand all, but    │        │\n",
              "│        │ one feels the power of the film to every second, every picture. An extraordinary vision of    │        │\n",
              "│        │ the future of the 7th art and the one of the most pioneering, astounding, rejoicing in the    │        │\n",
              "│        │ recent years. VITAL severe MASTERPIECE! It's absolutely perfect as it is.                     │        │\n",
              "│        │ 10000000000000/10000000000000</s>                                                             │        │\n",
              "└────────┴───────────────────────────────────────────────────────────────────────────────────────────────┴────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                  Sample Example                                                   </span>\n",
              "┏━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Prompt </span>┃<span style=\"font-weight: bold\"> Response                                                                                      </span>┃<span style=\"font-weight: bold\"> Reward </span>┃\n",
              "┡━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
              "│ &lt;/s&gt;   │ When Tsui Hark experiments, nothing and no one can withstand him. Legend of Zu is possibly    │ 0.0    │\n",
              "│        │ 6Hours condensed into 1h40. One does not understand all, but like at \"2001 A Space Odyssey\"   │        │\n",
              "│        │ you also don't have to, but one feels the power of the film to every second, every picture.   │        │\n",
              "│        │ An extraordinary vision of the future of the 7th art and the one of the most pioneering,      │        │\n",
              "│        │ astounding, rejoicing in the recent years. VITAL severe MASTERPIECE! It's absolutely perfect  │        │\n",
              "│        │ as it is.&lt;unk&gt;br /&gt;&lt;unk&gt;br /&gt;When Tsui Hark experiments, nothing and no one can withstand     │        │\n",
              "│        │ him. Legend of Zu is possibly 6Hours condensed into 1h40. One does not understand all, but    │        │\n",
              "│        │ one feels the power of the film to every second, every picture. An extraordinary vision of    │        │\n",
              "│        │ the future of the 7th art and the one of the most pioneering, astounding, rejoicing in the    │        │\n",
              "│        │ recent years. VITAL severe MASTERPIECE! It's absolutely perfect as it is.                     │        │\n",
              "│        │ 10000000000000/10000000000000&lt;/s&gt;                                                             │        │\n",
              "└────────┴───────────────────────────────────────────────────────────────────────────────────────────────┴────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[RANK 0] Logging experience string statistics\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m        Experience String Stats (mean ∈ [min, max])        \u001b[0m\n",
              "┏━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mPrompt Length\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Length     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mSample Length     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ 1.00 ∈ [1, 1] │ 209.70 ∈ [21, 255] │ 210.70 ∈ [22, 256] │\n",
              "└───────────────┴────────────────────┴────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">        Experience String Stats (mean ∈ [min, max])        </span>\n",
              "┏━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Prompt Length </span>┃<span style=\"font-weight: bold\"> Output Length      </span>┃<span style=\"font-weight: bold\"> Sample Length      </span>┃\n",
              "┡━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ 1.00 ∈ [1, 1] │ 209.70 ∈ [21, 255] │ 210.70 ∈ [22, 256] │\n",
              "└───────────────┴────────────────────┴────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[RANK 0] Starting training\n",
            "[RANK 0] Evaluating model\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[generation sweep 0/1 | eval batch 0/4]:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "71a7bfcb3ce644a28e10639c3439d0a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "[RANK 0] Computing metrics\n",
            "[RANK 0] Summarizing evaluation\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                                      Evaluation #0 metrics/sentiments: 0.321                                      \u001b[0m\n",
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mprompt                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutput                                                             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1msentiments\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
              "│ What made this movie so      │ This movie is just awful, the acting and editing was terrible, and  │ 0.997      │\n",
              "│                              │ the storyline was just laugh out loud stupid. It would be a waste   │            │\n",
              "│                              │ of money to even make an episode of this movie, what was with the   │            │\n",
              "│                              │ original show?                                                      │            │\n",
              "├──────────────────────────────┼─────────────────────────────────────────────────────────────────────┼────────────┤\n",
              "│ This actor of this movie is  │ This actor of this movie this movie is this movie of actor of actor │ 0.286      │\n",
              "├──────────────────────────────┼─────────────────────────────────────────────────────────────────────┼────────────┤\n",
              "│ This plot of the movie is    │ This plot of the movie is the movie is the movie is the flir of the │ 0.218      │\n",
              "│                              │ i n this plot the movie is the The movie is the the movie is the    │            │\n",
              "│                              │ movie is this plot of the movie is the story about the asian sen    │            │\n",
              "└──────────────────────────────┴─────────────────────────────────────────────────────────────────────┴────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                      Evaluation #0 metrics/sentiments: 0.321                                      </span>\n",
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> prompt                       </span>┃<span style=\"font-weight: bold\"> output                                                              </span>┃<span style=\"font-weight: bold\"> sentiments </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
              "│ What made this movie so      │ This movie is just awful, the acting and editing was terrible, and  │ 0.997      │\n",
              "│                              │ the storyline was just laugh out loud stupid. It would be a waste   │            │\n",
              "│                              │ of money to even make an episode of this movie, what was with the   │            │\n",
              "│                              │ original show?                                                      │            │\n",
              "├──────────────────────────────┼─────────────────────────────────────────────────────────────────────┼────────────┤\n",
              "│ This actor of this movie is  │ This actor of this movie this movie is this movie of actor of actor │ 0.286      │\n",
              "├──────────────────────────────┼─────────────────────────────────────────────────────────────────────┼────────────┤\n",
              "│ This plot of the movie is    │ This plot of the movie is the movie is the movie is the flir of the │ 0.218      │\n",
              "│                              │ i n this plot the movie is the The movie is the the movie is the    │            │\n",
              "│                              │ movie is this plot of the movie is the story about the asian sen    │            │\n",
              "└──────────────────────────────┴─────────────────────────────────────────────────────────────────────┴────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "febec210c0fd4dfa8d2d32efa4c1a5b1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92m<cell line: 6>\u001b[0m:\u001b[94m6\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/content/drive/MyDrive/trlx_0403/trlx/trlx/\u001b[0m\u001b[1;33mtrlx.py\u001b[0m:\u001b[94m124\u001b[0m in \u001b[92mtrain\u001b[0m                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m121 \u001b[0m\u001b[2m│   \u001b[0meval_pipeline = get_pipeline(config.train.pipeline)(eval_prompts, max_prompt_length,   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m122 \u001b[0m\u001b[2m│   \u001b[0mtrainer.add_eval_pipeline(eval_pipeline)                                               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m123 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m124 \u001b[2m│   \u001b[0mtrainer.learn()                                                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m125 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m trainer                                                                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m126 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/content/drive/MyDrive/trlx_0403/trlx/trlx/trainer/\u001b[0m\u001b[1;33maccelerate_base_trainer.py\u001b[0m:\u001b[94m533\u001b[0m in \u001b[92mlearn\u001b[0m       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m530 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mfor\u001b[0m mb \u001b[95min\u001b[0m mbs:                                                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m531 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mself\u001b[0m._accumulate():                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m532 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0mforward_time -= time()                                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m533 \u001b[2m│   │   │   │   │   │   │   \u001b[0mloss, stats = \u001b[96mself\u001b[0m.loss(mb)                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m534 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0mforward_time += time()                                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m535 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0mbackward_time -= time()                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m536 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.accelerator.backward(loss)                                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/content/drive/MyDrive/trlx_0403/trlx/trlx/trainer/\u001b[0m\u001b[1;33maccelerate_ilql_trainer.py\u001b[0m:\u001b[94m143\u001b[0m in \u001b[92mloss\u001b[0m        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m140 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mloss\u001b[0m(\u001b[96mself\u001b[0m, batch: Union[ILQLBatch, ILQLSeq2SeqBatch]):                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m141 \u001b[0m\u001b[2m│   │   \u001b[0mbatch = to_device(batch, \u001b[96mself\u001b[0m.accelerator.device)                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m142 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.config.model.model_arch_type == \u001b[33m\"\u001b[0m\u001b[33mseq2seq\u001b[0m\u001b[33m\"\u001b[0m:                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m143 \u001b[2m│   │   │   \u001b[0mlogits, qs, target_qs, vs, _, _ = \u001b[96mself\u001b[0m.model(                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m144 \u001b[0m\u001b[2m│   │   │   │   \u001b[0minput_ids=batch.input_ids,                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m145 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mattention_mask=batch.attention_mask,                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m146 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mactions_ixs=batch.actions_ixs,                                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/content/drive/MyDrive/trlx_0403/trlx/trlx/models/\u001b[0m\u001b[1;33mmodeling_ilql.py\u001b[0m:\u001b[94m422\u001b[0m in \u001b[92mforward\u001b[0m                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m419 \u001b[0m\u001b[2m│   │   \u001b[0mhs = out.decoder_hidden_states[-\u001b[94m1\u001b[0m]                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m420 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m421 \u001b[0m\u001b[2m│   │   \u001b[0mlogits = \u001b[96mself\u001b[0m.base_model.lm_head(hs)                                               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m422 \u001b[2m│   │   \u001b[0mqs, target_qs, vs = \u001b[96mself\u001b[0m.ilql_heads(hs, states_ixs=states_ixs, actions_ixs=actio   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m423 \u001b[0m\u001b[2m│   │   \u001b[0mencoder_outputs = (out.encoder_last_hidden_state, out.encoder_hidden_states, out   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m424 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m logits, qs, target_qs, vs, out.past_key_values, encoder_outputs             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m425 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/content/drive/MyDrive/trlx_0403/trlx/trlx/models/\u001b[0m\u001b[1;33mmodeling_ilql.py\u001b[0m:\u001b[94m176\u001b[0m in \u001b[92mforward\u001b[0m                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m173 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m174 \u001b[0m\u001b[2m│   │   │   \u001b[0mstates_hs = actions_hs = hs                                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m175 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m176 \u001b[2m│   │   \u001b[0mqs = \u001b[96mtuple\u001b[0m(q_head(actions_hs) \u001b[94mfor\u001b[0m q_head \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.q_heads)                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m177 \u001b[0m\u001b[2m│   │   \u001b[0mtarget_qs = \u001b[96mtuple\u001b[0m(q_head(actions_hs) \u001b[94mfor\u001b[0m q_head \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.target_q_heads)            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m178 \u001b[0m\u001b[2m│   │   \u001b[0mvs = \u001b[96mself\u001b[0m.v_head(states_hs)                                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m179 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/content/drive/MyDrive/trlx_0403/trlx/trlx/models/\u001b[0m\u001b[1;33mmodeling_ilql.py\u001b[0m:\u001b[94m176\u001b[0m in \u001b[92m<genexpr>\u001b[0m              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m173 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m174 \u001b[0m\u001b[2m│   │   │   \u001b[0mstates_hs = actions_hs = hs                                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m175 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m176 \u001b[2m│   │   \u001b[0mqs = \u001b[96mtuple\u001b[0m(q_head(actions_hs) \u001b[94mfor\u001b[0m q_head \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.q_heads)                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m177 \u001b[0m\u001b[2m│   │   \u001b[0mtarget_qs = \u001b[96mtuple\u001b[0m(q_head(actions_hs) \u001b[94mfor\u001b[0m q_head \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.target_q_heads)            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m178 \u001b[0m\u001b[2m│   │   \u001b[0mvs = \u001b[96mself\u001b[0m.v_head(states_hs)                                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m179 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mcontainer.py\u001b[0m:\u001b[94m217\u001b[0m in \u001b[92mforward\u001b[0m              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m214 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# with Any as TorchScript expects a more precise type\u001b[0m                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m215 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m):                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m216 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m module \u001b[95min\u001b[0m \u001b[96mself\u001b[0m:                                                                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m217 \u001b[2m│   │   │   \u001b[0m\u001b[96minput\u001b[0m = module(\u001b[96minput\u001b[0m)                                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m218 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96minput\u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m219 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m220 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mappend\u001b[0m(\u001b[96mself\u001b[0m, module: Module) -> \u001b[33m'\u001b[0m\u001b[33mSequential\u001b[0m\u001b[33m'\u001b[0m:                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mlinear.py\u001b[0m:\u001b[94m114\u001b[0m in \u001b[92mforward\u001b[0m                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m111 \u001b[0m\u001b[2m│   │   │   \u001b[0minit.uniform_(\u001b[96mself\u001b[0m.bias, -bound, bound)                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m: Tensor) -> Tensor:                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m114 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m F.linear(\u001b[96minput\u001b[0m, \u001b[96mself\u001b[0m.weight, \u001b[96mself\u001b[0m.bias)                                     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m115 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mextra_repr\u001b[0m(\u001b[96mself\u001b[0m) -> \u001b[96mstr\u001b[0m:                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m117 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[33m'\u001b[0m\u001b[33min_features=\u001b[0m\u001b[33m{}\u001b[0m\u001b[33m, out_features=\u001b[0m\u001b[33m{}\u001b[0m\u001b[33m, bias=\u001b[0m\u001b[33m{}\u001b[0m\u001b[33m'\u001b[0m.format(                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mOutOfMemoryError: \u001b[0mCUDA out of memory. Tried to allocate \u001b[1;36m250.00\u001b[0m MiB \u001b[1m(\u001b[0mGPU \u001b[1;36m0\u001b[0m; \u001b[1;36m14.75\u001b[0m GiB total capacity; \u001b[1;36m13.28\u001b[0m GiB \n",
              "already allocated; \u001b[1;36m140.81\u001b[0m MiB free; \u001b[1;36m13.63\u001b[0m GiB reserved in total by PyTorch\u001b[1m)\u001b[0m If reserved memory is >> allocated \n",
              "memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and \n",
              "PYTORCH_CUDA_ALLOC_CONF\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 6&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">6</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/content/drive/MyDrive/trlx_0403/trlx/trlx/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trlx.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">124</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train</span>                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121 │   </span>eval_pipeline = get_pipeline(config.train.pipeline)(eval_prompts, max_prompt_length,   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">122 │   </span>trainer.add_eval_pipeline(eval_pipeline)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">123 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>124 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>trainer.learn()                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">125 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> trainer                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">126 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/content/drive/MyDrive/trlx_0403/trlx/trlx/trainer/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">accelerate_base_trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">533</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">learn</span>       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">530 │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> mb <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> mbs:                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">531 │   │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._accumulate():                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">532 │   │   │   │   │   │   │   </span>forward_time -= time()                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>533 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   </span>loss, stats = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.loss(mb)                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">534 │   │   │   │   │   │   │   </span>forward_time += time()                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">535 │   │   │   │   │   │   │   </span>backward_time -= time()                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">536 │   │   │   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.accelerator.backward(loss)                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/content/drive/MyDrive/trlx_0403/trlx/trlx/trainer/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">accelerate_ilql_trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">143</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">loss</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">140 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">loss</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, batch: Union[ILQLBatch, ILQLSeq2SeqBatch]):                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">141 │   │   </span>batch = to_device(batch, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.accelerator.device)                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">142 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.config.model.model_arch_type == <span style=\"color: #808000; text-decoration-color: #808000\">\"seq2seq\"</span>:                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>143 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>logits, qs, target_qs, vs, _, _ = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.model(                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">144 │   │   │   │   </span>input_ids=batch.input_ids,                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">145 │   │   │   │   </span>attention_mask=batch.attention_mask,                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">146 │   │   │   │   </span>actions_ixs=batch.actions_ixs,                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.9/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/content/drive/MyDrive/trlx_0403/trlx/trlx/models/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_ilql.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">422</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">419 │   │   </span>hs = out.decoder_hidden_states[-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>]                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">420 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">421 │   │   </span>logits = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.base_model.lm_head(hs)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>422 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>qs, target_qs, vs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.ilql_heads(hs, states_ixs=states_ixs, actions_ixs=actio   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">423 │   │   </span>encoder_outputs = (out.encoder_last_hidden_state, out.encoder_hidden_states, out   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">424 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> logits, qs, target_qs, vs, out.past_key_values, encoder_outputs             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">425 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.9/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/content/drive/MyDrive/trlx_0403/trlx/trlx/models/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_ilql.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">176</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">173 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">174 │   │   │   </span>states_hs = actions_hs = hs                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">175 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>176 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>qs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">tuple</span>(q_head(actions_hs) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> q_head <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.q_heads)                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">177 │   │   </span>target_qs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">tuple</span>(q_head(actions_hs) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> q_head <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.target_q_heads)            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">178 │   │   </span>vs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.v_head(states_hs)                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">179 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/content/drive/MyDrive/trlx_0403/trlx/trlx/models/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_ilql.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">176</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;genexpr&gt;</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">173 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">174 │   │   │   </span>states_hs = actions_hs = hs                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">175 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>176 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>qs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">tuple</span>(q_head(actions_hs) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> q_head <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.q_heads)                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">177 │   │   </span>target_qs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">tuple</span>(q_head(actions_hs) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> q_head <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.target_q_heads)            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">178 │   │   </span>vs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.v_head(states_hs)                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">179 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.9/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.9/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">container.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">217</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">214 │   # with Any as TorchScript expects a more precise type</span>                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">215 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>):                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">216 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> module <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>:                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>217 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span> = module(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>)                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">218 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">219 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">220 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">append</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, module: Module) -&gt; <span style=\"color: #808000; text-decoration-color: #808000\">'Sequential'</span>:                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.9/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.9/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">linear.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">114</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">111 │   │   │   </span>init.uniform_(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.bias, -bound, bound)                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">112 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">113 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>: Tensor) -&gt; Tensor:                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>114 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> F.linear(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.weight, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.bias)                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">115 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">116 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">extra_repr</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>) -&gt; <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>:                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">117 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #808000; text-decoration-color: #808000\">'in_features={}, out_features={}, bias={}'</span>.format(                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">OutOfMemoryError: </span>CUDA out of memory. Tried to allocate <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">250.00</span> MiB <span style=\"font-weight: bold\">(</span>GPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14.75</span> GiB total capacity; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13.28</span> GiB \n",
              "already allocated; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">140.81</span> MiB free; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13.63</span> GiB reserved in total by PyTorch<span style=\"font-weight: bold\">)</span> If reserved memory is &gt;&gt; allocated \n",
              "memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and \n",
              "PYTORCH_CUDA_ALLOC_CONF\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# output\n",
        "input_str = 'this plot of the movie is  '\n",
        "trainer_output = trainer.generate_eval(\n",
        "    **trainer.tokenizer(input_str, return_tensors='pt'))[0]\n",
        "print(trainer.tokenizer.decode(trainer_output , skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-X5WpMhKGO-4",
        "outputId": "e4ffb2f5-8993-415a-d659-2ad84a048a96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This plot summary may be too long or excessively detailed. Please help improve it by removing unnecessary details and making it more concise. (May 2012) (Learn how and when to remove this template message) A SWAT team barges into a building that is\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# output\n",
        "input_str_list = ['What do you think of the movie ?']*20\n",
        "rlhf_t5_output_list = []\n",
        "for input_str in input_str_list:\n",
        "    trainer_output = trainer.generate_eval(**trainer.tokenizer(input_str, return_tensors='pt'))[0]\n",
        "    rlhf_t5_output_list.append(trainer.tokenizer.decode(trainer_output , skip_special_tokens=True))\n",
        "print(rlhf_t5_output_list)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUlDFq_lHbbW",
        "outputId": "141277f8-2b5d-4f16-8e7e-935ba6d1c199"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['good', 'a tad bit predictable', 'good', \"I think it's a very funny movie\", 'good', 'Good but not great', 'good', 'okay', 'it was so bad', 'good', 'the cast and crew were so good that the whole movie was well worth seeing again', 'good', 'I thought that this movie is really good.', 'it was boring', 'good', 'okay', 'I like it a lot.', 'The movie was very funny and interesting.', 'It is a movie that can help you understand life better', 'The storyline is good.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rlhf_t5_output_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCi5KCpwKe9I",
        "outputId": "026b6ece-ed04-4a59-ee21-3c85ea59b8aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['good',\n",
              " 'a tad bit predictable',\n",
              " 'good',\n",
              " \"I think it's a very funny movie\",\n",
              " 'good',\n",
              " 'Good but not great',\n",
              " 'good',\n",
              " 'okay',\n",
              " 'it was so bad',\n",
              " 'good',\n",
              " 'the cast and crew were so good that the whole movie was well worth seeing again',\n",
              " 'good',\n",
              " 'I thought that this movie is really good.',\n",
              " 'it was boring',\n",
              " 'good',\n",
              " 'okay',\n",
              " 'I like it a lot.',\n",
              " 'The movie was very funny and interesting.',\n",
              " 'It is a movie that can help you understand life better',\n",
              " 'The storyline is good.']"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = metric_fn(rlhf_t5_output_list)\n",
        "metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnAxKyoiJxSW",
        "outputId": "999e1b6d-12d7-4675-a360-02f05a3737d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sentiments': [0.03137087821960449,\n",
              "  0.9029200673103333,\n",
              "  0.03137087821960449,\n",
              "  0.007058396469801664,\n",
              "  0.031370893120765686,\n",
              "  0.780984103679657,\n",
              "  0.03137087821960449,\n",
              "  0.46163320541381836,\n",
              "  0.9929181933403015,\n",
              "  0.03137087821960449,\n",
              "  0.009077776223421097,\n",
              "  0.03137087821960449,\n",
              "  0.015483071096241474,\n",
              "  0.992356538772583,\n",
              "  0.03137087821960449,\n",
              "  0.46163320541381836,\n",
              "  0.00731270294636488,\n",
              "  0.009917120449244976,\n",
              "  0.007533278316259384,\n",
              "  0.019929053261876106]}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "3145728/786295808\n",
        "#trainer中的eval_prompts是用于在训练过程中验证效果的样本\n",
        "#看看用这些提示输入，模型返回的句子是怎么样的 ，理论上输出会根据这些提示输出正面评价的output\n",
        "#Evaluation #11 metrics/sentiments: 0.528 这个值是句子的正面分类得分 由上面metric_fn的定义而来\n",
        "\n",
        "\n",
        "trainer = trlx.train(\n",
        "    \n",
        "    #prompts=prompts,\n",
        "    #eval_prompts=val_prompts,\n",
        "    #reward_fn=metric_fn,\n",
        "    #config=config,\n",
        "    samples=imdb_1k_ds['text'],#imdb[\"text\"][:1000] ,#ds['query'][:200], #imdb[\"text\"][:20000],  #输入文本\n",
        "    #注意这个rewards和scores函数对应 做减法就是scores函数取NEGATIVE的值\n",
        "    #rewards=[ 1.0 - value  for value in ds[\"label\"][:200]],\n",
        "    rewards=[  1.0 -value  for value in imdb_1k_ds[\"label\"]],#[  1.0 -value  for value in imdb[\"label\"][:1000]],\n",
        "    #,  #被标注的label=0 ，1 代表负面或者正面，既然是reward那么越高越高 所以这是引导输出1即正面文字\n",
        "    eval_prompts = [\n",
        "        \"What made this movie so \",\n",
        "        \"This actor of this movie is  \",\n",
        "        \"This plot of the movie is \",\n",
        "        \"I didn't expect this movie was\",\n",
        "    ] * 8,\n",
        "    metric_fn=metric_fn, #这个metric_fn会把上面的samples作为输入\n",
        "    config=config,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLSwOehlMISA",
        "outputId": "877eb637-584c-485f-da75-5f8930982617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[RANK 0] Initializing model: google/flan-t5-large\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imdb 50000 pos:25000 neg 25000\n"
      ],
      "metadata": {
        "id": "5R5qtqm5wP4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' 保存 save\n",
        "Weights&Bais官网说是 \n",
        "trainer.save('/path/to/output/folder/')\n",
        "\n",
        "下面是另外的说法来自https://blog.eleuther.ai/trlx-exploratory-analysis/ \n",
        "\n",
        "trainer.model.base_model.save_pretrained(\"base_model/\")\n",
        "'''"
      ],
      "metadata": {
        "id": "nV7AmT3MW55L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ub94uonbXHXa",
        "outputId": "9b75ec6e-d123-4e9b-ab19-538260ffb4bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/trlx_0403/trlx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save('/content/drive/MyDrive/20230418_flan_t5_large_lora/')"
      ],
      "metadata": {
        "id": "q4M4ZhPfXA98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#这个代码不对\n",
        "trainer.model.base_model.save_pretrained(\"/content/drive/MyDrive/20230418_flan_t5_large_base_model/\")"
      ],
      "metadata": {
        "id": "QUuggieiXi8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#这才是保存基础模型到本地的正确代码\n",
        "trainer.save_pretrained('/content/drive/MyDrive/20230418_flan_t5_large_pretrained_model/')"
      ],
      "metadata": {
        "id": "LpcNI4-6dPvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WF8mOHaDXf3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# output\n",
        "input_str = 'i think the movie is so   '\n",
        "trainer_output = trainer.generate_eval(\n",
        "    **trainer.tokenizer(input_str, return_tensors='pt'))[0]\n",
        "print(trainer.tokenizer.decode(trainer_output))"
      ],
      "metadata": {
        "id": "82MoB8xGVO-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT2 + PPO 例子"
      ],
      "metadata": {
        "id": "kLo364oJGWz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch,os\n",
        "from typing import List\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "import trlx\n",
        "from trlx.data.configs import (\n",
        "    ModelConfig,\n",
        "    OptimizerConfig,\n",
        "    SchedulerConfig,\n",
        "    TokenizerConfig,\n",
        "    TrainConfig,\n",
        "    TRLConfig,\n",
        ")\n",
        "from trlx.models.modeling_ppo import PPOConfig\n",
        "from trlx.models.modeling_ilql import ILQLConfig\n",
        "\n",
        "# try:\n",
        "#     import evaluate\n",
        "# except ImportError:\n",
        "#     raise ImportError(\n",
        "#         \"To run this example, please install the `evaluate` and `nltk` packages\" \"by running `pip install evaluate`\"\n",
        "#     )\n",
        "\n",
        "config = TRLConfig(\n",
        "    train=TrainConfig(\n",
        "        seq_length=256,\n",
        "        epochs=5,\n",
        "        total_steps=10,\n",
        "        batch_size=8,\n",
        "        checkpoint_interval=10,\n",
        "        eval_interval=2,\n",
        "        pipeline=\"PromptPipeline\",\n",
        "        trainer='AccelerateILQLTrainer',#\"AcceleratePPOTrainer\",\n",
        "        tracker=None, #default is wandb\n",
        "    ),\n",
        "    model=ModelConfig(\n",
        "        model_path=\"gpt2\",\n",
        "        model_arch_type=\"causul\",\n",
        "        num_layers_unfrozen=2,\n",
        "    ),\n",
        "    tokenizer=TokenizerConfig(\n",
        "        tokenizer_path=\"gpt2\",\n",
        "        truncation_side=\"right\",\n",
        "    ),\n",
        "    optimizer=OptimizerConfig(\n",
        "        name=\"adamw\",\n",
        "        kwargs={\n",
        "            \"lr\": 1.0e-5,\n",
        "            \"betas\": [0.9, 0.999],\n",
        "            \"eps\": 1.0e-8,\n",
        "            \"weight_decay\": 1.0e-6,\n",
        "        },\n",
        "    ),\n",
        "    scheduler=SchedulerConfig(\n",
        "        name=\"cosine_annealing\",\n",
        "        kwargs={\n",
        "            \"T_max\": 10000,\n",
        "            \"eta_min\": 1.0e-6,\n",
        "        },\n",
        "    ),\n",
        "\n",
        "    # method=PPOConfig(\n",
        "    #     name=\"PPOConfig\",\n",
        "    #     num_rollouts=128,\n",
        "    #     chunk_size=24,\n",
        "    #     ppo_epochs=4,\n",
        "    #     init_kl_coef=0.05,\n",
        "    #     target=6,\n",
        "    #     horizon=10000,\n",
        "    #     gamma=0.99,\n",
        "    #     lam=0.95,\n",
        "    #     cliprange=0.2,\n",
        "    #     cliprange_value=0.2,\n",
        "    #     vf_coef=1.0,\n",
        "    #     scale_reward=None,\n",
        "    #     ref_mean=None,\n",
        "    #     ref_std=None,\n",
        "    #     cliprange_reward=10,\n",
        "    #     gen_kwargs={\n",
        "    #         \"max_new_tokens\": 100,\n",
        "    #     },\n",
        "    #     gen_experience_kwargs={\n",
        "    #         \"max_new_tokens\": 60,\n",
        "    #         \"do_sample\": True,\n",
        "    #         \"temperature\": 1.0,\n",
        "    #         \"top_k\": 5, #50,\n",
        "    #         \"top_p\": 0.95,\n",
        "    #     },\n",
        "    # ),\n",
        "\n",
        "    method =ILQLConfig(\n",
        "        \n",
        "        name =\"ILQLConfig\",\n",
        "        tau =  0.7,\n",
        "        gamma = 0.99,\n",
        "        cql_scale = 0.1,\n",
        "        awac_scale =  1,\n",
        "        alpha =  0.001,\n",
        "        beta =  0,\n",
        "        steps_for_target_q_sync =  5,\n",
        "        two_qs = True,\n",
        "        gen_kwargs={\n",
        "            \n",
        "            \"max_new_tokens\": 56,\n",
        "            \"top_k\": 20,\n",
        "            \"beta\": 1,\n",
        "            \"temperature\": 1.0\n",
        "        }\n",
        "    ),\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "bcUqawc6GaXu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "3f2d4c14-6240-4cdc-f1fc-6ef4222f3bf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[91m╭──────────────────────────────────────────────────────────────────────────────────────────────────╮\u001b[0m\n",
              "\u001b[91m│\u001b[0m         \u001b[33mepochs\u001b[0m=,                                                                                 \u001b[91m│\u001b[0m\n",
              "\u001b[91m│\u001b[0m                \u001b[1;91m▲\u001b[0m                                                                                 \u001b[91m│\u001b[0m\n",
              "\u001b[91m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mSyntaxError: \u001b[0minvalid syntax\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000\">╭──────────────────────────────────────────────────────────────────────────────────────────────────╮</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>         <span style=\"color: #808000; text-decoration-color: #808000\">epochs</span>=,                                                                                 <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">▲</span>                                                                                 <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">SyntaxError: </span>invalid syntax\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#这个ppo_config.yml是哪儿来的\n",
        "#default_config = yaml.safe_load(open(\"configs/ppo_config.yml\"))"
      ],
      "metadata": {
        "id": "W1qx5oV3JoDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IPnoxhJyKQ7k",
        "outputId": "6cdba6ec-bdfb-4bc9-da9b-5b6497065a50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/trlx_0403/trlx'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls /content/drive/MyDrive/trlx_0403/trlx/configs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzgKAAOHKUL7",
        "outputId": "61229b35-5cfd-40d3-9ce6-d8cec0a07c15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34maccelerate\u001b[0m/  \u001b[01;34mnemo_configs\u001b[0m/  \u001b[01;34msweeps\u001b[0m/  test_config.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(default_config)"
      ],
      "metadata": {
        "id": "tI3fePnrJ3WP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_negative_score(scores):\n",
        "    \"Extract value associated with a negative sentiment from pipeline's output\"\n",
        "    return dict(map(lambda x: tuple(x.values()), scores))[\"NEGATIVE\"]\n",
        "\n",
        "#default_config = yaml.safe_load(open(\"configs/ppo_config.yml\"))\n",
        "\n",
        "default_config = config\n",
        "\n",
        "def main(hparams={}):\n",
        "    config = TRLConfig.update(default_config, hparams)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        device = int(os.environ.get(\"LOCAL_RANK\", 0))\n",
        "    else:\n",
        "        device = -1\n",
        "\n",
        "    sentiment_fn = pipeline(\n",
        "        \"sentiment-analysis\",\n",
        "        \"lvwerra/distilbert-imdb\",\n",
        "        top_k=2,\n",
        "        truncation=True,\n",
        "        batch_size=256,\n",
        "        device=device,\n",
        "    )\n",
        "\n",
        "    def reward_fn(samples: List[str], **kwargs) -> List[float]:\n",
        "        sentiments = list(map(get_negative_score, sentiment_fn(samples)))\n",
        "        return sentiments\n",
        "\n",
        "    # Take few words off of movies reviews as prompts\n",
        "    imdb = load_dataset(\"imdb\", split=\"train+test\")\n",
        "    prompts = [\" \".join(review.split()[:4]) for review in imdb[\"text\"]]\n",
        "    print('see what the prompts look like:')\n",
        "    print(prompts[:5])\n",
        "\n",
        "    return trlx.train(\n",
        "        #reward_fn=reward_fn,\n",
        "        #prompts=prompts,\n",
        "        metric_fn = reward_fn ,\n",
        "        rewards = imdb['label'],\n",
        "        samples = imdb['text'] ,\n",
        "        eval_prompts=[#\"It's hard to believe the sequel to Avatar has actually come out. After 13 years and what feels like half-a-dozen delays\",\n",
        "               #\"This film seems to be boring.\" ,\n",
        "               #\"Do you recommend the movie ?\",\n",
        "               #\"This movie makes me feel like\"\n",
        "               \"What made this movie so \",\n",
        "               \"This movie was just like \",\n",
        "               \"This movie is not so \",\n",
        "               \"I didn't expect this movie was\",\n",
        "                      ] * 8,\n",
        "        config=config,\n",
        "    )"
      ],
      "metadata": {
        "id": "gJ7jOIjoGpBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer= main()"
      ],
      "metadata": {
        "id": "XXCOCtZjGVSB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "690949ac-cba3-4760-c1b1-dace15640244"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset imdb (/root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n",
            "[RANK 0] Initializing model: gpt2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "see what the prompts look like:\n",
            "['I rented I AM', '\"I Am Curious: Yellow\"', 'If only to avoid', 'This film was probably', 'Oh, brother...after hearing about']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[RANK 0] Collecting rollouts\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1169 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# output\n",
        "input_str = 'i think the movie is so'\n",
        "trainer_output = trainer.generate_eval(\n",
        "    **trainer.tokenizer(input_str, return_tensors='pt'))[0]\n",
        "print(trainer.tokenizer.decode(trainer_output))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3vgpnRWaLqr",
        "outputId": "90ed2852-356f-465e-f733-61ec5b014726"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i think the movie is so much more than just a movie. It's a movie about a man who's lost his mind and his life. It's about a man who's lost his mind and his life.\n",
            "\n",
            "It's about a man who's lost his mind and his life. It's about a man who's lost his mind and his life.\n",
            "\n",
            "It's about a man who's lost his mind and his life. It's about a man who's lost his mind and his life.\n",
            "\n",
            "It\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.model.base_model.save_pretrained(\"/content/drive/MyDrive/ppo_trained_base_model/\")"
      ],
      "metadata": {
        "id": "G9ShYQN8dJCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 加载训练完的模型"
      ],
      "metadata": {
        "id": "ZXy0YhPDh7W_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline,AutoTokenizer,AutoModelForCausalLM"
      ],
      "metadata": {
        "id": "tcGMSpZjiLAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saved_model_path = \"/content/drive/MyDrive/ppo_trained_base_model/\"\n",
        "rlhf_model = AutoModelForCausalLM.from_pretrained(saved_model_path)"
      ],
      "metadata": {
        "id": "q2wAStaDgrf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2Model\n",
        "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
        "#model = GPT2Model.from_pretrained(saved_model_path)\n",
        "text = \"this movie is such \"\n",
        "input_ids = tokenizer(text, return_tensors=\"pt\", truncation=True).input_ids\n",
        "outputs = rlhf_model.generate(input_ids, max_new_tokens=200, do_sample=True,top_p=0.7,temperature=0.1)\n",
        "output_text = tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0]\n",
        "print(output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRpA_bsehCC7",
        "outputId": "fe126b3a-65bb-4438-ff18-c81d9f1fbc01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this movie is such  a huge hit that I actually didn't even bother to watch it. \n",
            "I actually didn't even bother to watch it. \n",
            "I actually didn't even bother to watch it. \n",
            "I actually didn't even bother to watch it. \n",
            "I actually didn't even bother to watch it. \n",
            "I actually didn't even bother to watch it. \n",
            "I actually didn't even bother to watch it. \n",
            "I actually didn't even bother to watch it. \n",
            "I actually didn't even bother to watch it. \n",
            "I actually didn't evenprotein.com \n",
            "I actually didn't even bother to watch it.\n",
            "I actually didn't even bother to watch it.\n",
            "I actually didn't even bother to watch it.\n",
            "I actually didn't even bother to watch it.\n",
            "I actually didn't even bother to watch it.\n",
            "I actually didn't even bother to watch it.\n",
            "I actually didn't even bother to watch it.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2Model,GPT2LMHeadModel\n",
        "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "text = \"this movie is such\"\n",
        "input_ids = tokenizer(text, return_tensors=\"pt\", truncation=True).input_ids\n",
        "outputs = model.generate(input_ids, max_new_tokens=200, do_sample=True,top_p=0.7,temperature=0.1)\n",
        "output_text = tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0]\n",
        "print(output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyEMCtkLohfC",
        "outputId": "9ff03983-6a98-4cc2-a844-ceebd5b07893"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this movie is such a great movie, I'm going to watch it again. I'm going to watch it again. I'm going to watch it again. I'm going to watch it again. I'm going to watch it again. I'm going to watch it again. I'm going to watch it again. I'm going to watch it again. I'm going to watch it again. I'm going to watch it again. I'm going to watch it again. I'm going to watch it again. I'm going to watch it again. I'm going to watch it again. I'm going to watch it again. I'm going to watch it again. I'm going to watch it again. I'm going to watch it again. I'm going to watch it again. I'm going to watch it again. I'm going towing it again. I'm going towing it again. I'm going towing it again. I'm going towing it again. I'm going to\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEXZeHggjEb8",
        "outputId": "558d4cae-fe69-45b5-956b-3c666591bc08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The movie is so much more than a movie. It's a movie about the people who live in the world. It's about the people who live in the world. It's about the people who live in the world. It's about the people who live in the world. It's about the people who live in the world. It's about the people who live in the world. It's about the people who live in the world. It's about the people who live in the world. It's about the people who live in the world. It's about the people who live in the world. It's about the people who live in the world. It's about the people who live in the world. It's about the people who live in the world. It's about the people who live in the world. It's about the people who live in the world. It's about the people who live in the world. It's about the people who live in the world. It's about the people\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -Uqq git+https://github.com/neelnanda-io/TransformerLens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 962
        },
        "id": "AQLNtlTibUcr",
        "outputId": "677f834d-512b-4f33-a363-127018ca2223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92m<cell line: 1>\u001b[0m:\u001b[94m1\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/IPython/core/\u001b[0m\u001b[1;33minteractiveshell.py\u001b[0m:\u001b[94m2418\u001b[0m in \u001b[92mrun_line_magic\u001b[0m   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m2415 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mgetattr\u001b[0m(fn, \u001b[33m\"\u001b[0m\u001b[33mneeds_local_scope\u001b[0m\u001b[33m\"\u001b[0m, \u001b[94mFalse\u001b[0m):                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m2416 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mkwargs[\u001b[33m'\u001b[0m\u001b[33mlocal_ns\u001b[0m\u001b[33m'\u001b[0m] = \u001b[96mself\u001b[0m.get_local_scope(stack_depth)                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m2417 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mself\u001b[0m.builtin_trap:                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2418 \u001b[2m│   │   │   │   \u001b[0mresult = fn(*args, **kwargs)                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m2419 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m result                                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m2420 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m2421 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mget_local_scope\u001b[0m(\u001b[96mself\u001b[0m, stack_depth):                                               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/google/colab/\u001b[0m\u001b[1;33m_installation_commands.py\u001b[0m:\u001b[94m49\u001b[0m in \u001b[92m_pip_magic\u001b[0m   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m46 \u001b[0m\u001b[2m  \u001b[0m\u001b[2m# Use bare \"pip install\" rather than \"python -m pip install\".\u001b[0m                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m47 \u001b[0m\u001b[2m  \u001b[0m\u001b[2m# Colab is set up such that pip does the right thing, and pip install\u001b[0m                     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m48 \u001b[0m\u001b[2m  \u001b[0m\u001b[2m# will properly trigger the pip install warning.\u001b[0m                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m49 \u001b[2m  \u001b[0m\u001b[94mreturn\u001b[0m ip.system(\u001b[33m'\u001b[0m\u001b[33mpip \u001b[0m\u001b[33m{}\u001b[0m\u001b[33m'\u001b[0m.format(line))                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m50 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m51 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m52 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_register_magics\u001b[0m(ip):                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/google/colab/\u001b[0m\u001b[1;33m_shell.py\u001b[0m:\u001b[94m99\u001b[0m in \u001b[92msystem\u001b[0m                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 96 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m pip_warn:                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 97 \u001b[0m\u001b[2m│     \u001b[0mkwargs.update({\u001b[33m'\u001b[0m\u001b[33malso_return_output\u001b[0m\u001b[33m'\u001b[0m: \u001b[94mTrue\u001b[0m})                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 98 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 99 \u001b[2m│   \u001b[0moutput = _system_commands._system_compat(\u001b[96mself\u001b[0m, *args, **kwargs)  \u001b[2m# pylint:disable=pr\u001b[0m   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m100 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m101 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m pip_warn:                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m102 \u001b[0m\u001b[2m│     \u001b[0m_pip.print_previous_import_warning(output)                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/google/colab/\u001b[0m\u001b[1;33m_system_commands.py\u001b[0m:\u001b[94m453\u001b[0m in \u001b[92m_system_compat\u001b[0m    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m450 \u001b[0m\u001b[2m  \u001b[0m\u001b[2m# We set a higher depth than the IPython system command since a shell object\u001b[0m             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m451 \u001b[0m\u001b[2m  \u001b[0m\u001b[2m# is expected to call this function, thus adding one level of nesting to the\u001b[0m             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m452 \u001b[0m\u001b[2m  \u001b[0m\u001b[2m# stack.\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m453 \u001b[2m  \u001b[0mresult = _run_command(                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m454 \u001b[0m\u001b[2m│     \u001b[0mshell.var_expand(cmd, depth=\u001b[94m2\u001b[0m), clear_streamed_output=\u001b[94mFalse\u001b[0m                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m455 \u001b[0m\u001b[2m  \u001b[0m)                                                                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m456 \u001b[0m\u001b[2m  \u001b[0mshell.user_ns[\u001b[33m'\u001b[0m\u001b[33m_exit_code\u001b[0m\u001b[33m'\u001b[0m] = result.returncode                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/google/colab/\u001b[0m\u001b[1;33m_system_commands.py\u001b[0m:\u001b[94m167\u001b[0m in \u001b[92m_run_command\u001b[0m      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m164 \u001b[0m\u001b[2;90m  \u001b[0m\u001b[33m\"\"\"Calls the shell command, forwarding input received on the stdin_socket.\"\"\"\u001b[0m            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m165 \u001b[0m\u001b[2m  \u001b[0mlocale_encoding = locale.getpreferredencoding()                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m166 \u001b[0m\u001b[2m  \u001b[0m\u001b[94mif\u001b[0m locale_encoding != _ENCODING:                                                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m167 \u001b[2m│   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mNotImplementedError\u001b[0m(                                                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m168 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[33m'\u001b[0m\u001b[33mA UTF-8 locale is required. Got \u001b[0m\u001b[33m{}\u001b[0m\u001b[33m'\u001b[0m.format(locale_encoding)                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m169 \u001b[0m\u001b[2m│   \u001b[0m)                                                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m170 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mNotImplementedError: \u001b[0mA UTF-\u001b[1;36m8\u001b[0m locale is required. Got ANSI_X3.\u001b[1;36m4\u001b[0m-\u001b[1;36m1968\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 1&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.9/dist-packages/IPython/core/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">interactiveshell.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2418</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">run_line_magic</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2415 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">getattr</span>(fn, <span style=\"color: #808000; text-decoration-color: #808000\">\"needs_local_scope\"</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>):                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2416 │   │   │   │   </span>kwargs[<span style=\"color: #808000; text-decoration-color: #808000\">'local_ns'</span>] = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.get_local_scope(stack_depth)                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2417 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.builtin_trap:                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2418 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>result = fn(*args, **kwargs)                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2419 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> result                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2420 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2421 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_local_scope</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, stack_depth):                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.9/dist-packages/google/colab/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_installation_commands.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">49</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_pip_magic</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">46   # Use bare \"pip install\" rather than \"python -m pip install\".</span>                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">47   # Colab is set up such that pip does the right thing, and pip install</span>                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">48   # will properly trigger the pip install warning.</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>49 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> ip.system(<span style=\"color: #808000; text-decoration-color: #808000\">'pip {}'</span>.format(line))                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">50 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">51 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">52 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_register_magics</span>(ip):                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.9/dist-packages/google/colab/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_shell.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">99</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">system</span>                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 96 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> pip_warn:                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 97 │     </span>kwargs.update({<span style=\"color: #808000; text-decoration-color: #808000\">'also_return_output'</span>: <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>})                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 98 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 99 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>output = _system_commands._system_compat(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, *args, **kwargs)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># pylint:disable=pr</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">100 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">101 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> pip_warn:                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">102 │     </span>_pip.print_previous_import_warning(output)                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.9/dist-packages/google/colab/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_system_commands.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">453</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_system_compat</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">450   # We set a higher depth than the IPython system command since a shell object</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">451   # is expected to call this function, thus adding one level of nesting to the</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">452   # stack.</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>453 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span>result = _run_command(                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">454 │     </span>shell.var_expand(cmd, depth=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>), clear_streamed_output=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">455   </span>)                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">456   </span>shell.user_ns[<span style=\"color: #808000; text-decoration-color: #808000\">'_exit_code'</span>] = result.returncode                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.9/dist-packages/google/colab/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_system_commands.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">167</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_run_command</span>      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">164 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">  </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"Calls the shell command, forwarding input received on the stdin_socket.\"\"\"</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">165   </span>locale_encoding = locale.getpreferredencoding()                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">166   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> locale_encoding != _ENCODING:                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>167 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">NotImplementedError</span>(                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">168 │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">'A UTF-8 locale is required. Got {}'</span>.format(locale_encoding)                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">169 │   </span>)                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">170 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NotImplementedError: </span>A UTF-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> locale is required. Got ANSI_X3.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1968</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer"
      ],
      "metadata": {
        "id": "Kpb-WhxQbko8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9tI-yDaBaXih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3L3JcQ4n44mT"
      },
      "outputs": [],
      "source": [
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "import trlx\n",
        "from trlx.data.configs import (\n",
        "    ModelConfig,\n",
        "    OptimizerConfig,\n",
        "    SchedulerConfig,\n",
        "    TokenizerConfig,\n",
        "    TrainConfig,\n",
        "    TRLConfig,\n",
        ")\n",
        "from trlx.models.modeling_ppo import PPOConfig\n",
        "\n",
        "try:\n",
        "    import evaluate\n",
        "except ImportError:\n",
        "    raise ImportError(\n",
        "        \"To run this example, please install the `evaluate` and `nltk` packages\" \"by running `pip install evaluate`\"\n",
        "    )\n",
        "\n",
        "config = TRLConfig(\n",
        "    train=TrainConfig(\n",
        "        seq_length=612,\n",
        "        epochs=100,\n",
        "        total_steps=1000,\n",
        "        batch_size=1,\n",
        "        checkpoint_interval=1000,\n",
        "        eval_interval=10,\n",
        "        pipeline=\"PromptPipeline\",\n",
        "        trainer=\"AcceleratePPOTrainer\",\n",
        "        tracker=None, #default is wandb\n",
        "    ),\n",
        "    model=ModelConfig(\n",
        "        model_path=\"google/flan-t5-small\",\n",
        "        model_arch_type=\"seq2seq\",\n",
        "        num_layers_unfrozen=2,\n",
        "    ),\n",
        "    tokenizer=TokenizerConfig(\n",
        "        tokenizer_path=\"google/flan-t5-small\",\n",
        "        truncation_side=\"right\",\n",
        "    ),\n",
        "    optimizer=OptimizerConfig(\n",
        "        name=\"adamw\",\n",
        "        kwargs={\n",
        "            \"lr\": 1.0e-5,\n",
        "            \"betas\": [0.9, 0.999],\n",
        "            \"eps\": 1.0e-8,\n",
        "            \"weight_decay\": 1.0e-6,\n",
        "        },\n",
        "    ),\n",
        "    scheduler=SchedulerConfig(\n",
        "        name=\"cosine_annealing\",\n",
        "        kwargs={\n",
        "            \"T_max\": 10000,\n",
        "            \"eta_min\": 1.0e-6,\n",
        "        },\n",
        "    ),\n",
        "    method=PPOConfig(\n",
        "        name=\"PPOConfig\",\n",
        "        num_rollouts=512,\n",
        "        chunk_size=12,\n",
        "        ppo_epochs=4,\n",
        "        init_kl_coef=0.05,\n",
        "        target=6,\n",
        "        horizon=10000,\n",
        "        gamma=0.99,\n",
        "        lam=0.95,\n",
        "        cliprange=0.2,\n",
        "        cliprange_value=0.2,\n",
        "        vf_coef=1.0,\n",
        "        scale_reward=None,\n",
        "        ref_mean=None,\n",
        "        ref_std=None,\n",
        "        cliprange_reward=10,\n",
        "        gen_kwargs={\n",
        "            \"max_new_tokens\": 100,\n",
        "        },\n",
        "        gen_experience_kwargs={\n",
        "            \"max_new_tokens\": 100,\n",
        "            \"do_sample\": True,\n",
        "            \"temperature\": 1.0,\n",
        "            \"top_k\": 50,\n",
        "            \"top_p\": 0.95,\n",
        "        },\n",
        "    ),\n",
        ")\n",
        "\n",
        "\n",
        "meteor = evaluate.load(\"meteor\")  # use meteor as the reward function\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "6dhoVllICI_2",
        "outputId": "73fafbca-e261-46ff-ef5d-c0e028563ac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92m<cell line: 18>\u001b[0m:\u001b[94m19\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mModuleNotFoundError: \u001b[0mNo module named \u001b[32m'evaluate'\u001b[0m\n",
              "\n",
              "\u001b[3mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
              "\n",
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/IPython/core/\u001b[0m\u001b[1;33minteractiveshell.py\u001b[0m:\u001b[94m3553\u001b[0m in \u001b[92mrun_code\u001b[0m         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m3550 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94melif\u001b[0m async_ :                                                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m3551 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mawait\u001b[0m \u001b[96meval\u001b[0m(code_obj, \u001b[96mself\u001b[0m.user_global_ns, \u001b[96mself\u001b[0m.user_ns)               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m3552 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3553 \u001b[2m│   │   │   │   │   \u001b[0mexec(code_obj, \u001b[96mself\u001b[0m.user_global_ns, \u001b[96mself\u001b[0m.user_ns)                     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m3554 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mfinally\u001b[0m:                                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m3555 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# Reset our crash handler in place\u001b[0m                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m3556 \u001b[0m\u001b[2m│   │   │   │   \u001b[0msys.excepthook = old_excepthook                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92m<cell line: 18>\u001b[0m:\u001b[94m21\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mImportError: \u001b[0mTo run this example, please install the `evaluate` and `nltk` packagesby running `pip install \n",
              "evaluate`\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 18&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">19</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ModuleNotFoundError: </span>No module named <span style=\"color: #008000; text-decoration-color: #008000\">'evaluate'</span>\n",
              "\n",
              "<span style=\"font-style: italic\">During handling of the above exception, another exception occurred:</span>\n",
              "\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.9/dist-packages/IPython/core/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">interactiveshell.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3553</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">run_code</span>         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3550 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> async_ :                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3551 │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">await</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">eval</span>(code_obj, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.user_global_ns, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.user_ns)               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3552 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3553 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>exec(code_obj, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.user_global_ns, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.user_ns)                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3554 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">finally</span>:                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3555 │   │   │   │   # Reset our crash handler in place</span>                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3556 │   │   │   │   </span>sys.excepthook = old_excepthook                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 18&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">21</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ImportError: </span>To run this example, please install the `evaluate` and `nltk` packagesby running `pip install \n",
              "evaluate`\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start =1"
      ],
      "metadata": {
        "id": "pb4_AyxxCS5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if start ==1:\n",
        "\n",
        "    def reward_fn(samples: List[str], prompts: List[str], outputs: List[str]):\n",
        "        original_summaries = [prompt_label[prompt.strip()] for prompt in prompts]\n",
        "        scores = [\n",
        "            meteor.compute(predictions=[output.strip()], references=[original])[\"meteor\"]\n",
        "            for (original, output) in zip(original_summaries, outputs)\n",
        "        ]\n",
        "        return scores\n",
        "\n",
        "    dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\", cache_dir=\"data\")\n",
        "\n",
        "    # take 20,000 samples from the training set as prompts for training\n",
        "    prompts = dataset[\"train\"][\"article\"][0:200]\n",
        "    summaries = dataset[\"train\"][\"highlights\"][0:200]\n",
        "    prompts = [\"Summarize: \" + prompt for prompt in prompts]\n",
        "\n",
        "    # take 1,000 samples from the validation set as prompts for evaluation\n",
        "    val_prompts = [\"Summarize: \" + prompt for prompt in dataset[\"validation\"][\"article\"][0:10]]\n",
        "    val_summaries = dataset[\"validation\"][\"highlights\"][0:10]\n",
        "\n",
        "    # make dictionary of prompts and labels to use for reward function\n",
        "    tokenizer = AutoTokenizer.from_pretrained(config.model.model_path)\n",
        "    tokenizer.padding_side = \"left\"\n",
        "    tokenizer.truncation_side = \"right\"\n",
        "    tokenizer.sep_token = \"<sep>\"\n",
        "    prompt_label = {}\n",
        "    max_length = config.train.seq_length - config.method.gen_kwargs[\"max_new_tokens\"]\n",
        "\n",
        "    for i in tqdm(range(len(prompts))):\n",
        "        key = tokenizer.decode(\n",
        "            tokenizer(prompts[i], truncation=True, max_length=max_length, add_special_tokens=False)[\"input_ids\"],\n",
        "            skip_special_tokens=True,\n",
        "        )  # get prompt like trlx's prompt\n",
        "        prompt_label[key.strip()] = summaries[i]\n",
        "\n",
        "    for i in tqdm(range(len(val_prompts))):\n",
        "        key = tokenizer.decode(\n",
        "            tokenizer(val_prompts[i], truncation=True, max_length=max_length, add_special_tokens=False)[\"input_ids\"],\n",
        "            skip_special_tokens=True,\n",
        "        )  # get prompt like trlx's prompt\n",
        "        prompt_label[key.strip()] = val_summaries[i]\n",
        "\n",
        "    trlx.train(\n",
        "        reward_fn=reward_fn,\n",
        "        prompts=prompts,\n",
        "        eval_prompts=val_prompts,\n",
        "        config=config,\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "B8K41YOICRad",
        "outputId": "9cb8992b-20d6-4308-ef70-e231fc07dacf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92m<cell line: 1>\u001b[0m:\u001b[94m1\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'start'\u001b[0m is not defined\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 1&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'start'</span> is not defined\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "trlx",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "ff6c2b5200ddef8677aa61880964789bda1a252a745e754869943e5efda88bbf"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4b57316c3f524bc9b11c26e62b7e9436": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d6e47d5dac75448e897936d58e82989b",
              "IPY_MODEL_37c49557f6ee4d13bd5d5a13c7bed603",
              "IPY_MODEL_5981f16e2f08400bb43f60d3a546f08a"
            ],
            "layout": "IPY_MODEL_34e8fe507e204ccab37e422a0b8b83d2"
          }
        },
        "d6e47d5dac75448e897936d58e82989b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19d615fa592045fbb0c34bf785165a9b",
            "placeholder": "​",
            "style": "IPY_MODEL_7155fea914614aa8a731fef4306abbeb",
            "value": "Downloading data files: 100%"
          }
        },
        "37c49557f6ee4d13bd5d5a13c7bed603": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_598f0a69ac8f4bdaac8fcb3a8957a0cb",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3b5cfbd7f6624b609d82187586affd94",
            "value": 1
          }
        },
        "5981f16e2f08400bb43f60d3a546f08a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cde93d9d95cb42d2a0abde616e2f6809",
            "placeholder": "​",
            "style": "IPY_MODEL_c02269065b9d4308a137b3cc5f45a2f9",
            "value": " 1/1 [00:00&lt;00:00, 48.26it/s]"
          }
        },
        "34e8fe507e204ccab37e422a0b8b83d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19d615fa592045fbb0c34bf785165a9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7155fea914614aa8a731fef4306abbeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "598f0a69ac8f4bdaac8fcb3a8957a0cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b5cfbd7f6624b609d82187586affd94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cde93d9d95cb42d2a0abde616e2f6809": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c02269065b9d4308a137b3cc5f45a2f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3b1177cc33a48908119c0a6679e5e83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a502d7021f874d90bd21f204452e239a",
              "IPY_MODEL_3e90fd39786b483c98fd7b72380fc4ef",
              "IPY_MODEL_7a6cb42745fd4985b9e76c8539de7114"
            ],
            "layout": "IPY_MODEL_7797b71dc7a9495c8b0f89d55a7088d1"
          }
        },
        "a502d7021f874d90bd21f204452e239a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a96a3bcfd0234687898b4410cdecd60b",
            "placeholder": "​",
            "style": "IPY_MODEL_63d992abcc65415aa574afeeccfffd85",
            "value": "Extracting data files: 100%"
          }
        },
        "3e90fd39786b483c98fd7b72380fc4ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f89cc0bf8ee45dfbe30ae8c4ee45ed1",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1a2393fb5a6d44e59d7c9c0e338d5a40",
            "value": 1
          }
        },
        "7a6cb42745fd4985b9e76c8539de7114": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9232b0b00264fee913f6b72e09e795f",
            "placeholder": "​",
            "style": "IPY_MODEL_6007c6a18ea449d4a2bff9018aab8e65",
            "value": " 1/1 [00:00&lt;00:00, 39.32it/s]"
          }
        },
        "7797b71dc7a9495c8b0f89d55a7088d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a96a3bcfd0234687898b4410cdecd60b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63d992abcc65415aa574afeeccfffd85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f89cc0bf8ee45dfbe30ae8c4ee45ed1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a2393fb5a6d44e59d7c9c0e338d5a40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d9232b0b00264fee913f6b72e09e795f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6007c6a18ea449d4a2bff9018aab8e65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "666c3a69fd9f4cc480745717a2413da9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ad1b4dbdefa4e79b6e5e46d7883c83b",
              "IPY_MODEL_e37a77e30f1b4e43ac23b2861af99580",
              "IPY_MODEL_1e20a124c925428ca1ecde672f7f0573"
            ],
            "layout": "IPY_MODEL_edd95c00a18144a19a16df1ee74284c1"
          }
        },
        "6ad1b4dbdefa4e79b6e5e46d7883c83b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7a8dcb86d534c6dbca77d8bafd55061",
            "placeholder": "​",
            "style": "IPY_MODEL_bee96bf3f25749bebee2b73a9511624e",
            "value": "Generating train split: "
          }
        },
        "e37a77e30f1b4e43ac23b2861af99580": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a1201e1d3a94955a8125df54d7b2e68",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e6b230deff0042adbb5e78dffb74b1bc",
            "value": 1
          }
        },
        "1e20a124c925428ca1ecde672f7f0573": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c34bdc0accb0427b8c1a224936a6d8d9",
            "placeholder": "​",
            "style": "IPY_MODEL_f72c6c8fe376407382176e4e49a137b1",
            "value": " 0/0 [00:00&lt;?, ? examples/s]"
          }
        },
        "edd95c00a18144a19a16df1ee74284c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "a7a8dcb86d534c6dbca77d8bafd55061": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bee96bf3f25749bebee2b73a9511624e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a1201e1d3a94955a8125df54d7b2e68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "e6b230deff0042adbb5e78dffb74b1bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c34bdc0accb0427b8c1a224936a6d8d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f72c6c8fe376407382176e4e49a137b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f7cd6e3a0014c188699afca6379d56f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c253e1af3349494b8b2d7dff7895ff12",
              "IPY_MODEL_32613f45e07f444dbc18fb5e1e7ef706",
              "IPY_MODEL_3c0a8755a136461ebdd1089cd52fd78c"
            ],
            "layout": "IPY_MODEL_912fc9be8de84e5ea3dee6290a949833"
          }
        },
        "c253e1af3349494b8b2d7dff7895ff12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_788f74fae6aa47feb80aba504fd9ca00",
            "placeholder": "​",
            "style": "IPY_MODEL_e90b8b434c7e4d8d8f2c1f1d5300b4c4",
            "value": "100%"
          }
        },
        "32613f45e07f444dbc18fb5e1e7ef706": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e7feab0147748b49bc2e03b3cace377",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f786bb2548934b7fa71026497e692b58",
            "value": 1
          }
        },
        "3c0a8755a136461ebdd1089cd52fd78c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3b0c193bb8b4b9fa8be2ce7d4491cfb",
            "placeholder": "​",
            "style": "IPY_MODEL_0a469bb7383a453f9432e145ae241433",
            "value": " 1/1 [00:00&lt;00:00, 51.45it/s]"
          }
        },
        "912fc9be8de84e5ea3dee6290a949833": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "788f74fae6aa47feb80aba504fd9ca00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e90b8b434c7e4d8d8f2c1f1d5300b4c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e7feab0147748b49bc2e03b3cace377": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f786bb2548934b7fa71026497e692b58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d3b0c193bb8b4b9fa8be2ce7d4491cfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a469bb7383a453f9432e145ae241433": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c1175f25f4f40d0a66659a69df21dbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_700737966620420da9ae2909da2bbbce",
              "IPY_MODEL_c27f83328b0b459a902c337ea747adcd",
              "IPY_MODEL_d1b8ad7bc16c4edd99ce7232e1c0c626"
            ],
            "layout": "IPY_MODEL_7d8c41ce2da24c4b921c1cebdd935fac"
          }
        },
        "700737966620420da9ae2909da2bbbce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_315582a357814c39b720c62100c5ef2a",
            "placeholder": "​",
            "style": "IPY_MODEL_5da2e45ceee4417eaa1cd2b953de6b58",
            "value": "Downloading data files: 100%"
          }
        },
        "c27f83328b0b459a902c337ea747adcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5e5ec5ac76e4ec39a10aa3df96cdf9c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22e3a233cdc847e382a9c26a3df23d48",
            "value": 1
          }
        },
        "d1b8ad7bc16c4edd99ce7232e1c0c626": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_955fcb214f164ac0a3bb9ebac0db3119",
            "placeholder": "​",
            "style": "IPY_MODEL_4644b13ae1e241e092d85a92ae7b20ca",
            "value": " 1/1 [00:00&lt;00:00, 39.32it/s]"
          }
        },
        "7d8c41ce2da24c4b921c1cebdd935fac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "315582a357814c39b720c62100c5ef2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5da2e45ceee4417eaa1cd2b953de6b58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5e5ec5ac76e4ec39a10aa3df96cdf9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22e3a233cdc847e382a9c26a3df23d48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "955fcb214f164ac0a3bb9ebac0db3119": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4644b13ae1e241e092d85a92ae7b20ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d11ebcd9ea934d858774e4b8f75e1d5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e524c38d7adb4a53aae86b968ebf8fbe",
              "IPY_MODEL_6920d631feb1423fb34c4e19fd338ebc",
              "IPY_MODEL_a02b6ab9baef4145ab8d1c0e05d4c739"
            ],
            "layout": "IPY_MODEL_dca5ae6677b54571bc32f96f44167975"
          }
        },
        "e524c38d7adb4a53aae86b968ebf8fbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_329410de24df47d09a94601c912a4a96",
            "placeholder": "​",
            "style": "IPY_MODEL_34efcd63e62140ceb909a515a170db38",
            "value": "Extracting data files: 100%"
          }
        },
        "6920d631feb1423fb34c4e19fd338ebc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdc91fb0aac8467383631a43280592c3",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af7214134dce4992a939fac5be347115",
            "value": 1
          }
        },
        "a02b6ab9baef4145ab8d1c0e05d4c739": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_152f647052ee46e3bc5bc0c1b61690ee",
            "placeholder": "​",
            "style": "IPY_MODEL_66f86cb7a1b44dd08d2d25b7ad239f36",
            "value": " 1/1 [00:00&lt;00:00, 39.67it/s]"
          }
        },
        "dca5ae6677b54571bc32f96f44167975": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "329410de24df47d09a94601c912a4a96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34efcd63e62140ceb909a515a170db38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cdc91fb0aac8467383631a43280592c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af7214134dce4992a939fac5be347115": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "152f647052ee46e3bc5bc0c1b61690ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66f86cb7a1b44dd08d2d25b7ad239f36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ceb499487c1d4a8fbe59925154e10357": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_182129f2e50a44a5aa5bd261d98f887e",
              "IPY_MODEL_07f6c9d203454780b7cb4ebee4ef4c01",
              "IPY_MODEL_d95c67a60abe4208ba38a5469e68c153"
            ],
            "layout": "IPY_MODEL_d734d61d27d54c45b83454b3d410d481"
          }
        },
        "182129f2e50a44a5aa5bd261d98f887e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc749e44b1394345ab399d4c0a72cdc3",
            "placeholder": "​",
            "style": "IPY_MODEL_b648cb89bd3c447686adec5aaa635617",
            "value": "Generating train split: "
          }
        },
        "07f6c9d203454780b7cb4ebee4ef4c01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1ce8ba66790459fa9b663160a97d99d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0ec80017d693485c8fd0fd11898f584d",
            "value": 1
          }
        },
        "d95c67a60abe4208ba38a5469e68c153": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a86532955e0144018b7e370dcc7851ac",
            "placeholder": "​",
            "style": "IPY_MODEL_dae2faed7bcf4000904b25389db651a6",
            "value": " 0/0 [00:00&lt;?, ? examples/s]"
          }
        },
        "d734d61d27d54c45b83454b3d410d481": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "fc749e44b1394345ab399d4c0a72cdc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b648cb89bd3c447686adec5aaa635617": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1ce8ba66790459fa9b663160a97d99d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "0ec80017d693485c8fd0fd11898f584d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a86532955e0144018b7e370dcc7851ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dae2faed7bcf4000904b25389db651a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2b7aaaf062c43d1a8b9835ac5e2e87d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ae9906b88c77459f880e00f7978bcb17",
              "IPY_MODEL_d4dbefe0775f485d8f7f14db78e3947a",
              "IPY_MODEL_311584c003064ed792ec4c1a6a2eb21a"
            ],
            "layout": "IPY_MODEL_22e8c564a1d04a3b9c381467252fe0e3"
          }
        },
        "ae9906b88c77459f880e00f7978bcb17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fce87225291f4b5fbb8b03a31183d6d5",
            "placeholder": "​",
            "style": "IPY_MODEL_4fb7d0cfc40f4b5e890d8d673e72d95d",
            "value": "100%"
          }
        },
        "d4dbefe0775f485d8f7f14db78e3947a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a40ce5aa1414fa7adff6b7f5e0147c6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_16413fe2e8534221a3f48a20d465c245",
            "value": 1
          }
        },
        "311584c003064ed792ec4c1a6a2eb21a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bfb9835efb246cab867edd63c298280",
            "placeholder": "​",
            "style": "IPY_MODEL_4b96ec03168d4b1583ea56277f462d4a",
            "value": " 1/1 [00:00&lt;00:00, 32.53it/s]"
          }
        },
        "22e8c564a1d04a3b9c381467252fe0e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fce87225291f4b5fbb8b03a31183d6d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fb7d0cfc40f4b5e890d8d673e72d95d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a40ce5aa1414fa7adff6b7f5e0147c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16413fe2e8534221a3f48a20d465c245": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9bfb9835efb246cab867edd63c298280": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b96ec03168d4b1583ea56277f462d4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "686000c9e36f41149539cb1775f1add9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5cfe39c4f840474c8fb4496d71e1fa29",
              "IPY_MODEL_0a368e2e9d864678920ee5e14aa552f2",
              "IPY_MODEL_4d65713bfbbf403c8a6bf033a0d695cc"
            ],
            "layout": "IPY_MODEL_7bd0a22547fd434b9153571cdb7d4cbc"
          }
        },
        "5cfe39c4f840474c8fb4496d71e1fa29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee2e9084efc94a57aa3b58555ab55402",
            "placeholder": "​",
            "style": "IPY_MODEL_db57a69093484d0f87e7aac9139a6254",
            "value": "Downloading builder script: 100%"
          }
        },
        "0a368e2e9d864678920ee5e14aa552f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d75ca1cd8574673baac42cf288c0166",
            "max": 4314,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d7618e562fe54de68ff9bd867bb543a9",
            "value": 4314
          }
        },
        "4d65713bfbbf403c8a6bf033a0d695cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46ffc586d453485e8eb430b19e19142f",
            "placeholder": "​",
            "style": "IPY_MODEL_d97eb077de4146fdb3f874de12f8bc19",
            "value": " 4.31k/4.31k [00:00&lt;00:00, 166kB/s]"
          }
        },
        "7bd0a22547fd434b9153571cdb7d4cbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee2e9084efc94a57aa3b58555ab55402": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db57a69093484d0f87e7aac9139a6254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d75ca1cd8574673baac42cf288c0166": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7618e562fe54de68ff9bd867bb543a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "46ffc586d453485e8eb430b19e19142f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d97eb077de4146fdb3f874de12f8bc19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eed05ffd5d3f49e7a1a9dc3759e4f8d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8615fe3a2524084a39edb1c48134f71",
              "IPY_MODEL_6217bf69887e40c9b0a99338b5a2c175",
              "IPY_MODEL_ad74cfdebaf440ba8b38c13c4083e8a9"
            ],
            "layout": "IPY_MODEL_ac33b6d7a3d048e5833f8f017f3d32bf"
          }
        },
        "e8615fe3a2524084a39edb1c48134f71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c23b04f65aca40b79c58685a793c36a9",
            "placeholder": "​",
            "style": "IPY_MODEL_0df4ac0568024bffa565a6354bcbbec4",
            "value": "Downloading metadata: 100%"
          }
        },
        "6217bf69887e40c9b0a99338b5a2c175": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e09959706804306b65ffa0e82a1c916",
            "max": 2166,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b53c38a9d464426fb4352dcfa6c9e9f3",
            "value": 2166
          }
        },
        "ad74cfdebaf440ba8b38c13c4083e8a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82db8ff5b53d46529375ba75a1a1ccd9",
            "placeholder": "​",
            "style": "IPY_MODEL_267b561006e64303820b42d9887fba20",
            "value": " 2.17k/2.17k [00:00&lt;00:00, 73.8kB/s]"
          }
        },
        "ac33b6d7a3d048e5833f8f017f3d32bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c23b04f65aca40b79c58685a793c36a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0df4ac0568024bffa565a6354bcbbec4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e09959706804306b65ffa0e82a1c916": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b53c38a9d464426fb4352dcfa6c9e9f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "82db8ff5b53d46529375ba75a1a1ccd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "267b561006e64303820b42d9887fba20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df2dd0f0a48646c08739fefe71d8543f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_30c0f2fdfaa94cde8bde05bd37255ac2",
              "IPY_MODEL_5dbfd72eba194bf482d6fe013a66e9f4",
              "IPY_MODEL_aab84284c1f64e4c8eaad37092df6f8c"
            ],
            "layout": "IPY_MODEL_368411e5d5e3417db588160f35a3ca1a"
          }
        },
        "30c0f2fdfaa94cde8bde05bd37255ac2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60fd0072868849c987339ecff8d46a62",
            "placeholder": "​",
            "style": "IPY_MODEL_676253a401a14334ac6076b94dfff2b2",
            "value": "Downloading readme: 100%"
          }
        },
        "5dbfd72eba194bf482d6fe013a66e9f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c1051146ae14a3fa88ba336129ca6f9",
            "max": 7590,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b5dd4dc841d74e3f8376aac762285782",
            "value": 7590
          }
        },
        "aab84284c1f64e4c8eaad37092df6f8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b87ee69e5d7c4fb5bc2be407751733fe",
            "placeholder": "​",
            "style": "IPY_MODEL_6129506551e54065b5811feef887345f",
            "value": " 7.59k/7.59k [00:00&lt;00:00, 280kB/s]"
          }
        },
        "368411e5d5e3417db588160f35a3ca1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60fd0072868849c987339ecff8d46a62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "676253a401a14334ac6076b94dfff2b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c1051146ae14a3fa88ba336129ca6f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5dd4dc841d74e3f8376aac762285782": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b87ee69e5d7c4fb5bc2be407751733fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6129506551e54065b5811feef887345f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "723d5dda640e4e17a1b74759a8ee7c1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_afcd7336514e4a96894279dc0b93e0c1",
              "IPY_MODEL_7b19739190e4433283d728e8b955dc88",
              "IPY_MODEL_681934a1030a48c49bc3ee127d6cd681"
            ],
            "layout": "IPY_MODEL_a5c2a95f727b4ee0b1b93e37f4988fca"
          }
        },
        "afcd7336514e4a96894279dc0b93e0c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0523f9a09c41433fa36752a0b9f51d43",
            "placeholder": "​",
            "style": "IPY_MODEL_4667efa7efae4620b35136f329dcab05",
            "value": "Downloading data: 100%"
          }
        },
        "7b19739190e4433283d728e8b955dc88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_024c2f461151416693b4e2526c4f7206",
            "max": 84125825,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_31e96aee7c73466d9ff38d2af2e74bfc",
            "value": 84125825
          }
        },
        "681934a1030a48c49bc3ee127d6cd681": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b4d6adbf3e44c7ca76bfc2d86a55d4f",
            "placeholder": "​",
            "style": "IPY_MODEL_9c6f621299264000976411252b22dfea",
            "value": " 84.1M/84.1M [00:09&lt;00:00, 19.1MB/s]"
          }
        },
        "a5c2a95f727b4ee0b1b93e37f4988fca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0523f9a09c41433fa36752a0b9f51d43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4667efa7efae4620b35136f329dcab05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "024c2f461151416693b4e2526c4f7206": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31e96aee7c73466d9ff38d2af2e74bfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4b4d6adbf3e44c7ca76bfc2d86a55d4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c6f621299264000976411252b22dfea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ec39fb9b0394ff29aca9363ca623dfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d68810bb3664b32a4f7e57c7d045f12",
              "IPY_MODEL_dd28d1a21d014490a00e5973a08af576",
              "IPY_MODEL_64d9b28a7884414d89cf32e20d879265"
            ],
            "layout": "IPY_MODEL_fa5889e60b1c491a90fe248db7fa2f08"
          }
        },
        "1d68810bb3664b32a4f7e57c7d045f12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f47e0cf2ea74bba965bde5f353b41b2",
            "placeholder": "​",
            "style": "IPY_MODEL_ffaad0a085024bc4bd9fdbb1d30caf3c",
            "value": "Generating train split: 100%"
          }
        },
        "dd28d1a21d014490a00e5973a08af576": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95e74c34605b4f3d84844529208e92b0",
            "max": 25000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_27e1de79a8ce4c9ca4cf7636c0d372b2",
            "value": 25000
          }
        },
        "64d9b28a7884414d89cf32e20d879265": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02433cf760cc40ddab668ed696cf3b5c",
            "placeholder": "​",
            "style": "IPY_MODEL_0e18eb913d364d69ae2ba709543b9455",
            "value": " 25000/25000 [00:16&lt;00:00, 4487.54 examples/s]"
          }
        },
        "fa5889e60b1c491a90fe248db7fa2f08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "7f47e0cf2ea74bba965bde5f353b41b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffaad0a085024bc4bd9fdbb1d30caf3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95e74c34605b4f3d84844529208e92b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27e1de79a8ce4c9ca4cf7636c0d372b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "02433cf760cc40ddab668ed696cf3b5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e18eb913d364d69ae2ba709543b9455": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b0f6796c33c4e86b0649c645c2ba339": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d82530b59187404a85d971e667ca60a8",
              "IPY_MODEL_010b0d1f14404e1cbee05fc25c4f8ac0",
              "IPY_MODEL_8e1097309c6d469396bf470d9eef4b58"
            ],
            "layout": "IPY_MODEL_ae83af989bdf466b9531ee642b4f057c"
          }
        },
        "d82530b59187404a85d971e667ca60a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3f41fbf522c4a75b2f759312cecbe63",
            "placeholder": "​",
            "style": "IPY_MODEL_f3da7c2995394c7eb02c8c76048cd5d3",
            "value": "Generating test split: 100%"
          }
        },
        "010b0d1f14404e1cbee05fc25c4f8ac0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47f500f3f1f74e82a4d1818c19e3f326",
            "max": 25000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e99b8fbc9d5e40548de5c89fdeaaa44d",
            "value": 25000
          }
        },
        "8e1097309c6d469396bf470d9eef4b58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ca87b59b6904065a79561ee6223cc58",
            "placeholder": "​",
            "style": "IPY_MODEL_0727e12c05644de29a62091189651d7a",
            "value": " 25000/25000 [00:24&lt;00:00, 7214.19 examples/s]"
          }
        },
        "ae83af989bdf466b9531ee642b4f057c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "a3f41fbf522c4a75b2f759312cecbe63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3da7c2995394c7eb02c8c76048cd5d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47f500f3f1f74e82a4d1818c19e3f326": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e99b8fbc9d5e40548de5c89fdeaaa44d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8ca87b59b6904065a79561ee6223cc58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0727e12c05644de29a62091189651d7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c1f241807404c4cbc52d1314368d6e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d07fbfa75ca048fda1fdea732ae813af",
              "IPY_MODEL_1e095b5ddc1b43978b3af58ee29bb85f",
              "IPY_MODEL_308eb890117c431a8b5d25d30b32695e"
            ],
            "layout": "IPY_MODEL_f6a864c4949a4ef7a90315db85a7954f"
          }
        },
        "d07fbfa75ca048fda1fdea732ae813af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f5a525e118448798b4982b760c8fb59",
            "placeholder": "​",
            "style": "IPY_MODEL_762b2446ca8d4b0ea0b80185aea555cd",
            "value": "Generating unsupervised split: 100%"
          }
        },
        "1e095b5ddc1b43978b3af58ee29bb85f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46cb0a520aa54c5ebb47bc8a2dea40e6",
            "max": 50000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4d14bab2342c4c588a0de26905b80827",
            "value": 50000
          }
        },
        "308eb890117c431a8b5d25d30b32695e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e77593fa03cc4430832ffc6d5f6c5e26",
            "placeholder": "​",
            "style": "IPY_MODEL_8cfbda2a0d8a4f5fa25265ac3303f9ed",
            "value": " 50000/50000 [00:34&lt;00:00, 7502.34 examples/s]"
          }
        },
        "f6a864c4949a4ef7a90315db85a7954f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "6f5a525e118448798b4982b760c8fb59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "762b2446ca8d4b0ea0b80185aea555cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46cb0a520aa54c5ebb47bc8a2dea40e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d14bab2342c4c588a0de26905b80827": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e77593fa03cc4430832ffc6d5f6c5e26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cfbda2a0d8a4f5fa25265ac3303f9ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1281eed63ef4fcc9f997a029d6b734c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1383cb7539a647e2bfc62f6c6932d831",
              "IPY_MODEL_bc64af65441143b780970728e1431360",
              "IPY_MODEL_ca0f73d8f2c2494fa66852694d9e7144"
            ],
            "layout": "IPY_MODEL_c2472924d7f34b20b460b6c57d343ce2"
          }
        },
        "1383cb7539a647e2bfc62f6c6932d831": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c72eeecc36be4c10a903bd28f51c37d2",
            "placeholder": "​",
            "style": "IPY_MODEL_fe754088114245ecb6fff201d7971e4b",
            "value": "Map: 100%"
          }
        },
        "bc64af65441143b780970728e1431360": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5b594779a9145459ed4d84c8cce4080",
            "max": 50000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cdaf7cf64b2246f0aad6d79194b7356e",
            "value": 50000
          }
        },
        "ca0f73d8f2c2494fa66852694d9e7144": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfdb0585348b44b2b7d1b787b250ff87",
            "placeholder": "​",
            "style": "IPY_MODEL_42d6855379de4edea2c97fd1f0438e15",
            "value": " 49974/50000 [02:45&lt;00:00, 198.36 examples/s]"
          }
        },
        "c2472924d7f34b20b460b6c57d343ce2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "c72eeecc36be4c10a903bd28f51c37d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe754088114245ecb6fff201d7971e4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5b594779a9145459ed4d84c8cce4080": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdaf7cf64b2246f0aad6d79194b7356e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dfdb0585348b44b2b7d1b787b250ff87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42d6855379de4edea2c97fd1f0438e15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d632cce31730445a8c9ccf5d5c02225b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_926547d1646941718f5f09e319ffe964",
              "IPY_MODEL_efa62eb2bac144b89c3eebc37e77fc9c",
              "IPY_MODEL_a47b8a20659e469b8613252045f542e6"
            ],
            "layout": "IPY_MODEL_e9848f1b6e42454593ba8aea7bfe6534"
          }
        },
        "926547d1646941718f5f09e319ffe964": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8448416d0d46447da98b8011ea39c1db",
            "placeholder": "​",
            "style": "IPY_MODEL_4678015f68434d39a8f7efa3339a2b2e",
            "value": "[generation sweep 0/1 | eval batch 0/1]:   0%"
          }
        },
        "efa62eb2bac144b89c3eebc37e77fc9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f1ebd16ef0949e9b02eb9499df909f3",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f3743a3e9f7e486782f53cae47f0cbe7",
            "value": 0
          }
        },
        "a47b8a20659e469b8613252045f542e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2eaabfbe2694897934e5d82fad4b861",
            "placeholder": "​",
            "style": "IPY_MODEL_e8f64c10a87742729bd5b953c729492b",
            "value": " 0/1 [00:00&lt;?, ?it/s]"
          }
        },
        "e9848f1b6e42454593ba8aea7bfe6534": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8448416d0d46447da98b8011ea39c1db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4678015f68434d39a8f7efa3339a2b2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f1ebd16ef0949e9b02eb9499df909f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3743a3e9f7e486782f53cae47f0cbe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f2eaabfbe2694897934e5d82fad4b861": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8f64c10a87742729bd5b953c729492b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84596edc3cd14511942d5d87623d8964": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_612e77cc2fd74bb081b1f45b73a00684",
              "IPY_MODEL_feee40745e6f46dfa5a1d1a106da2625",
              "IPY_MODEL_7ab11506bcd7477882eb5f65425a14cd"
            ],
            "layout": "IPY_MODEL_689d8ebe9a09443d83bd1e8c1c79b4df"
          }
        },
        "612e77cc2fd74bb081b1f45b73a00684": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ed881d07ea94ea3afd5d6ededb2a7a1",
            "placeholder": "​",
            "style": "IPY_MODEL_ae0cd0a7b34543c98f2598871149970d",
            "value": "Downloading data files: 100%"
          }
        },
        "feee40745e6f46dfa5a1d1a106da2625": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7031676d638b4945b79311643c5b9911",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a4129066c6cb4c9aa61becd3d8fe2225",
            "value": 1
          }
        },
        "7ab11506bcd7477882eb5f65425a14cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_359bd2a427bc44aa8e94d67782638dd5",
            "placeholder": "​",
            "style": "IPY_MODEL_ea4f40c12dc449458e933069628277ac",
            "value": " 1/1 [00:00&lt;00:00, 44.39it/s]"
          }
        },
        "689d8ebe9a09443d83bd1e8c1c79b4df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ed881d07ea94ea3afd5d6ededb2a7a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae0cd0a7b34543c98f2598871149970d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7031676d638b4945b79311643c5b9911": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4129066c6cb4c9aa61becd3d8fe2225": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "359bd2a427bc44aa8e94d67782638dd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea4f40c12dc449458e933069628277ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca0692f20fde4edabb7e95199434b853": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_316197278593419ca5d075081a11881d",
              "IPY_MODEL_eb747b371533441a8e815e997d354b43",
              "IPY_MODEL_e95513b8628f410f8441592ca88a3f7e"
            ],
            "layout": "IPY_MODEL_3c7718c4a35d4901b17a5b3cb746fd48"
          }
        },
        "316197278593419ca5d075081a11881d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c847dbbc9c3c4c568beff8cc2672b8e9",
            "placeholder": "​",
            "style": "IPY_MODEL_77b578bf53364abeaf7d3f53f1b69254",
            "value": "Extracting data files: 100%"
          }
        },
        "eb747b371533441a8e815e997d354b43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56fe6d386eb24683bacee87d51574263",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ca711f2b9e24027aca28279a63a12e0",
            "value": 1
          }
        },
        "e95513b8628f410f8441592ca88a3f7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae33439e69a540db85cc56f8b56bd9af",
            "placeholder": "​",
            "style": "IPY_MODEL_463a30c137e94d64953b726d465d44c3",
            "value": " 1/1 [00:00&lt;00:00, 39.30it/s]"
          }
        },
        "3c7718c4a35d4901b17a5b3cb746fd48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c847dbbc9c3c4c568beff8cc2672b8e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77b578bf53364abeaf7d3f53f1b69254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56fe6d386eb24683bacee87d51574263": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ca711f2b9e24027aca28279a63a12e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae33439e69a540db85cc56f8b56bd9af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "463a30c137e94d64953b726d465d44c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6350deeec6744b9cb48669c865c893aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ed800fde3b744a89bfb13c665b4cd9a",
              "IPY_MODEL_f86b0643d7ca410fb0d72b620938bd22",
              "IPY_MODEL_ea30485cc0b54f329f252f57f3471c0e"
            ],
            "layout": "IPY_MODEL_222e5e8cb1014e2b96c95c7027190f0f"
          }
        },
        "0ed800fde3b744a89bfb13c665b4cd9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c84b2ecf94a846959ef070728d740450",
            "placeholder": "​",
            "style": "IPY_MODEL_e333d942fa354303bad9f0e0cccc7b7d",
            "value": "Generating train split: "
          }
        },
        "f86b0643d7ca410fb0d72b620938bd22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff1a37dff9f24ca09c159fced82b9c92",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e6115b3e94bf418daeddaeaa2f320fed",
            "value": 1
          }
        },
        "ea30485cc0b54f329f252f57f3471c0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77d4468931d348d7a97a46569bedeff9",
            "placeholder": "​",
            "style": "IPY_MODEL_0b89140d21434f9a8bf25497db0a9e11",
            "value": " 0/0 [00:00&lt;?, ? examples/s]"
          }
        },
        "222e5e8cb1014e2b96c95c7027190f0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "c84b2ecf94a846959ef070728d740450": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e333d942fa354303bad9f0e0cccc7b7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff1a37dff9f24ca09c159fced82b9c92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "e6115b3e94bf418daeddaeaa2f320fed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "77d4468931d348d7a97a46569bedeff9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b89140d21434f9a8bf25497db0a9e11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71a7bfcb3ce644a28e10639c3439d0a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5101ef58855247f8852249b65fe419ab",
              "IPY_MODEL_c2829b1716b04ec888d1789d0169244b",
              "IPY_MODEL_b8e28f81e06a4722bad654e6dc91c8b7"
            ],
            "layout": "IPY_MODEL_1c3d156217964da8b1c193e2ea4ff0a9"
          }
        },
        "5101ef58855247f8852249b65fe419ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0d5adebcb9d4a8cb761b1a00a6540a8",
            "placeholder": "​",
            "style": "IPY_MODEL_aad3ea00d81b46ce9e2a1c9f2eba4bb1",
            "value": "[generation sweep 1/1 | eval batch 4/4]: 100%"
          }
        },
        "c2829b1716b04ec888d1789d0169244b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4135780cc16a4db59b2e879a0b5b9abf",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7c4cbb256b7a47e491cc3ad212e31b5d",
            "value": 4
          }
        },
        "b8e28f81e06a4722bad654e6dc91c8b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8e8fe1819c44c6aad31130f1899834b",
            "placeholder": "​",
            "style": "IPY_MODEL_8e3bee401e4f4337960a28eab1d4e274",
            "value": " 4/4 [00:23&lt;00:00,  5.61s/it]"
          }
        },
        "1c3d156217964da8b1c193e2ea4ff0a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0d5adebcb9d4a8cb761b1a00a6540a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aad3ea00d81b46ce9e2a1c9f2eba4bb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4135780cc16a4db59b2e879a0b5b9abf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c4cbb256b7a47e491cc3ad212e31b5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8e8fe1819c44c6aad31130f1899834b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e3bee401e4f4337960a28eab1d4e274": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "febec210c0fd4dfa8d2d32efa4c1a5b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_456b3399506349888b11ae157cf7372e",
              "IPY_MODEL_3529f88bef074ced8ac46547e3f685a1",
              "IPY_MODEL_d25b4c66e9f74e97b768e59cf2d929c0"
            ],
            "layout": "IPY_MODEL_10982521d3104a50abbf2ecb1effba51"
          }
        },
        "456b3399506349888b11ae157cf7372e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0791aabad7f049c2bd24a78ba8d56cff",
            "placeholder": "​",
            "style": "IPY_MODEL_4e2303dc9fab4a699c0b9877dd756307",
            "value": "  0%"
          }
        },
        "3529f88bef074ced8ac46547e3f685a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab656885af4440f7b719c90391d9f7ef",
            "max": 5000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f43b7bb62a7746b3b2a49f88fd2660b5",
            "value": 0
          }
        },
        "d25b4c66e9f74e97b768e59cf2d929c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4a6780e506a4e6081e9d4172250d388",
            "placeholder": "​",
            "style": "IPY_MODEL_c1b8d87574434858865a6a6189985861",
            "value": " 0/5000 [00:00&lt;?, ?it/s]"
          }
        },
        "10982521d3104a50abbf2ecb1effba51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0791aabad7f049c2bd24a78ba8d56cff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e2303dc9fab4a699c0b9877dd756307": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab656885af4440f7b719c90391d9f7ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f43b7bb62a7746b3b2a49f88fd2660b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a4a6780e506a4e6081e9d4172250d388": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1b8d87574434858865a6a6189985861": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}